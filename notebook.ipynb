{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llama_cpp import Llama\n",
    "from langdetect import detect\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset \n",
    "\n",
    "Prepare the dataset for use, explaining your selection criteria for the subset you choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'train.jsonl', 'test': 'test.jsonl'}\n",
    "df = pd.read_json(\"hf://datasets/ajaykarthick/imdb-movie-reviews/\" + splits[\"train\"], lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ms Aparna Sen, the maker of Mr &amp; Mrs Iyer, dir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have seen this film only once, on TV, and it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was only fourteen when I first saw the Alien...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This marvelous short will hit home with everyo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you are 10 years old and never seen a movie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  Ms Aparna Sen, the maker of Mr & Mrs Iyer, dir...      0\n",
       "1  I have seen this film only once, on TV, and it...      0\n",
       "2  I was only fourteen when I first saw the Alien...      1\n",
       "3  This marvelous short will hit home with everyo...      0\n",
       "4  If you are 10 years old and never seen a movie...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should check that all these reviews are in English so will use the `langdetect` library to do that\n",
    "# N.B. this is quite slow(about 2 mins on my machine)\n",
    "df[\"language\"] = df[\"review\"].apply(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also add a column for the length of the review\n",
    "df[\"review_length\"] = df[\"review\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ms Aparna Sen, the maker of Mr &amp; Mrs Iyer, dir...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>2408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have seen this film only once, on TV, and it...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was only fourteen when I first saw the Alien...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>1481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This marvelous short will hit home with everyo...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you are 10 years old and never seen a movie...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label language  \\\n",
       "0  Ms Aparna Sen, the maker of Mr & Mrs Iyer, dir...      0       en   \n",
       "1  I have seen this film only once, on TV, and it...      0       en   \n",
       "2  I was only fourteen when I first saw the Alien...      1       en   \n",
       "3  This marvelous short will hit home with everyo...      0       en   \n",
       "4  If you are 10 years old and never seen a movie...      1       en   \n",
       "\n",
       "   review_length  \n",
       "0           2408  \n",
       "1            662  \n",
       "2           1481  \n",
       "3            830  \n",
       "4            238  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1312.303950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500006</td>\n",
       "      <td>993.920001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>970.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1598.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13704.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  review_length\n",
       "count  40000.000000   40000.000000\n",
       "mean       0.500000    1312.303950\n",
       "std        0.500006     993.920001\n",
       "min        0.000000      41.000000\n",
       "25%        0.000000     699.000000\n",
       "50%        0.500000     970.000000\n",
       "75%        1.000000    1598.000000\n",
       "max        1.000000   13704.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['review_length'], bins=30, edgecolor='black')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Review length')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_length_bin'] = pd.qcut(df['review_length'], q=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "      <th>review_length</th>\n",
       "      <th>review_length_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ms Aparna Sen, the maker of Mr &amp; Mrs Iyer, dir...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>2408</td>\n",
       "      <td>(1829.0, 2583.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have seen this film only once, on TV, and it...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>662</td>\n",
       "      <td>(503.0, 662.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was only fourteen when I first saw the Alien...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>1481</td>\n",
       "      <td>(1412.0, 1829.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This marvelous short will hit home with everyo...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>830</td>\n",
       "      <td>(739.0, 838.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you are 10 years old and never seen a movie...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>238</td>\n",
       "      <td>(40.999, 503.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label language  \\\n",
       "0  Ms Aparna Sen, the maker of Mr & Mrs Iyer, dir...      0       en   \n",
       "1  I have seen this film only once, on TV, and it...      0       en   \n",
       "2  I was only fourteen when I first saw the Alien...      1       en   \n",
       "3  This marvelous short will hit home with everyo...      0       en   \n",
       "4  If you are 10 years old and never seen a movie...      1       en   \n",
       "\n",
       "   review_length review_length_bin  \n",
       "0           2408  (1829.0, 2583.0]  \n",
       "1            662    (503.0, 662.0]  \n",
       "2           1481  (1412.0, 1829.0]  \n",
       "3            830    (739.0, 838.0]  \n",
       "4            238   (40.999, 503.0]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'id'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the language of the reviews quickly\n",
    "df['language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>.....whoops - looks like it's gonna cost you a...</td>\n",
       "      <td>0</td>\n",
       "      <td>id</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label language  \\\n",
       "24998  .....whoops - looks like it's gonna cost you a...      0       id   \n",
       "\n",
       "       review_length  \n",
       "24998            730  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the examples where the language is not English\n",
    "df[df[\"language\"] != \"en\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like all the reviews are in English so most immediate way of subsetting the data is by review_length and the label. Could go deep with something like https://pypi.org/project/py-readability-metrics/ but don't really want to overdo this. \n",
    "\n",
    "As for size of subset let's go with 5k for now (not sure what constraints of my machine are yet) and will review later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df,\n",
    "    df[[\"review_length\", \"label\"]],\n",
    "    stratify=df[[\"review_length_bin\", \"label\"]],\n",
    "    test_size=5000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35000.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1312.883314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500007</td>\n",
       "      <td>995.889168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>970.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1597.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13704.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  review_length\n",
       "count  35000.000000   35000.000000\n",
       "mean       0.500000    1312.883314\n",
       "std        0.500007     995.889168\n",
       "min        0.000000      41.000000\n",
       "25%        0.000000     699.000000\n",
       "50%        0.500000     970.000000\n",
       "75%        1.000000    1597.000000\n",
       "max        1.000000   13704.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK looks like that's worked, let's clean up and get onto the next bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.00000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>1308.248400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50005</td>\n",
       "      <td>980.113877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>698.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>970.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1606.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>7068.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label  review_length\n",
       "count  5000.00000    5000.000000\n",
       "mean      0.50000    1308.248400\n",
       "std       0.50005     980.113877\n",
       "min       0.00000      64.000000\n",
       "25%       0.00000     698.000000\n",
       "50%       0.50000     970.000000\n",
       "75%       1.00000    1606.250000\n",
       "max       1.00000    7068.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_test[['review', 'label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement local inference\n",
    "\n",
    "- Choose optimal inference parameters (e.g., temperature, top_p, top_k) for each model\n",
    "- https://llama-cpp-python.readthedocs.io/en/latest/api-reference/#llama_cpp.Llama.create_chat_completion contains avaliable parameters \n",
    "- It doesn't look like I can batch up responses so will have to just keep hitting the model: https://github.com/abetlen/llama-cpp-python/issues/1529 \n",
    "- Unsure how clever I want to be here, will have to see how long it takes to get these responses out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuff to work out / ideas\n",
    "\n",
    "- [ ] How to choose optimal inference params (do I need to do a bit of a hyperparameter tuning?)\n",
    "- [x] How do I run this stuff in batch mode: YOU CAN'T\n",
    "- [ ] Do I want to try and mess around with context window? Feels like default is set like that for a reason. \n",
    "- [ ] With context window at 512, randomise which part of review to take (if it's longer than 512) and aggregate \n",
    "- [ ] I need to understand top_k / top_p etc. \n",
    "- [ ] Need to make a decision RE temperature \n",
    "- [ ] Make decision on metrics (what is usually used for sentiment analysis?) Probably don't want to overthink this?\n",
    "- [ ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anna/.pyenv/versions/3.12.7/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "llama_load_model_from_file: using device Metal (AMD Radeon Pro 5500M) - 8176 MiB free\n",
      "llama_model_loader: loaded meta data with 37 key-value pairs and 290 tensors from /Users/anna/.cache/huggingface/hub/models--bartowski--Qwen2.5-0.5B-Instruct-GGUF/snapshots/41ba88dbac95fed2528c92514c131d73eb5a174b/./Qwen2.5-0.5B-Instruct-IQ2_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Qwen2.5 0.5B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Qwen2.5\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 0.5B\n",
      "llama_model_loader: - kv   6:                            general.license str              = apache-2.0\n",
      "llama_model_loader: - kv   7:                   general.base_model.count u32              = 1\n",
      "llama_model_loader: - kv   8:                  general.base_model.0.name str              = Qwen2.5 0.5B\n",
      "llama_model_loader: - kv   9:          general.base_model.0.organization str              = Qwen\n",
      "llama_model_loader: - kv  10:              general.base_model.0.repo_url str              = https://huggingface.co/Qwen/Qwen2.5-0.5B\n",
      "llama_model_loader: - kv  11:                               general.tags arr[str,2]       = [\"chat\", \"text-generation\"]\n",
      "llama_model_loader: - kv  12:                          general.languages arr[str,1]       = [\"en\"]\n",
      "llama_model_loader: - kv  13:                          qwen2.block_count u32              = 24\n",
      "llama_model_loader: - kv  14:                       qwen2.context_length u32              = 32768\n",
      "llama_model_loader: - kv  15:                     qwen2.embedding_length u32              = 896\n",
      "llama_model_loader: - kv  16:                  qwen2.feed_forward_length u32              = 4864\n",
      "llama_model_loader: - kv  17:                 qwen2.attention.head_count u32              = 14\n",
      "llama_model_loader: - kv  18:              qwen2.attention.head_count_kv u32              = 2\n",
      "llama_model_loader: - kv  19:                       qwen2.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  20:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  21:                          general.file_type u32              = 29\n",
      "llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = qwen2\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,151387]  = [\" \", \" \", \"i n\", \" t\",...\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 151645\n",
      "llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 151643\n",
      "llama_model_loader: - kv  29:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  30:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  31:                    tokenizer.chat_template str              = {%- if tools %}\\n    {{- '<|im_start|>...\n",
      "llama_model_loader: - kv  32:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  33:                      quantize.imatrix.file str              = /models_out/Qwen2.5-0.5B-Instruct-GGU...\n",
      "llama_model_loader: - kv  34:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  35:             quantize.imatrix.entries_count i32              = 168\n",
      "llama_model_loader: - kv  36:              quantize.imatrix.chunks_count i32              = 128\n",
      "llama_model_loader: - type  f32:  121 tensors\n",
      "llama_model_loader: - type q5_0:   24 tensors\n",
      "llama_model_loader: - type q8_0:    1 tensors\n",
      "llama_model_loader: - type iq4_nl:  120 tensors\n",
      "llama_model_loader: - type iq3_s:    3 tensors\n",
      "llama_model_loader: - type iq2_s:   21 tensors\n",
      "llm_load_vocab: control token: 151659 '<|fim_prefix|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151656 '<|video_pad|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151655 '<|image_pad|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151653 '<|vision_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151652 '<|vision_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151651 '<|quad_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151649 '<|box_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151648 '<|box_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151646 '<|object_ref_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151644 '<|im_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151661 '<|fim_suffix|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151647 '<|object_ref_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151660 '<|fim_middle|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151654 '<|vision_pad|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151650 '<|quad_start|>' is not marked as EOG\n",
      "llm_load_vocab: special tokens cache size = 22\n",
      "llm_load_vocab: token to piece cache size = 0.9310 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = qwen2\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 151936\n",
      "llm_load_print_meta: n_merges         = 151387\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 896\n",
      "llm_load_print_meta: n_layer          = 24\n",
      "llm_load_print_meta: n_head           = 14\n",
      "llm_load_print_meta: n_head_kv        = 2\n",
      "llm_load_print_meta: n_rot            = 64\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 64\n",
      "llm_load_print_meta: n_embd_head_v    = 64\n",
      "llm_load_print_meta: n_gqa            = 7\n",
      "llm_load_print_meta: n_embd_k_gqa     = 128\n",
      "llm_load_print_meta: n_embd_v_gqa     = 128\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 4864\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 1B\n",
      "llm_load_print_meta: model ftype      = IQ2_M - 2.7 bpw\n",
      "llm_load_print_meta: model params     = 494.03 M\n",
      "llm_load_print_meta: model size       = 307.70 MiB (5.22 BPW) \n",
      "llm_load_print_meta: general.name     = Qwen2.5 0.5B Instruct\n",
      "llm_load_print_meta: BOS token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: EOS token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: EOT token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: PAD token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 148848 ''\n",
      "llm_load_print_meta: FIM PRE token    = 151659 '<|fim_prefix|>'\n",
      "llm_load_print_meta: FIM SUF token    = 151661 '<|fim_suffix|>'\n",
      "llm_load_print_meta: FIM MID token    = 151660 '<|fim_middle|>'\n",
      "llm_load_print_meta: FIM PAD token    = 151662 '<|fim_pad|>'\n",
      "llm_load_print_meta: FIM REP token    = 151663 '<|repo_name|>'\n",
      "llm_load_print_meta: FIM SEP token    = 151664 '<|file_sep|>'\n",
      "llm_load_print_meta: EOG token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: EOG token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: EOG token        = 151662 '<|fim_pad|>'\n",
      "llm_load_print_meta: EOG token        = 151663 '<|repo_name|>'\n",
      "llm_load_print_meta: EOG token        = 151664 '<|file_sep|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q8_0) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/25 layers to GPU\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =   307.70 MiB\n",
      ".........................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 512\n",
      "llama_new_context_with_model: n_ctx_per_seq = 512\n",
      "llama_new_context_with_model: n_batch       = 512\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 0\n",
      "llama_new_context_with_model: freq_base     = 1000000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Intel(R) UHD Graphics 630\n",
      "ggml_metal_init: found device: AMD Radeon Pro 5500M\n",
      "ggml_metal_init: picking default device: AMD Radeon Pro 5500M\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   AMD Radeon Pro 5500M\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = false\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = false\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  =  8573.16 MB\n",
      "ggml_metal_init: loaded kernel_add                                 0x7fcde720f540 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row                             0x7fce53f06970 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                 0x7fcde5498e50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row                             0x7fcde720ffb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                 0x7fcde549a460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row                             0x7fcdf2338510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                 0x7fcde7211240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row                             0x7fcde549bb00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                          0x7fcde7211cb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                          0x7fcde7212f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                          0x7fcde549d1f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                          0x7fcde549de00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                               0x7fcde549fcb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                             0x7fcde7096e10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                               0x7fcde54a10c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                0x7fce53f070b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                0x7fce53f077f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                             0x7fcdf23398a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                0x7fce53f08260 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                              0x7fcdf233a1f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                          0x7fcde7214b80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                        0x7fcde554c8d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                0x7fcdf233ae90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                              0x7fcde7097c50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                        0x7fcde7216730 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                      0x7fcde554d340 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                        0x7fcde54a29f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                      0x7fcdf233cc60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                       0x7fcde7099050 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                     0x7fcde7217ab0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                        0x7fcde554ddb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                        0x7fcdf3218030 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                       0x7fcde54a3f10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                       0x7fcde54a49b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                       0x7fcde7219540 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                       0x7fce53f08cd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                       0x7fcde721a520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                       0x7fce54906930 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                       0x7fcde709a9d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                       0x7fcde721b300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                       0x7fcde721c140 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                       0x7fcdf233da00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                    0x7fcde54a6540 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                     0x7fcdf233e550 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                    0x7fcde721d200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                      0x7fcdf233f610 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                      0x7fcde54a8020 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                      0x7fce53f093b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                      0x7fcde709be60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                     0x7fcde709d730 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                     0x7fcde709dfd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                        0x7fce53f09e20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                            0x7fcde54a9410 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                          0x7fcdf2340ec0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                0x7fce53f0ac20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                        0x7fce549078b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                        0x7fcdf2341f70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                      0x7fcde537dc70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                      0x7fcdf2342f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                 0x7fcde537e3b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                   0x7fcdf2344620 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                      0x7fcdf2345a50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                     0x7fcde72207a0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                     0x7fcde709f6a0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                     0x7fcde554e820 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                     0x7fcde54ab130 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                     0x7fcde54abf60 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                     0x7fcde5621f60 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                     0x7fcde54ada80 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                     0x7fcde537ee20 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                     0x7fcdf23473b0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                     0x7fcde54af130 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                  0x7fcde70a0c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                   0x7fcde7221f30 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                  0x7fcde70a1ea0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                    0x7fcde554f290 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                    0x7fcde54b0be0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                    0x7fcde56226a0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                    0x7fcde70a2fd0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                   0x7fcde70a3e80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                   0x7fcde54b22a0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                   0x7fcde54b3620 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                   0x7fcdf2348a70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                  0x7fcde7222fb0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                  0x7fcde5623480 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                  0x7fcde5623ef0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                  0x7fcde70a58a0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                  0x7fcde54b5050 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                  0x7fcde54b5d50 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                  0x7fcde54b7210 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                  0x7fcde70a7170 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                  0x7fcde54b8b90 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                  0x7fcde54ba000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32               0x7fcde70a8a40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                0x7fcde7224630 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32               0x7fcde7225400 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                 0x7fcdf321a020 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                 0x7fcde5624f80 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                 0x7fcde54bba70 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                 0x7fcde7226d30 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                0x7fcde70a9870 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                0x7fcde54bc720 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_f32_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_f16_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q8_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q2_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q3_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q6_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_m_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_nl_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f32_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f16_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q8_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q2_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q3_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q6_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xs_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_m_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_nl_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_xs_f32              (not supported)\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                       0x7fcde54bd570 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                       0x7fcdf321ba80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                       0x7fcdf234b170 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                       0x7fcde5625aa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                          0x7fcde7227740 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                          0x7fcde54bf0a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                      0x7fcde70ab280 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                      0x7fcde54bfde0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                         0x7fcdf321c490 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                             0x7fcde7228f30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32              0x7fcde70ac230 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                          0x7fcde70ace30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                 0x7fcde722a710 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                0x7fcdf234ca70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                      0x7fcde5627690 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h64            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h80            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h96            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h112           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h128           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h256           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h256          (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128         0x7fcde537f890 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128        0x7fcdf234ce20 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128        0x7fcde54c2110 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128        0x7fcde54c3320 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128        0x7fcdf234db60 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128        0x7fcde70af530 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256         0x7fcde5380300 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256        0x7fcde54c44c0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256        0x7fcdf321e0c0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256        0x7fcde722c720 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256        0x7fcde722e130 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256        0x7fcde54c6090 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                         0x7fcde722fac0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                         0x7fcde70b0990 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                         0x7fcde54c78f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                         0x7fcde54c8670 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                        0x7fcde70b1ee0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                        0x7fcdf234e960 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                        0x7fcde7231530 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                        0x7fcde54ca000 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                        0x7fcde70b28f0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                      0x7fcde70b40d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                              0x7fcde70b4d30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                 0x7fcdf2350450 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                0x7fcde54cb170 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                 0x7fcde54cbef0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                 0x7fcde7232be0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                            0x7fcde54cd560 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                     0x7fcde54cdfd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                     0x7fcdf2351860 | th_max = 1024 | th_width =   32\n",
      "llama_kv_cache_init:        CPU KV buffer size =     6.00 MiB\n",
      "llama_new_context_with_model: KV self size  =    6.00 MiB, K (f16):    3.00 MiB, V (f16):    3.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.58 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   298.50 MiB\n",
      "llama_new_context_with_model: graph nodes  = 846\n",
      "llama_new_context_with_model: graph splits = 386 (with bs=512), 1 (with bs=1)\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | AMX_INT8 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'quantize.imatrix.entries_count': '168', 'quantize.imatrix.file': '/models_out/Qwen2.5-0.5B-Instruct-GGUF/Qwen2.5-0.5B-Instruct.imatrix', 'quantize.imatrix.chunks_count': '128', 'tokenizer.chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are a helpful assistant.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- else %}\\n        {{- \\'<|im_start|>system\\\\nYou are a helpful assistant.<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.add_bos_token': 'false', 'tokenizer.ggml.padding_token_id': '151643', 'tokenizer.ggml.eos_token_id': '151645', 'qwen2.attention.layer_norm_rms_epsilon': '0.000001', 'general.basename': 'Qwen2.5', 'qwen2.attention.head_count_kv': '2', 'general.size_label': '0.5B', 'general.base_model.0.name': 'Qwen2.5 0.5B', 'qwen2.embedding_length': '896', 'qwen2.context_length': '32768', 'qwen2.block_count': '24', 'general.base_model.0.organization': 'Qwen', 'tokenizer.ggml.pre': 'qwen2', 'general.base_model.count': '1', 'qwen2.rope.freq_base': '1000000.000000', 'general.quantization_version': '2', 'general.license': 'apache-2.0', 'general.base_model.0.repo_url': 'https://huggingface.co/Qwen/Qwen2.5-0.5B', 'general.file_type': '29', 'general.finetune': 'Instruct', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'general.name': 'Qwen2.5 0.5B Instruct', 'qwen2.feed_forward_length': '4864', 'general.architecture': 'qwen2', 'qwen2.attention.head_count': '14', 'tokenizer.ggml.bos_token_id': '151643', 'general.type': 'model', 'tokenizer.ggml.model': 'gpt2'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- messages[0]['content'] }}\n",
      "    {%- else %}\n",
      "        {{- 'You are a helpful assistant.' }}\n",
      "    {%- endif %}\n",
      "    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n",
      "    {%- else %}\n",
      "        {{- '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {{- '<|im_start|>' + message.role }}\n",
      "        {%- if message.content %}\n",
      "            {{- '\\n' + message.content }}\n",
      "        {%- endif %}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- if tool_call.function is defined %}\n",
      "                {%- set tool_call = tool_call.function %}\n",
      "            {%- endif %}\n",
      "            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n",
      "            {{- tool_call.name }}\n",
      "            {{- '\", \"arguments\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- '}\\n</tool_call>' }}\n",
      "        {%- endfor %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|endoftext|>\n",
      "llama_load_model_from_file: using device Metal (AMD Radeon Pro 5500M) - 8165 MiB free\n",
      "llama_model_loader: loaded meta data with 37 key-value pairs and 338 tensors from /Users/anna/.cache/huggingface/hub/models--bartowski--Qwen2.5-1.5B-Instruct-GGUF/snapshots/9eadc66189c7641e1ddd226b8267a9119b2ce2d4/./Qwen2.5-1.5B-Instruct-IQ2_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Qwen2.5 1.5B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Qwen2.5\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 1.5B\n",
      "llama_model_loader: - kv   6:                            general.license str              = apache-2.0\n",
      "llama_model_loader: - kv   7:                   general.base_model.count u32              = 1\n",
      "llama_model_loader: - kv   8:                  general.base_model.0.name str              = Qwen2.5 1.5B\n",
      "llama_model_loader: - kv   9:          general.base_model.0.organization str              = Qwen\n",
      "llama_model_loader: - kv  10:              general.base_model.0.repo_url str              = https://huggingface.co/Qwen/Qwen2.5-1.5B\n",
      "llama_model_loader: - kv  11:                               general.tags arr[str,2]       = [\"chat\", \"text-generation\"]\n",
      "llama_model_loader: - kv  12:                          general.languages arr[str,1]       = [\"en\"]\n",
      "llama_model_loader: - kv  13:                          qwen2.block_count u32              = 28\n",
      "llama_model_loader: - kv  14:                       qwen2.context_length u32              = 32768\n",
      "llama_model_loader: - kv  15:                     qwen2.embedding_length u32              = 1536\n",
      "llama_model_loader: - kv  16:                  qwen2.feed_forward_length u32              = 8960\n",
      "llama_model_loader: - kv  17:                 qwen2.attention.head_count u32              = 12\n",
      "llama_model_loader: - kv  18:              qwen2.attention.head_count_kv u32              = 2\n",
      "llama_model_loader: - kv  19:                       qwen2.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  20:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  21:                          general.file_type u32              = 29\n",
      "llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = qwen2\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,151387]  = [\" \", \" \", \"i n\", \" t\",...\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 151645\n",
      "llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 151643\n",
      "llama_model_loader: - kv  29:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  30:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  31:                    tokenizer.chat_template str              = {%- if tools %}\\n    {{- '<|im_start|>...\n",
      "llama_model_loader: - kv  32:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  33:                      quantize.imatrix.file str              = /models_out/Qwen2.5-1.5B-Instruct-GGU...\n",
      "llama_model_loader: - kv  34:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  35:             quantize.imatrix.entries_count i32              = 196\n",
      "llama_model_loader: - kv  36:              quantize.imatrix.chunks_count i32              = 128\n",
      "llama_model_loader: - type  f32:  141 tensors\n",
      "llama_model_loader: - type q4_K:   28 tensors\n",
      "llama_model_loader: - type q5_K:    1 tensors\n",
      "llama_model_loader: - type iq3_s:   31 tensors\n",
      "llama_model_loader: - type iq2_s:  137 tensors\n",
      "llm_load_vocab: control token: 151659 '<|fim_prefix|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151656 '<|video_pad|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151655 '<|image_pad|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151653 '<|vision_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151652 '<|vision_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151651 '<|quad_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151649 '<|box_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151648 '<|box_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151646 '<|object_ref_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151644 '<|im_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151661 '<|fim_suffix|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151647 '<|object_ref_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151660 '<|fim_middle|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151654 '<|vision_pad|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151650 '<|quad_start|>' is not marked as EOG\n",
      "llm_load_vocab: special tokens cache size = 22\n",
      "llm_load_vocab: token to piece cache size = 0.9310 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = qwen2\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 151936\n",
      "llm_load_print_meta: n_merges         = 151387\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 1536\n",
      "llm_load_print_meta: n_layer          = 28\n",
      "llm_load_print_meta: n_head           = 12\n",
      "llm_load_print_meta: n_head_kv        = 2\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 6\n",
      "llm_load_print_meta: n_embd_k_gqa     = 256\n",
      "llm_load_print_meta: n_embd_v_gqa     = 256\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 8960\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 1.5B\n",
      "llm_load_print_meta: model ftype      = IQ2_M - 2.7 bpw\n",
      "llm_load_print_meta: model params     = 1.54 B\n",
      "llm_load_print_meta: model size       = 567.54 MiB (3.08 BPW) \n",
      "llm_load_print_meta: general.name     = Qwen2.5 1.5B Instruct\n",
      "llm_load_print_meta: BOS token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: EOS token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: EOT token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: PAD token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 148848 ''\n",
      "llm_load_print_meta: FIM PRE token    = 151659 '<|fim_prefix|>'\n",
      "llm_load_print_meta: FIM SUF token    = 151661 '<|fim_suffix|>'\n",
      "llm_load_print_meta: FIM MID token    = 151660 '<|fim_middle|>'\n",
      "llm_load_print_meta: FIM PAD token    = 151662 '<|fim_pad|>'\n",
      "llm_load_print_meta: FIM REP token    = 151663 '<|repo_name|>'\n",
      "llm_load_print_meta: FIM SEP token    = 151664 '<|file_sep|>'\n",
      "llm_load_print_meta: EOG token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: EOG token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: EOG token        = 151662 '<|fim_pad|>'\n",
      "llm_load_print_meta: EOG token        = 151663 '<|repo_name|>'\n",
      "llm_load_print_meta: EOG token        = 151664 '<|file_sep|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q5_K) (and 338 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/29 layers to GPU\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =   567.54 MiB\n",
      "...........................................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 512\n",
      "llama_new_context_with_model: n_ctx_per_seq = 512\n",
      "llama_new_context_with_model: n_batch       = 512\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 0\n",
      "llama_new_context_with_model: freq_base     = 1000000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Intel(R) UHD Graphics 630\n",
      "ggml_metal_init: found device: AMD Radeon Pro 5500M\n",
      "ggml_metal_init: picking default device: AMD Radeon Pro 5500M\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   AMD Radeon Pro 5500M\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = false\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = false\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  =  8573.16 MB\n",
      "ggml_metal_init: loaded kernel_add                                 0x7fcde70b6330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row                             0x7fcde70b6a70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                 0x7fcde70b71b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row                             0x7fcde70b78f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                 0x7fcde70b8030 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row                             0x7fcde70b8aa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                 0x7fcde70b9510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row                             0x7fcde70ba060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                          0x7fcde70bb0a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                          0x7fcde70bb940 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                          0x7fcdd6abe3e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                          0x7fcdd6abf9b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                               0x7fcdd6ac0ba0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                             0x7fcde70bcaa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                               0x7fcdd6ac1da0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                0x7fcde7234630 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                0x7fcdf2352c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                             0x7fcdf233ba10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                0x7fcdd7e5d5e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                              0x7fcde5625660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                          0x7fcde5629050 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                        0x7fcde5629790 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                0x7fcde5629ed0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                              0x7fcde562a5b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                        0x7fcde72350a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                      0x7fcde70bdcc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                        0x7fcdf23533a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                      0x7fcde7235b10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                       0x7fcde70bf050 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                     0x7fcde72361f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                        0x7fcdd6ac2da0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                        0x7fcdd6ac3f30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                       0x7fcde72372a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                       0x7fcde70c03e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                       0x7fcde70c1730 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                       0x7fcde70c2d10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                       0x7fcde72384b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                       0x7fcde7239800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                       0x7fcde723ab50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                       0x7fcdd7e5e8b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                       0x7fcde70c40a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                       0x7fcde53833b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                    0x7fcde723beb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                     0x7fcde723d150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                    0x7fcdd6ac5a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                      0x7fcde723e470 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                      0x7fcdd6ac6d20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                      0x7fcdd6ac7de0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                      0x7fcde723f700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                     0x7fcde70c5420 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                     0x7fcdd6ac8680 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                        0x7fcdd6ac9850 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                            0x7fcdd6acaac0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                          0x7fcde72409d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                0x7fcde70c6770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                        0x7fcde70c79a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                        0x7fcde7241fb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                      0x7fcde70c8d60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                      0x7fcde562b500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                 0x7fcde70ca0a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                   0x7fcde7243350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                      0x7fcde562ca20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                     0x7fcde562dfe0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                     0x7fcde562f2f0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                     0x7fcdd6acbd50 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                     0x7fcdf2353ae0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                     0x7fcdf2354550 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                     0x7fcde72446d0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                     0x7fcdf2354fc0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                     0x7fcdf2355a30 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                     0x7fcdf2356ae0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                     0x7fcdd7e5fbb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                  0x7fcdd7e60ef0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                   0x7fcdd7e62420 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                  0x7fcdf2357380 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                    0x7fcde7245a30 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                    0x7fcde7246c80 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                    0x7fcdd7e634d0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                    0x7fcde70cb420 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                   0x7fcde7249110 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                   0x7fcde70cc930 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                   0x7fcdf23588b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                   0x7fcde70cdbe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                  0x7fcde70cf220 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                  0x7fcdf2359ac0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                  0x7fcde724a300 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                  0x7fcde724b840 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                  0x7fcde724cdd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                  0x7fcde724e130 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                  0x7fcde70d0580 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                  0x7fcde70d1b60 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                  0x7fcdd6accff0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                  0x7fcde70d3140 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32               0x7fcde70d44a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                0x7fcdf235ae40 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32               0x7fcde5630930 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                 0x7fcde724f470 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                 0x7fcdd6ace3a0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                 0x7fcdd6acf810 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                 0x7fcde5631c10 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                0x7fcde5633140 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                0x7fcde72509c0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_f32_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_f16_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q8_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q2_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q3_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q6_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_m_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_nl_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f32_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f16_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q8_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q2_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q3_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q6_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xs_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_m_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_nl_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_xs_f32              (not supported)\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                       0x7fcde70d5a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                       0x7fcdf235c3d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                       0x7fcdf235d6d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                       0x7fcdf235ea10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                          0x7fcdf235fda0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                          0x7fcde5634400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                      0x7fcdd6ad0e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                      0x7fcdd6ad20c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                         0x7fcdd6ad3450 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                             0x7fcdf2361110 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32              0x7fcdf2362400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                          0x7fcde5635790 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                 0x7fcde5636ab0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                0x7fcde70d6fb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                      0x7fcdf2363760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h64            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h80            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h96            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h112           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h128           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h256           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h256          (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128         0x7fcde5637e40 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128        0x7fcde70d8300 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128        0x7fcde7252010 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128        0x7fcde5639440 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128        0x7fcde70d9930 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128        0x7fcde70db200 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256         0x7fcde70dc820 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256        0x7fcde70ddba0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256        0x7fcde70df460 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256        0x7fcde70e0d20 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256        0x7fcde70e25e0 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256        0x7fcdf2364ae0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                         0x7fcde563aa50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                         0x7fcde72532c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                         0x7fcde7254600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                         0x7fcdd7e63f60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                        0x7fcdf2366390 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                        0x7fcdf23676f0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                        0x7fcde563bde0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                        0x7fcde563d3c0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                        0x7fcde563e9e0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                      0x7fcde563fd70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                              0x7fcde5641280 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                 0x7fcde5642560 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                0x7fcde5643880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                 0x7fcde7255940 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                 0x7fcde70e3e90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                            0x7fcde7256c60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                     0x7fcde7257fe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                     0x7fcdd7e65340 | th_max = 1024 | th_width =   32\n",
      "llama_kv_cache_init:        CPU KV buffer size =    14.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   14.00 MiB, K (f16):    7.00 MiB, V (f16):    7.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.58 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   299.75 MiB\n",
      "llama_new_context_with_model: graph nodes  = 986\n",
      "llama_new_context_with_model: graph splits = 450 (with bs=512), 1 (with bs=1)\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | AMX_INT8 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'quantize.imatrix.entries_count': '196', 'quantize.imatrix.file': '/models_out/Qwen2.5-1.5B-Instruct-GGUF/Qwen2.5-1.5B-Instruct.imatrix', 'quantize.imatrix.chunks_count': '128', 'tokenizer.chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are a helpful assistant.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- else %}\\n        {{- \\'<|im_start|>system\\\\nYou are a helpful assistant.<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.add_bos_token': 'false', 'tokenizer.ggml.padding_token_id': '151643', 'tokenizer.ggml.eos_token_id': '151645', 'qwen2.attention.layer_norm_rms_epsilon': '0.000001', 'general.basename': 'Qwen2.5', 'qwen2.attention.head_count_kv': '2', 'general.size_label': '1.5B', 'general.base_model.0.name': 'Qwen2.5 1.5B', 'qwen2.embedding_length': '1536', 'qwen2.context_length': '32768', 'qwen2.block_count': '28', 'general.base_model.0.organization': 'Qwen', 'tokenizer.ggml.pre': 'qwen2', 'general.base_model.count': '1', 'qwen2.rope.freq_base': '1000000.000000', 'general.quantization_version': '2', 'general.license': 'apache-2.0', 'general.base_model.0.repo_url': 'https://huggingface.co/Qwen/Qwen2.5-1.5B', 'general.file_type': '29', 'general.finetune': 'Instruct', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'general.name': 'Qwen2.5 1.5B Instruct', 'qwen2.feed_forward_length': '8960', 'general.architecture': 'qwen2', 'qwen2.attention.head_count': '12', 'tokenizer.ggml.bos_token_id': '151643', 'general.type': 'model', 'tokenizer.ggml.model': 'gpt2'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- messages[0]['content'] }}\n",
      "    {%- else %}\n",
      "        {{- 'You are a helpful assistant.' }}\n",
      "    {%- endif %}\n",
      "    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n",
      "    {%- else %}\n",
      "        {{- '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {{- '<|im_start|>' + message.role }}\n",
      "        {%- if message.content %}\n",
      "            {{- '\\n' + message.content }}\n",
      "        {%- endif %}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- if tool_call.function is defined %}\n",
      "                {%- set tool_call = tool_call.function %}\n",
      "            {%- endif %}\n",
      "            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n",
      "            {{- tool_call.name }}\n",
      "            {{- '\", \"arguments\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- '}\\n</tool_call>' }}\n",
      "        {%- endfor %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# NB this takes c.2mins \n",
    "\n",
    "# Small model\n",
    "llm_small = Llama.from_pretrained(\n",
    "\trepo_id=\"bartowski/Qwen2.5-0.5B-Instruct-GGUF\",\n",
    "\tfilename=\"Qwen2.5-0.5B-Instruct-IQ2_M.gguf\",\n",
    ")\n",
    "# Big model\n",
    "llm_big = Llama.from_pretrained(\n",
    "\trepo_id=\"bartowski/Qwen2.5-1.5B-Instruct-GGUF\",\n",
    "\tfilename=\"Qwen2.5-1.5B-Instruct-IQ2_M.gguf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output is noisy so we suppress it\n",
    "llm_small.verbose = False\n",
    "llm_big.verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are doing sentiment analysis on movie reviews. Classify the review as positive (0) or negative (1).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default context window size is 512 characters so we'll stick with that for now\n",
    "def truncate_review(review, max_length=512):\n",
    "    return review[:max_length]\n",
    "\n",
    "def sentiment_inference(llm_model, review, system_prompt):\n",
    "    response = llm_model.create_chat_completion(\n",
    "        temperature=1,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": truncate_review(review)},\n",
    "        ],\n",
    "    )\n",
    "    try:\n",
    "        return int(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    except ValueError:  # not an int\n",
    "        return -1  # sentinel value to use for \"model failed to return a valid label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_inference(llm_small, data[\"review\"].iloc[0], system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tiny = data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l8/nxqb7fdj4h79rs4h1s8k5zyr0000gn/T/ipykernel_18334/872085586.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_tiny['sentiment_llm_small'] = data_tiny['review'].apply(lambda review: sentiment_inference(llm_small, review, system_prompt))\n",
      "/var/folders/l8/nxqb7fdj4h79rs4h1s8k5zyr0000gn/T/ipykernel_18334/872085586.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_tiny['sentiment_llm_big'] = data_tiny['review'].apply(lambda review: sentiment_inference(llm_big, review, system_prompt))\n"
     ]
    }
   ],
   "source": [
    "data_tiny['sentiment_llm_small'] = data_tiny['review'].apply(lambda review: sentiment_inference(llm_small, review, system_prompt))\n",
    "data_tiny['sentiment_llm_big'] = data_tiny['review'].apply(lambda review: sentiment_inference(llm_big, review, system_prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tiny = data_tiny.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment_llm_small</th>\n",
       "      <th>sentiment_llm_big</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25534</th>\n",
       "      <td>This is quite possibly the worst film I have e...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33900</th>\n",
       "      <td>It is beyond me why two million Danish people ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7922</th>\n",
       "      <td>I saw this on Zone horror and fully expected i...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27153</th>\n",
       "      <td>The Happiest Days of Your Life showcases some ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>Clifton Webb is one of my favorites. However, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24916</th>\n",
       "      <td>This is one of my all time favorite movies, it...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33580</th>\n",
       "      <td>WHITE FIRE was recommended to me by a guy who ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>While possibly the stupidest, most tasteless, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>This movie sucked. The problem was not with th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35401</th>\n",
       "      <td>The second 'Mr. Eko' episode has somewhat less...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label  \\\n",
       "25534  This is quite possibly the worst film I have e...      1   \n",
       "33900  It is beyond me why two million Danish people ...      1   \n",
       "7922   I saw this on Zone horror and fully expected i...      0   \n",
       "27153  The Happiest Days of Your Life showcases some ...      0   \n",
       "2101   Clifton Webb is one of my favorites. However, ...      1   \n",
       "24916  This is one of my all time favorite movies, it...      0   \n",
       "33580  WHITE FIRE was recommended to me by a guy who ...      0   \n",
       "4463   While possibly the stupidest, most tasteless, ...      0   \n",
       "2834   This movie sucked. The problem was not with th...      1   \n",
       "35401  The second 'Mr. Eko' episode has somewhat less...      0   \n",
       "\n",
       "       sentiment_llm_small  sentiment_llm_big  \n",
       "25534                  0.0                0.0  \n",
       "33900                  0.0                0.0  \n",
       "7922                  -1.0                1.0  \n",
       "27153                 -1.0                0.0  \n",
       "2101                  -1.0                0.0  \n",
       "24916                 -1.0                1.0  \n",
       "33580                  0.0                0.0  \n",
       "4463                  -1.0                0.0  \n",
       "2834                   1.0               -1.0  \n",
       "35401                 -1.0                0.0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2\n",
      "Precision: 0.6\n",
      "Recall: 0.2\n",
      "F1 Score: 0.29333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anna/.pyenv/versions/3.12.7/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(data_tiny[\"label\"], data_tiny[\"sentiment_llm_small\"])\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "precision = precision_score(\n",
    "    data_tiny[\"label\"], data_tiny[\"sentiment_llm_small\"], average=\"weighted\"\n",
    ")\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(\n",
    "    data_tiny[\"label\"], data_tiny[\"sentiment_llm_small\"], average=\"weighted\"\n",
    ")\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "\n",
    "f1 = f1_score(data_tiny[\"label\"], data_tiny[\"sentiment_llm_small\"], average=\"weighted\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n",
      "Precision: 0.34285714285714286\n",
      "Recall: 0.4\n",
      "F1 Score: 0.36923076923076925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anna/.pyenv/versions/3.12.7/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(data_tiny[\"label\"], data_tiny[\"sentiment_llm_big\"])\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "precision = precision_score(\n",
    "    data_tiny[\"label\"], data_tiny[\"sentiment_llm_big\"], average=\"weighted\"\n",
    ")\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(\n",
    "    data_tiny[\"label\"], data_tiny[\"sentiment_llm_big\"], average=\"weighted\"\n",
    ")\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "\n",
    "f1 = f1_score(data_tiny[\"label\"], data_tiny[\"sentiment_llm_big\"], average=\"weighted\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jetbrains",
   "language": "python",
   "name": "jetbrains"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
