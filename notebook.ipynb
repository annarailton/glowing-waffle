{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import swifter\n",
    "from llama_cpp import Llama\n",
    "from langdetect import detect\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset \n",
    "\n",
    "Prepare the dataset for use, explaining your selection criteria for the subset you choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'train.jsonl', 'test': 'test.jsonl'}\n",
    "df = pd.read_json(\"hf://datasets/ajaykarthick/imdb-movie-reviews/\" + splits[\"train\"], lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ms Aparna Sen, the maker of Mr &amp; Mrs Iyer, dir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have seen this film only once, on TV, and it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was only fourteen when I first saw the Alien...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This marvelous short will hit home with everyo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you are 10 years old and never seen a movie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  Ms Aparna Sen, the maker of Mr & Mrs Iyer, dir...      0\n",
       "1  I have seen this film only once, on TV, and it...      0\n",
       "2  I was only fourteen when I first saw the Alien...      1\n",
       "3  This marvelous short will hit home with everyo...      0\n",
       "4  If you are 10 years old and never seen a movie...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should check that all these reviews are in English so will use the `langdetect` library to do that\n",
    "# N.B. this is quite slow(about 2 mins on my machine)\n",
    "# DO NOT RERUN\n",
    "# df[\"language\"] = df[\"review\"].apply(detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also add a column for the length of the review\n",
    "df[\"review_length\"] = df[\"review\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ms Aparna Sen, the maker of Mr &amp; Mrs Iyer, dir...</td>\n",
       "      <td>0</td>\n",
       "      <td>2408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have seen this film only once, on TV, and it...</td>\n",
       "      <td>0</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was only fourteen when I first saw the Alien...</td>\n",
       "      <td>1</td>\n",
       "      <td>1481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This marvelous short will hit home with everyo...</td>\n",
       "      <td>0</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you are 10 years old and never seen a movie...</td>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label  review_length\n",
       "0  Ms Aparna Sen, the maker of Mr & Mrs Iyer, dir...      0           2408\n",
       "1  I have seen this film only once, on TV, and it...      0            662\n",
       "2  I was only fourteen when I first saw the Alien...      1           1481\n",
       "3  This marvelous short will hit home with everyo...      0            830\n",
       "4  If you are 10 years old and never seen a movie...      1            238"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1312.303950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500006</td>\n",
       "      <td>993.920001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>970.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1598.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13704.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  review_length\n",
       "count  40000.000000   40000.000000\n",
       "mean       0.500000    1312.303950\n",
       "std        0.500006     993.920001\n",
       "min        0.000000      41.000000\n",
       "25%        0.000000     699.000000\n",
       "50%        0.500000     970.000000\n",
       "75%        1.000000    1598.000000\n",
       "max        1.000000   13704.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['review_length'], bins=30, edgecolor='black')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Review length')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_length_bin'] = pd.qcut(df['review_length'], q=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>review_length</th>\n",
       "      <th>review_length_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ms Aparna Sen, the maker of Mr &amp; Mrs Iyer, dir...</td>\n",
       "      <td>0</td>\n",
       "      <td>2408</td>\n",
       "      <td>(1829.0, 2583.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have seen this film only once, on TV, and it...</td>\n",
       "      <td>0</td>\n",
       "      <td>662</td>\n",
       "      <td>(503.0, 662.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was only fourteen when I first saw the Alien...</td>\n",
       "      <td>1</td>\n",
       "      <td>1481</td>\n",
       "      <td>(1412.0, 1829.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This marvelous short will hit home with everyo...</td>\n",
       "      <td>0</td>\n",
       "      <td>830</td>\n",
       "      <td>(739.0, 838.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you are 10 years old and never seen a movie...</td>\n",
       "      <td>1</td>\n",
       "      <td>238</td>\n",
       "      <td>(40.999, 503.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label  review_length  \\\n",
       "0  Ms Aparna Sen, the maker of Mr & Mrs Iyer, dir...      0           2408   \n",
       "1  I have seen this film only once, on TV, and it...      0            662   \n",
       "2  I was only fourteen when I first saw the Alien...      1           1481   \n",
       "3  This marvelous short will hit home with everyo...      0            830   \n",
       "4  If you are 10 years old and never seen a movie...      1            238   \n",
       "\n",
       "  review_length_bin  \n",
       "0  (1829.0, 2583.0]  \n",
       "1    (503.0, 662.0]  \n",
       "2  (1412.0, 1829.0]  \n",
       "3    (739.0, 838.0]  \n",
       "4   (40.999, 503.0]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'id'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the language of the reviews quickly\n",
    "# df['language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "      <th>review_length</th>\n",
       "      <th>review_length_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>.....whoops - looks like it's gonna cost you a...</td>\n",
       "      <td>0</td>\n",
       "      <td>id</td>\n",
       "      <td>730</td>\n",
       "      <td>(662.0, 739.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label language  \\\n",
       "24998  .....whoops - looks like it's gonna cost you a...      0       id   \n",
       "\n",
       "       review_length review_length_bin  \n",
       "24998            730    (662.0, 739.0]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at the examples where the language is not English\n",
    "# df[df[\"language\"] != \"en\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like all the reviews are in English so most immediate way of subsetting the data is by review_length and the label. Could go deep with something like https://pypi.org/project/py-readability-metrics/ but don't really want to overdo this. \n",
    "\n",
    "As for size of subset let's go with 1k for now (not sure what constraints of my machine are yet) and will review later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df,\n",
    "    df[[\"review_length\", \"label\"]],\n",
    "    stratify=df[[\"review_length_bin\", \"label\"]],\n",
    "    test_size=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39000.000000</td>\n",
       "      <td>39000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1312.617923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500006</td>\n",
       "      <td>994.535534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>970.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13704.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label  review_length\n",
       "count  39000.000000   39000.000000\n",
       "mean       0.500000    1312.617923\n",
       "std        0.500006     994.535534\n",
       "min        0.000000      41.000000\n",
       "25%        0.000000     699.000000\n",
       "50%        0.500000     970.000000\n",
       "75%        1.000000    1599.000000\n",
       "max        1.000000   13704.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK looks like that's worked, let's clean up and get onto the next bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>1306.31600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50025</td>\n",
       "      <td>970.20587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>98.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>702.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.50000</td>\n",
       "      <td>967.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1601.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>5948.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label  review_length\n",
       "count  1000.00000     1000.00000\n",
       "mean      0.50000     1306.31600\n",
       "std       0.50025      970.20587\n",
       "min       0.00000       98.00000\n",
       "25%       0.00000      702.00000\n",
       "50%       0.50000      967.00000\n",
       "75%       1.00000     1601.25000\n",
       "max       1.00000     5948.00000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_test[['review', 'label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement local inference\n",
    "\n",
    "- Choose optimal inference parameters (e.g., temperature, top_p, top_k) for each model\n",
    "- https://llama-cpp-python.readthedocs.io/en/latest/api-reference/#llama_cpp.Llama.create_chat_completion contains avaliable parameters \n",
    "- It doesn't look like I can batch up responses so will have to just keep hitting the model: https://github.com/abetlen/llama-cpp-python/issues/1529 \n",
    "- Unsure how clever I want to be here, will have to see how long it takes to get these responses out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuff to work out / ideas\n",
    "\n",
    "- [x] How to choose optimal inference params (do I need to do a bit of a hyperparameter tuning?)\n",
    "- [x] How do I run this stuff in batch mode: YOU CAN'T\n",
    "- [x] Do I want to try and mess around with context window? Feels like default is set like that for a reason. \n",
    "- [x] Need to make a decision RE temperature \n",
    "- [x] Make decision on metrics (what is usually used for sentiment analysis?) Probably don't want to overthink this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_load_model_from_file: using device Metal (AMD Radeon Pro 5500M) - 8176 MiB free\n",
      "llama_model_loader: loaded meta data with 37 key-value pairs and 290 tensors from /Users/anna/.cache/huggingface/hub/models--bartowski--Qwen2.5-0.5B-Instruct-GGUF/snapshots/41ba88dbac95fed2528c92514c131d73eb5a174b/./Qwen2.5-0.5B-Instruct-IQ2_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Qwen2.5 0.5B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Qwen2.5\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 0.5B\n",
      "llama_model_loader: - kv   6:                            general.license str              = apache-2.0\n",
      "llama_model_loader: - kv   7:                   general.base_model.count u32              = 1\n",
      "llama_model_loader: - kv   8:                  general.base_model.0.name str              = Qwen2.5 0.5B\n",
      "llama_model_loader: - kv   9:          general.base_model.0.organization str              = Qwen\n",
      "llama_model_loader: - kv  10:              general.base_model.0.repo_url str              = https://huggingface.co/Qwen/Qwen2.5-0.5B\n",
      "llama_model_loader: - kv  11:                               general.tags arr[str,2]       = [\"chat\", \"text-generation\"]\n",
      "llama_model_loader: - kv  12:                          general.languages arr[str,1]       = [\"en\"]\n",
      "llama_model_loader: - kv  13:                          qwen2.block_count u32              = 24\n",
      "llama_model_loader: - kv  14:                       qwen2.context_length u32              = 32768\n",
      "llama_model_loader: - kv  15:                     qwen2.embedding_length u32              = 896\n",
      "llama_model_loader: - kv  16:                  qwen2.feed_forward_length u32              = 4864\n",
      "llama_model_loader: - kv  17:                 qwen2.attention.head_count u32              = 14\n",
      "llama_model_loader: - kv  18:              qwen2.attention.head_count_kv u32              = 2\n",
      "llama_model_loader: - kv  19:                       qwen2.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  20:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  21:                          general.file_type u32              = 29\n",
      "llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = qwen2\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,151387]  = [\" \", \" \", \"i n\", \" t\",...\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 151645\n",
      "llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 151643\n",
      "llama_model_loader: - kv  29:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  30:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  31:                    tokenizer.chat_template str              = {%- if tools %}\\n    {{- '<|im_start|>...\n",
      "llama_model_loader: - kv  32:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  33:                      quantize.imatrix.file str              = /models_out/Qwen2.5-0.5B-Instruct-GGU...\n",
      "llama_model_loader: - kv  34:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  35:             quantize.imatrix.entries_count i32              = 168\n",
      "llama_model_loader: - kv  36:              quantize.imatrix.chunks_count i32              = 128\n",
      "llama_model_loader: - type  f32:  121 tensors\n",
      "llama_model_loader: - type q5_0:   24 tensors\n",
      "llama_model_loader: - type q8_0:    1 tensors\n",
      "llama_model_loader: - type iq4_nl:  120 tensors\n",
      "llama_model_loader: - type iq3_s:    3 tensors\n",
      "llama_model_loader: - type iq2_s:   21 tensors\n",
      "llm_load_vocab: control token: 151659 '<|fim_prefix|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151656 '<|video_pad|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151655 '<|image_pad|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151653 '<|vision_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151652 '<|vision_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151651 '<|quad_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151649 '<|box_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151648 '<|box_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151646 '<|object_ref_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151644 '<|im_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151661 '<|fim_suffix|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151647 '<|object_ref_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151660 '<|fim_middle|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151654 '<|vision_pad|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151650 '<|quad_start|>' is not marked as EOG\n",
      "llm_load_vocab: special tokens cache size = 22\n",
      "llm_load_vocab: token to piece cache size = 0.9310 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = qwen2\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 151936\n",
      "llm_load_print_meta: n_merges         = 151387\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 896\n",
      "llm_load_print_meta: n_layer          = 24\n",
      "llm_load_print_meta: n_head           = 14\n",
      "llm_load_print_meta: n_head_kv        = 2\n",
      "llm_load_print_meta: n_rot            = 64\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 64\n",
      "llm_load_print_meta: n_embd_head_v    = 64\n",
      "llm_load_print_meta: n_gqa            = 7\n",
      "llm_load_print_meta: n_embd_k_gqa     = 128\n",
      "llm_load_print_meta: n_embd_v_gqa     = 128\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 4864\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 1B\n",
      "llm_load_print_meta: model ftype      = IQ2_M - 2.7 bpw\n",
      "llm_load_print_meta: model params     = 494.03 M\n",
      "llm_load_print_meta: model size       = 307.70 MiB (5.22 BPW) \n",
      "llm_load_print_meta: general.name     = Qwen2.5 0.5B Instruct\n",
      "llm_load_print_meta: BOS token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: EOS token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: EOT token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: PAD token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 148848 ''\n",
      "llm_load_print_meta: FIM PRE token    = 151659 '<|fim_prefix|>'\n",
      "llm_load_print_meta: FIM SUF token    = 151661 '<|fim_suffix|>'\n",
      "llm_load_print_meta: FIM MID token    = 151660 '<|fim_middle|>'\n",
      "llm_load_print_meta: FIM PAD token    = 151662 '<|fim_pad|>'\n",
      "llm_load_print_meta: FIM REP token    = 151663 '<|repo_name|>'\n",
      "llm_load_print_meta: FIM SEP token    = 151664 '<|file_sep|>'\n",
      "llm_load_print_meta: EOG token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: EOG token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: EOG token        = 151662 '<|fim_pad|>'\n",
      "llm_load_print_meta: EOG token        = 151663 '<|repo_name|>'\n",
      "llm_load_print_meta: EOG token        = 151664 '<|file_sep|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q8_0) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/25 layers to GPU\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =   307.70 MiB\n",
      ".........................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 32768\n",
      "llama_new_context_with_model: n_ctx_per_seq = 32768\n",
      "llama_new_context_with_model: n_batch       = 512\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 0\n",
      "llama_new_context_with_model: freq_base     = 1000000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: AMD Radeon Pro 5500M\n",
      "ggml_metal_init: found device: Intel(R) UHD Graphics 630\n",
      "ggml_metal_init: picking default device: AMD Radeon Pro 5500M\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   AMD Radeon Pro 5500M\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = false\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = false\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  =  8573.16 MB\n",
      "ggml_metal_init: loaded kernel_add                                 0x7fd69ec181f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row                             0x7fd68e8bff80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                 0x7fd68d5674d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row                             0x7fd68e8c0ef0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                 0x7fd66feac9d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row                             0x7fd66feadc40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                 0x7fd68d786f90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row                             0x7fd69ec18ed0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                          0x7fd66feaeb30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                          0x7fd698e114f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                          0x7fd69ec19d90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                          0x7fd698e11c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                               0x7fd6aef0a880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                             0x7fd68e8c28f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                               0x7fd698e12dd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                0x7fd698e13840 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                0x7fd698b41850 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                             0x7fd698e140e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                0x7fd68e8c3190 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                              0x7fd69cf10750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                          0x7fd69cf116a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                        0x7fd698b42320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                0x7fd69ec1ab50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                              0x7fd69cf128d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                        0x7fd68e8c4330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                      0x7fd68e8c58f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                        0x7fd68e8c6c80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                      0x7fd68d787a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                       0x7fd68d567bb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                     0x7fd68d568db0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                        0x7fd68d569ea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                        0x7fd698b42a60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                       0x7fd68d56aed0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                       0x7fd69fa09030 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                       0x7fd68d56c070 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                       0x7fd698b43530 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                       0x7fd68d56d000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                       0x7fd68d56d790 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                       0x7fd698e152a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                       0x7fd698e165b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                       0x7fd69cf13a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                       0x7fd69cf14b90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                    0x7fd69cf15db0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                     0x7fd69ec1bed0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                    0x7fd698e17930 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                      0x7fd698e18bf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                      0x7fd68d56ed00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                      0x7fd698e19ea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                      0x7fd69cf172a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                     0x7fd68d788f30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                     0x7fd68d56ffd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                        0x7fd68d5712a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                            0x7fd698b444a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                          0x7fd68d78a140 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                0x7fd69cf17f30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                        0x7fd69cf19120 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                        0x7fd69cf1a2c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                      0x7fd698b45f50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                      0x7fd69ec1d150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                 0x7fd698b472a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                   0x7fd66feafc10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                      0x7fd69cf1b460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                     0x7fd69ec1e780 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                     0x7fd69ec1f950 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                     0x7fd66feb0680 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                     0x7fd698b47b40 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                     0x7fd698b48f80 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                     0x7fd698b4a270 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                     0x7fd698b4b610 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                     0x7fd69ec21530 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                     0x7fd68d78a820 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                     0x7fd68d78b4f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                  0x7fd68d572620 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                   0x7fd68d573b80 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                  0x7fd698b4cc10 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                    0x7fd69cf1c970 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                    0x7fd68d574ea0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                    0x7fd68d5763e0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                    0x7fd68d78c320 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                   0x7fd68d78ce80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                   0x7fd68d5776c0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                   0x7fd69cf1d540 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                   0x7fd68d578990 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                  0x7fd68d579d30 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                  0x7fd68d78e400 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                  0x7fd69ec228d0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                  0x7fd66feb1ce0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                  0x7fd69cf1e640 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                  0x7fd66feb3080 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                  0x7fd66feb4520 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                  0x7fd66feb5620 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                  0x7fd698b4ef70 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                  0x7fd66feb5f80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32               0x7fd66feb75c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                0x7fd69ec23ed0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32               0x7fd66feb86b0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                 0x7fd698b50150 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                 0x7fd698b51680 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                 0x7fd69cf1f7e0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                 0x7fd69cf20ba0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                0x7fd66feb97b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                0x7fd69cf21e60 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_f32_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_f16_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q8_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q2_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q3_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q6_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_m_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_nl_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f32_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f16_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q8_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q2_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q3_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q6_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xs_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_m_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_nl_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_xs_f32              (not supported)\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                       0x7fd698b52b90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                       0x7fd698e1bcd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                       0x7fd698e1d010 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                       0x7fd69ec25570 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                          0x7fd69ec26130 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                          0x7fd69cf23560 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                      0x7fd68e8c8040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                      0x7fd698e1e1e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                         0x7fd68e8c9330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                             0x7fd698e1f6b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32              0x7fd68d57b100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                          0x7fd68d5807b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                 0x7fd69cf248c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                0x7fd69cf25c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                      0x7fd69cf26f90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h64            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h80            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h96            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h112           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h128           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h256           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h256          (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128         0x7fd68e8ca880 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128        0x7fd69ec27140 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128        0x7fd69ec28870 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128        0x7fd698e209e0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128        0x7fd66feba6d0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128        0x7fd66febbd00 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256         0x7fd69cf28210 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256        0x7fd698e22290 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256        0x7fd698e23b60 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256        0x7fd68d582130 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256        0x7fd68d790360 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256        0x7fd68d791c30 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                         0x7fd66febce80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                         0x7fd69cf29070 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                         0x7fd698e25420 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                         0x7fd68d7934f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                        0x7fd68e8cb400 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                        0x7fd66febe010 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                        0x7fd68d5833e0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                        0x7fd68d584a10 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                        0x7fd68d585d50 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                      0x7fd69ec2a480 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                              0x7fd68d794860 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                 0x7fd69ec2b4c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                0x7fd69cf2a3b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                 0x7fd69ec2c800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                 0x7fd69ec2db20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                            0x7fd69cf2b6f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                     0x7fd69cf2ca20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                     0x7fd6af80d290 | th_max = 1024 | th_width =   32\n",
      "llama_kv_cache_init:        CPU KV buffer size =   384.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  384.00 MiB, K (f16):  192.00 MiB, V (f16):  192.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.58 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   967.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 846\n",
      "llama_new_context_with_model: graph splits = 386 (with bs=512), 1 (with bs=1)\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | AMX_INT8 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'quantize.imatrix.entries_count': '168', 'quantize.imatrix.file': '/models_out/Qwen2.5-0.5B-Instruct-GGUF/Qwen2.5-0.5B-Instruct.imatrix', 'quantize.imatrix.chunks_count': '128', 'tokenizer.chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are a helpful assistant.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- else %}\\n        {{- \\'<|im_start|>system\\\\nYou are a helpful assistant.<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.add_bos_token': 'false', 'tokenizer.ggml.padding_token_id': '151643', 'tokenizer.ggml.eos_token_id': '151645', 'qwen2.attention.layer_norm_rms_epsilon': '0.000001', 'general.basename': 'Qwen2.5', 'qwen2.attention.head_count_kv': '2', 'general.size_label': '0.5B', 'general.base_model.0.name': 'Qwen2.5 0.5B', 'qwen2.embedding_length': '896', 'qwen2.context_length': '32768', 'qwen2.block_count': '24', 'general.base_model.0.organization': 'Qwen', 'tokenizer.ggml.pre': 'qwen2', 'general.base_model.count': '1', 'qwen2.rope.freq_base': '1000000.000000', 'general.quantization_version': '2', 'general.license': 'apache-2.0', 'general.base_model.0.repo_url': 'https://huggingface.co/Qwen/Qwen2.5-0.5B', 'general.file_type': '29', 'general.finetune': 'Instruct', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'general.name': 'Qwen2.5 0.5B Instruct', 'qwen2.feed_forward_length': '4864', 'general.architecture': 'qwen2', 'qwen2.attention.head_count': '14', 'tokenizer.ggml.bos_token_id': '151643', 'general.type': 'model', 'tokenizer.ggml.model': 'gpt2'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- messages[0]['content'] }}\n",
      "    {%- else %}\n",
      "        {{- 'You are a helpful assistant.' }}\n",
      "    {%- endif %}\n",
      "    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n",
      "    {%- else %}\n",
      "        {{- '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {{- '<|im_start|>' + message.role }}\n",
      "        {%- if message.content %}\n",
      "            {{- '\\n' + message.content }}\n",
      "        {%- endif %}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- if tool_call.function is defined %}\n",
      "                {%- set tool_call = tool_call.function %}\n",
      "            {%- endif %}\n",
      "            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n",
      "            {{- tool_call.name }}\n",
      "            {{- '\", \"arguments\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- '}\\n</tool_call>' }}\n",
      "        {%- endfor %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# Small model\n",
    "llm_small = Llama.from_pretrained(\n",
    "\trepo_id=\"bartowski/Qwen2.5-0.5B-Instruct-GGUF\",\n",
    "\tfilename=\"Qwen2.5-0.5B-Instruct-IQ2_M.gguf\",\n",
    "    n_ctx=0  # uses model default (32768)\n",
    ")\n",
    "\n",
    "# Content length from model is `qwen2.context_length = 32768`\n",
    "# By default Llama defaults to 512 but since the average review length is ~1300 it's better to have this longer\n",
    "# Clearly better than sticking with the default of 512 and truncating reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_load_model_from_file: using device Metal (AMD Radeon Pro 5500M) - 8165 MiB free\n",
      "llama_model_loader: loaded meta data with 37 key-value pairs and 338 tensors from /Users/anna/.cache/huggingface/hub/models--bartowski--Qwen2.5-1.5B-Instruct-GGUF/snapshots/9eadc66189c7641e1ddd226b8267a9119b2ce2d4/./Qwen2.5-1.5B-Instruct-IQ2_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Qwen2.5 1.5B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Qwen2.5\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 1.5B\n",
      "llama_model_loader: - kv   6:                            general.license str              = apache-2.0\n",
      "llama_model_loader: - kv   7:                   general.base_model.count u32              = 1\n",
      "llama_model_loader: - kv   8:                  general.base_model.0.name str              = Qwen2.5 1.5B\n",
      "llama_model_loader: - kv   9:          general.base_model.0.organization str              = Qwen\n",
      "llama_model_loader: - kv  10:              general.base_model.0.repo_url str              = https://huggingface.co/Qwen/Qwen2.5-1.5B\n",
      "llama_model_loader: - kv  11:                               general.tags arr[str,2]       = [\"chat\", \"text-generation\"]\n",
      "llama_model_loader: - kv  12:                          general.languages arr[str,1]       = [\"en\"]\n",
      "llama_model_loader: - kv  13:                          qwen2.block_count u32              = 28\n",
      "llama_model_loader: - kv  14:                       qwen2.context_length u32              = 32768\n",
      "llama_model_loader: - kv  15:                     qwen2.embedding_length u32              = 1536\n",
      "llama_model_loader: - kv  16:                  qwen2.feed_forward_length u32              = 8960\n",
      "llama_model_loader: - kv  17:                 qwen2.attention.head_count u32              = 12\n",
      "llama_model_loader: - kv  18:              qwen2.attention.head_count_kv u32              = 2\n",
      "llama_model_loader: - kv  19:                       qwen2.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  20:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  21:                          general.file_type u32              = 29\n",
      "llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = qwen2\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,151387]  = [\" \", \" \", \"i n\", \" t\",...\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 151645\n",
      "llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 151643\n",
      "llama_model_loader: - kv  29:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  30:               tokenizer.ggml.add_bos_token bool             = false\n",
      "llama_model_loader: - kv  31:                    tokenizer.chat_template str              = {%- if tools %}\\n    {{- '<|im_start|>...\n",
      "llama_model_loader: - kv  32:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  33:                      quantize.imatrix.file str              = /models_out/Qwen2.5-1.5B-Instruct-GGU...\n",
      "llama_model_loader: - kv  34:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  35:             quantize.imatrix.entries_count i32              = 196\n",
      "llama_model_loader: - kv  36:              quantize.imatrix.chunks_count i32              = 128\n",
      "llama_model_loader: - type  f32:  141 tensors\n",
      "llama_model_loader: - type q4_K:   28 tensors\n",
      "llama_model_loader: - type q5_K:    1 tensors\n",
      "llama_model_loader: - type iq3_s:   31 tensors\n",
      "llama_model_loader: - type iq2_s:  137 tensors\n",
      "llm_load_vocab: control token: 151659 '<|fim_prefix|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151656 '<|video_pad|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151655 '<|image_pad|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151653 '<|vision_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151652 '<|vision_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151651 '<|quad_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151649 '<|box_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151648 '<|box_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151646 '<|object_ref_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151644 '<|im_start|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151661 '<|fim_suffix|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151647 '<|object_ref_end|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151660 '<|fim_middle|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151654 '<|vision_pad|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 151650 '<|quad_start|>' is not marked as EOG\n",
      "llm_load_vocab: special tokens cache size = 22\n",
      "llm_load_vocab: token to piece cache size = 0.9310 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = qwen2\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 151936\n",
      "llm_load_print_meta: n_merges         = 151387\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 1536\n",
      "llm_load_print_meta: n_layer          = 28\n",
      "llm_load_print_meta: n_head           = 12\n",
      "llm_load_print_meta: n_head_kv        = 2\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 6\n",
      "llm_load_print_meta: n_embd_k_gqa     = 256\n",
      "llm_load_print_meta: n_embd_v_gqa     = 256\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 8960\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 2\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 1.5B\n",
      "llm_load_print_meta: model ftype      = IQ2_M - 2.7 bpw\n",
      "llm_load_print_meta: model params     = 1.54 B\n",
      "llm_load_print_meta: model size       = 567.54 MiB (3.08 BPW) \n",
      "llm_load_print_meta: general.name     = Qwen2.5 1.5B Instruct\n",
      "llm_load_print_meta: BOS token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: EOS token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: EOT token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: PAD token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 148848 ''\n",
      "llm_load_print_meta: FIM PRE token    = 151659 '<|fim_prefix|>'\n",
      "llm_load_print_meta: FIM SUF token    = 151661 '<|fim_suffix|>'\n",
      "llm_load_print_meta: FIM MID token    = 151660 '<|fim_middle|>'\n",
      "llm_load_print_meta: FIM PAD token    = 151662 '<|fim_pad|>'\n",
      "llm_load_print_meta: FIM REP token    = 151663 '<|repo_name|>'\n",
      "llm_load_print_meta: FIM SEP token    = 151664 '<|file_sep|>'\n",
      "llm_load_print_meta: EOG token        = 151643 '<|endoftext|>'\n",
      "llm_load_print_meta: EOG token        = 151645 '<|im_end|>'\n",
      "llm_load_print_meta: EOG token        = 151662 '<|fim_pad|>'\n",
      "llm_load_print_meta: EOG token        = 151663 '<|repo_name|>'\n",
      "llm_load_print_meta: EOG token        = 151664 '<|file_sep|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q5_K) (and 338 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/29 layers to GPU\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =   567.54 MiB\n",
      "...........................................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 32768\n",
      "llama_new_context_with_model: n_ctx_per_seq = 32768\n",
      "llama_new_context_with_model: n_batch       = 512\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 0\n",
      "llama_new_context_with_model: freq_base     = 1000000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: AMD Radeon Pro 5500M\n",
      "ggml_metal_init: found device: Intel(R) UHD Graphics 630\n",
      "ggml_metal_init: picking default device: AMD Radeon Pro 5500M\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   AMD Radeon Pro 5500M\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = false\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = false\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  =  8573.16 MB\n",
      "ggml_metal_init: loaded kernel_add                                 0x7fd66febe5d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row                             0x7fd68e8cd140 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                 0x7fd69cd04410 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row                             0x7fd69cd04b50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                 0x7fd66febedf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row                             0x7fd66fec0000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                 0x7fd69cd05290 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row                             0x7fd661a50600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                          0x7fd66fec0df0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                          0x7fd69cf2ddc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                          0x7fd698e26430 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                          0x7fd698e26b70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                               0x7fd69cd05d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                             0x7fd69cd06770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                               0x7fd66fec1ff0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                0x7fd69cf2e500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                0x7fd68e8cdd10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                             0x7fd68e8ce3f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                0x7fd69cf2ec40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                              0x7fd661a51bc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                          0x7fd69ec2e9a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                        0x7fd661a52ed0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                0x7fd661a54220 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                              0x7fd661a55520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                        0x7fd69cf2f320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                      0x7fd69cd071e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                        0x7fd69cd080a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                      0x7fd698b53ba0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                       0x7fd69cd08af0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                     0x7fd69cf2fd90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                        0x7fd698b542e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                        0x7fd69ef0d5b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                       0x7fd698e275e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                       0x7fd698b54690 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                       0x7fd698e283e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                       0x7fd66fec2e60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                       0x7fd66fec3f80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                       0x7fd69ec2f0e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                       0x7fd698a05b20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                       0x7fd69fe050e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                       0x7fd69cd09c90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                       0x7fd69cd0b820 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                    0x7fd69ec2f820 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                     0x7fd69cd0c480 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                    0x7fd66fec51a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                      0x7fd698e28e50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                      0x7fd69cf30470 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                      0x7fd69cd0d700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                      0x7fd66fec6ea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                     0x7fd66fec7f90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                     0x7fd66fec9000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                        0x7fd66feca060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                            0x7fd66fecab30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                          0x7fd66fecc660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                0x7fd69cf30b50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                        0x7fd698e299a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                        0x7fd69ec30620 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                      0x7fd698b54dd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                      0x7fd69ec31090 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                 0x7fd69cd0e900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                   0x7fd69cd0f680 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                      0x7fd68e8d0e50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                     0x7fd698e2a860 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                     0x7fd69cf315c0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                     0x7fd69ec31b00 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                     0x7fd69cf32030 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                     0x7fd69cf32fc0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                     0x7fd698e2baa0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                     0x7fd66fecdc00 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                     0x7fd66feceea0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                     0x7fd66fed03d0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                     0x7fd698e2cd40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                  0x7fd66fed0df0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                   0x7fd698b55840 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                  0x7fd698b562b0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                    0x7fd698e2e080 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                    0x7fd69cd102a0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                    0x7fd69cd117d0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                    0x7fd68e8d2630 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                   0x7fd66fed2270 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                   0x7fd66fed3400 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                   0x7fd69ec32c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                   0x7fd69ec334d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                  0x7fd698b56d20 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                  0x7fd698b57790 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                  0x7fd698b58200 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                  0x7fd698e2f350 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                  0x7fd698e30940 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                  0x7fd661a56910 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                  0x7fd69cd132e0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                  0x7fd661a57940 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                  0x7fd66fed4650 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                  0x7fd698b58c70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32               0x7fd69cd14920 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                0x7fd68e8d3b80 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32               0x7fd68e8d5140 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                 0x7fd66fed5370 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                 0x7fd69cf344d0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                 0x7fd698b596e0 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                 0x7fd69ec34ea0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                0x7fd698b5aa00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                0x7fd698e31ce0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_f32_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_f16_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q8_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q2_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q3_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q6_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_m_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_nl_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f32_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f16_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q8_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q2_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q3_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q6_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xs_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_m_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_nl_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_xs_f32              (not supported)\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                       0x7fd69cf35120 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                       0x7fd68e8d6b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                       0x7fd68e8d7e40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                       0x7fd68e8d9180 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                          0x7fd68e8da510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                          0x7fd68e8db850 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                      0x7fd69cd15e80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                      0x7fd69cd171c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                         0x7fd69cf363f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                             0x7fd69ec363f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32              0x7fd69cd18560 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                          0x7fd69cd19850 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                 0x7fd69cd1abb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                0x7fd66fed6280 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                      0x7fd69cf37780 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h64            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h80            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h96            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h112           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h128           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h256           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h256          (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128         0x7fd698e32bd0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128        0x7fd66fed7580 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128        0x7fd698e34200 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128        0x7fd69ec37720 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128        0x7fd69cf38ae0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128        0x7fd698e35200 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256         0x7fd69cf39da0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256        0x7fd69ec2d680 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256        0x7fd661a58f60 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256        0x7fd69cf3ac40 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256        0x7fd661a5a7c0 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256        0x7fd66fed8c80 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                         0x7fd66197a8e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                         0x7fd661a5bac0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                         0x7fd661904080 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                         0x7fd69ef0d960 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                        0x7fd69fe061c0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                        0x7fd698b5c270 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                        0x7fd698e36340 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                        0x7fd66feda0a0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                        0x7fd69cd1d670 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                      0x7fd698b5d6f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                              0x7fd68e8dcc10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                 0x7fd69cd1df50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                0x7fd661905840 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                 0x7fd69fe06e80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                 0x7fd661905f20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                            0x7fd661906ac0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                     0x7fd698b5e7e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                     0x7fd661907df0 | th_max = 1024 | th_width =   32\n",
      "llama_kv_cache_init:        CPU KV buffer size =   896.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  896.00 MiB, K (f16):  448.00 MiB, V (f16):  448.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.58 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   844.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 986\n",
      "llama_new_context_with_model: graph splits = 450 (with bs=512), 1 (with bs=1)\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | AMX_INT8 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'quantize.imatrix.entries_count': '196', 'quantize.imatrix.file': '/models_out/Qwen2.5-1.5B-Instruct-GGUF/Qwen2.5-1.5B-Instruct.imatrix', 'quantize.imatrix.chunks_count': '128', 'tokenizer.chat_template': '{%- if tools %}\\n    {{- \\'<|im_start|>system\\\\n\\' }}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- messages[0][\\'content\\'] }}\\n    {%- else %}\\n        {{- \\'You are a helpful assistant.\\' }}\\n    {%- endif %}\\n    {{- \"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> XML tags:\\\\n<tools>\" }}\\n    {%- for tool in tools %}\\n        {{- \"\\\\n\" }}\\n        {{- tool | tojson }}\\n    {%- endfor %}\\n    {{- \"\\\\n</tools>\\\\n\\\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\\\n<tool_call>\\\\n{{\\\\\"name\\\\\": <function-name>, \\\\\"arguments\\\\\": <args-json-object>}}\\\\n</tool_call><|im_end|>\\\\n\" }}\\n{%- else %}\\n    {%- if messages[0][\\'role\\'] == \\'system\\' %}\\n        {{- \\'<|im_start|>system\\\\n\\' + messages[0][\\'content\\'] + \\'<|im_end|>\\\\n\\' }}\\n    {%- else %}\\n        {{- \\'<|im_start|>system\\\\nYou are a helpful assistant.<|im_end|>\\\\n\\' }}\\n    {%- endif %}\\n{%- endif %}\\n{%- for message in messages %}\\n    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\\n        {{- \\'<|im_start|>\\' + message.role + \\'\\\\n\\' + message.content + \\'<|im_end|>\\' + \\'\\\\n\\' }}\\n    {%- elif message.role == \"assistant\" %}\\n        {{- \\'<|im_start|>\\' + message.role }}\\n        {%- if message.content %}\\n            {{- \\'\\\\n\\' + message.content }}\\n        {%- endif %}\\n        {%- for tool_call in message.tool_calls %}\\n            {%- if tool_call.function is defined %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {{- \\'\\\\n<tool_call>\\\\n{\"name\": \"\\' }}\\n            {{- tool_call.name }}\\n            {{- \\'\", \"arguments\": \\' }}\\n            {{- tool_call.arguments | tojson }}\\n            {{- \\'}\\\\n</tool_call>\\' }}\\n        {%- endfor %}\\n        {{- \\'<|im_end|>\\\\n\\' }}\\n    {%- elif message.role == \"tool\" %}\\n        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\\n            {{- \\'<|im_start|>user\\' }}\\n        {%- endif %}\\n        {{- \\'\\\\n<tool_response>\\\\n\\' }}\\n        {{- message.content }}\\n        {{- \\'\\\\n</tool_response>\\' }}\\n        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\\n            {{- \\'<|im_end|>\\\\n\\' }}\\n        {%- endif %}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|im_start|>assistant\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.add_bos_token': 'false', 'tokenizer.ggml.padding_token_id': '151643', 'tokenizer.ggml.eos_token_id': '151645', 'qwen2.attention.layer_norm_rms_epsilon': '0.000001', 'general.basename': 'Qwen2.5', 'qwen2.attention.head_count_kv': '2', 'general.size_label': '1.5B', 'general.base_model.0.name': 'Qwen2.5 1.5B', 'qwen2.embedding_length': '1536', 'qwen2.context_length': '32768', 'qwen2.block_count': '28', 'general.base_model.0.organization': 'Qwen', 'tokenizer.ggml.pre': 'qwen2', 'general.base_model.count': '1', 'qwen2.rope.freq_base': '1000000.000000', 'general.quantization_version': '2', 'general.license': 'apache-2.0', 'general.base_model.0.repo_url': 'https://huggingface.co/Qwen/Qwen2.5-1.5B', 'general.file_type': '29', 'general.finetune': 'Instruct', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'general.name': 'Qwen2.5 1.5B Instruct', 'qwen2.feed_forward_length': '8960', 'general.architecture': 'qwen2', 'qwen2.attention.head_count': '12', 'tokenizer.ggml.bos_token_id': '151643', 'general.type': 'model', 'tokenizer.ggml.model': 'gpt2'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- messages[0]['content'] }}\n",
      "    {%- else %}\n",
      "        {{- 'You are a helpful assistant.' }}\n",
      "    {%- endif %}\n",
      "    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n",
      "    {%- else %}\n",
      "        {{- '<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {{- '<|im_start|>' + message.role }}\n",
      "        {%- if message.content %}\n",
      "            {{- '\\n' + message.content }}\n",
      "        {%- endif %}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- if tool_call.function is defined %}\n",
      "                {%- set tool_call = tool_call.function %}\n",
      "            {%- endif %}\n",
      "            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n",
      "            {{- tool_call.name }}\n",
      "            {{- '\", \"arguments\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- '}\\n</tool_call>' }}\n",
      "        {%- endfor %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# Big model\n",
    "llm_big = Llama.from_pretrained(\n",
    "\trepo_id=\"bartowski/Qwen2.5-1.5B-Instruct-GGUF\",\n",
    "\tfilename=\"Qwen2.5-1.5B-Instruct-IQ2_M.gguf\",\n",
    "    n_ctx=0  # uses model default (32768)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output is noisy so we suppress it\n",
    "llm_small.verbose = False\n",
    "llm_big.verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_baseline = \"You are doing sentiment analysis on movie reviews. Classify the review as positive (0) or negative (1).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTINAL_VALUE = -2\n",
    "\n",
    "def sentiment_inference(\n",
    "    llm_model: Llama,\n",
    "    review: str,\n",
    "    system_prompt: str,\n",
    "    temperature: float = 0.2,  # llama default\n",
    "    top_p: float = 0.95,       # llama default\n",
    "    top_k: int = 40,           # llama default\n",
    ") -> int:\n",
    "    response = llm_model.create_chat_completion(\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": review},\n",
    "        ],\n",
    "    )\n",
    "    try:\n",
    "        return int(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    except ValueError:  # not an int\n",
    "        return SENTINAL_VALUE  # sentinel value to use for \"model failed to return a valid label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_inference(llm_small, data[\"review\"].iloc[0], system_prompt_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tiny = data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l8/nxqb7fdj4h79rs4h1s8k5zyr0000gn/T/ipykernel_9143/1161222981.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_tiny['sentiment_llm_small'] = data_tiny['review'].apply(lambda review: sentiment_inference(llm_small, review, system_prompt_baseline))\n",
      "/var/folders/l8/nxqb7fdj4h79rs4h1s8k5zyr0000gn/T/ipykernel_9143/1161222981.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_tiny['sentiment_llm_big'] = data_tiny['review'].apply(lambda review: sentiment_inference(llm_big, review, system_prompt_baseline))\n"
     ]
    }
   ],
   "source": [
    "data_tiny['sentiment_llm_small'] = data_tiny['review'].apply(lambda review: sentiment_inference(llm_small, review, system_prompt_baseline))\n",
    "data_tiny['sentiment_llm_big'] = data_tiny['review'].apply(lambda review: sentiment_inference(llm_big, review, system_prompt_baseline))\n",
    "\n",
    "# 10 examples took 40s\n",
    "# 30 examples took 2 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23564</th>\n",
       "      <td>Many of these other viewers complain that the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29363</th>\n",
       "      <td>When A Stranger Calls is actually a pretty goo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5085</th>\n",
       "      <td>I find it difficult to comprehend what makes v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>For once a sequel to 'The Karate Kid' without ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23032</th>\n",
       "      <td>I consider this film one of the worst in the N...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25153</th>\n",
       "      <td>I actually saw this movie at a cinema. At the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6950</th>\n",
       "      <td>Having just finished Cronicles of the Heroic K...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20656</th>\n",
       "      <td>This is one of my favourite Disney films. It h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12852</th>\n",
       "      <td>'For a Squadron Leader - normally the only guy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>I can't figure Al Pacino out. I watch him in t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9483</th>\n",
       "      <td>I have recently watched this movie twice, and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15240</th>\n",
       "      <td>This is one of those movies that make better t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>What a strange atmosphere is being created in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32527</th>\n",
       "      <td>Some genre films need to be dressed up. This o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8049</th>\n",
       "      <td>So fortunate were we to see this fantastic fil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22774</th>\n",
       "      <td>Worst movie ever!! Its not clever or funny or ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18377</th>\n",
       "      <td>This (extremely)low-budget movie is compared t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20703</th>\n",
       "      <td>I just saw this film at the 2001 Toronto inter...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13177</th>\n",
       "      <td>So, as far as I gather, this episode is trying...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21716</th>\n",
       "      <td>Who in the world told Harrison Ford that this ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12461</th>\n",
       "      <td>I chuckled a few times during this movie. I la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13866</th>\n",
       "      <td>What on earth has become of our dear Ramu? Is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18853</th>\n",
       "      <td>What can you say about a grainy, poorly filmed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19844</th>\n",
       "      <td>If this is film noir, then noir must be French...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Horrible Script, which was apparently directed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>I voted 3 for this movie because it looks grea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10244</th>\n",
       "      <td>I was pleasantly surprised I quite liked this ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>It's a strange, yet somehow impressive story, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8822</th>\n",
       "      <td>This story has held a special place in my hear...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>So what's the big fuss out of making an INDIAN...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label\n",
       "23564  Many of these other viewers complain that the ...      0\n",
       "29363  When A Stranger Calls is actually a pretty goo...      0\n",
       "5085   I find it difficult to comprehend what makes v...      1\n",
       "4197   For once a sequel to 'The Karate Kid' without ...      0\n",
       "23032  I consider this film one of the worst in the N...      1\n",
       "25153  I actually saw this movie at a cinema. At the ...      1\n",
       "6950   Having just finished Cronicles of the Heroic K...      0\n",
       "20656  This is one of my favourite Disney films. It h...      0\n",
       "12852  'For a Squadron Leader - normally the only guy...      0\n",
       "62     I can't figure Al Pacino out. I watch him in t...      1\n",
       "9483   I have recently watched this movie twice, and ...      1\n",
       "15240  This is one of those movies that make better t...      0\n",
       "1758   What a strange atmosphere is being created in ...      0\n",
       "32527  Some genre films need to be dressed up. This o...      0\n",
       "8049   So fortunate were we to see this fantastic fil...      0\n",
       "22774  Worst movie ever!! Its not clever or funny or ...      1\n",
       "18377  This (extremely)low-budget movie is compared t...      1\n",
       "20703  I just saw this film at the 2001 Toronto inter...      0\n",
       "13177  So, as far as I gather, this episode is trying...      1\n",
       "21716  Who in the world told Harrison Ford that this ...      1\n",
       "12461  I chuckled a few times during this movie. I la...      1\n",
       "13866  What on earth has become of our dear Ramu? Is ...      1\n",
       "18853  What can you say about a grainy, poorly filmed...      1\n",
       "19844  If this is film noir, then noir must be French...      1\n",
       "30     Horrible Script, which was apparently directed...      1\n",
       "4885   I voted 3 for this movie because it looks grea...      1\n",
       "10244  I was pleasantly surprised I quite liked this ...      0\n",
       "992    It's a strange, yet somehow impressive story, ...      0\n",
       "8822   This story has held a special place in my hear...      0\n",
       "407    So what's the big fuss out of making an INDIAN...      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43333333333333335\n",
      "Precision: 0.23214285714285715\n",
      "Recall: 0.43333333333333335\n",
      "F1 Score: 0.3023255813953488\n",
      "Confusion matrix:\n",
      "[[ 0  0  0]\n",
      " [ 2 13  0]\n",
      " [ 0 15  0]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.46      0.87      0.60        15\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.43        30\n",
      "   macro avg       0.15      0.29      0.20        30\n",
      "weighted avg       0.23      0.43      0.30        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Accuracy: {accuracy_score(data_tiny[\"label\"], data_tiny[\"sentiment_llm_small\"])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Precision: {precision_score(\n",
    "    data_tiny[\"label\"], data_tiny[\"sentiment_llm_small\"], average=\"weighted\", zero_division=0\n",
    ")}\"\n",
    ")\n",
    "print(\n",
    "    f\"Recall: {recall_score(\n",
    "    data_tiny[\"label\"], data_tiny[\"sentiment_llm_small\"], average=\"weighted\", zero_division=0\n",
    ")}\"\n",
    ")\n",
    "print(\n",
    "    f\"F1 Score: {f1_score(data_tiny[\"label\"], data_tiny[\"sentiment_llm_small\"], average=\"weighted\")}\"\n",
    ")\n",
    "print(\n",
    "    f\"Confusion matrix:\\n{confusion_matrix(data_tiny['label'], data_tiny['sentiment_llm_small'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Classification report:\\n{classification_report(data_tiny['label'], data_tiny['sentiment_llm_small'], zero_division=0)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4666666666666667\n",
      "Precision: 0.2413793103448276\n",
      "Recall: 0.4666666666666667\n",
      "F1 Score: 0.3181818181818182\n",
      "Confusion matrix:\n",
      "[[ 0 15]\n",
      " [ 1 14]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.46      0.87      0.60        15\n",
      "           1       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.43        30\n",
      "   macro avg       0.15      0.29      0.20        30\n",
      "weighted avg       0.23      0.43      0.30        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Accuracy: {accuracy_score(data_tiny[\"label\"], data_tiny[\"sentiment_llm_big\"])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Precision: {precision_score(\n",
    "    data_tiny[\"label\"], data_tiny[\"sentiment_llm_big\"], average=\"weighted\", zero_division=0\n",
    ")}\"\n",
    ")\n",
    "print(\n",
    "    f\"Recall: {recall_score(\n",
    "    data_tiny[\"label\"], data_tiny[\"sentiment_llm_big\"], average=\"weighted\", zero_division=0\n",
    ")}\"\n",
    ")\n",
    "print(\n",
    "    f\"F1 Score: {f1_score(data_tiny[\"label\"], data_tiny[\"sentiment_llm_big\"], average=\"weighted\")}\"\n",
    ")\n",
    "print(\n",
    "    f\"Confusion matrix:\\n{confusion_matrix(data_tiny['label'], data_tiny['sentiment_llm_big'])}\"\n",
    ")\n",
    "print(\n",
    "    f\"Classification report:\\n{classification_report(data_tiny['label'], data_tiny['sentiment_llm_small'], zero_division=0)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concurrency?\n",
    "\n",
    "We are running super slowly so going to try and speed up with some concurrency\n",
    "\n",
    "(This section turned out to be cursed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# This crashes the kernel #\n",
    "###########################\n",
    "\n",
    "\n",
    "# def apply_sentiment_inference(args):\n",
    "#     review, llm_model, system_prompt, temperature, top_p, top_k = args\n",
    "\n",
    "#     return sentiment_inference(\n",
    "#         llm_model=llm_model,\n",
    "#         review=review,\n",
    "#         system_prompt=system_prompt,\n",
    "#         temperature=temperature,\n",
    "#         top_p=top_p,\n",
    "#         top_k=top_k,\n",
    "#     )\n",
    "\n",
    "\n",
    "# # Prepare arguments for parallel processing\n",
    "# temperature = 0.2\n",
    "# top_p = 0.95\n",
    "# top_k = 40\n",
    "# args_small = [\n",
    "#     (review, llm_small, system_prompt_baseline, temperature, top_p, top_k) for review in data_tiny[\"review\"]\n",
    "# ]\n",
    "# args_big = [(review, llm_big, system_prompt_baseline, temperature, top_p, top_k) for review in data_tiny[\"review\"]]\n",
    "\n",
    "# # Apply sentiment_inference in parallel\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     data_tiny[\"sentiment_llm_small_1\"] = list(\n",
    "#         executor.map(apply_sentiment_inference, args_small)\n",
    "#     )\n",
    "#     data_tiny[\"sentiment_llm_big_1\"] = list(executor.map(apply_sentiment_inference, args_big))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577811acc42746a3948629459da05994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l8/nxqb7fdj4h79rs4h1s8k5zyr0000gn/T/ipykernel_10195/4168693646.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_tiny['sentiment_llm_small'] = data_tiny['review'].swifter.apply(lambda review: sentiment_inference(llm_small, review, system_prompt_baseline))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12266ff6ce8a4d968f975f7fcd344de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l8/nxqb7fdj4h79rs4h1s8k5zyr0000gn/T/ipykernel_10195/4168693646.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_tiny['sentiment_llm_big'] = data_tiny['review'].swifter.apply(lambda review: sentiment_inference(llm_big, review, system_prompt_baseline))\n"
     ]
    }
   ],
   "source": [
    "# # Trying out using swifter\n",
    "# import swifter \n",
    "\n",
    "# data_tiny['sentiment_llm_small'] = data_tiny['review'].swifter.apply(lambda review: sentiment_inference(llm_small, review, system_prompt_baseline))\n",
    "# data_tiny['sentiment_llm_big'] = data_tiny['review'].swifter.apply(lambda review: sentiment_inference(llm_big, review, system_prompt_baseline))\n",
    "\n",
    "# # 30 examples took 3 mins (lol) - turns out it's no better if the columns are strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TokenizationError",
     "evalue": "Object <function <lambda> at 0x11cdec7c0> cannot be deterministically hashed. See https://docs.dask.org/en/latest/custom-collections.html#implementing-deterministic-hashing for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTokenizationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/dask/tokenize.py:208\u001b[0m, in \u001b[0;36mnormalize_object\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_normalize_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/dask/tokenize.py:253\u001b[0m, in \u001b[0;36m_normalize_pickle\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pik \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[43m_maybe_raise_nondeterministic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFailed to tokenize deterministically\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     pik \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/dask/tokenize.py:89\u001b[0m, in \u001b[0;36m_maybe_raise_nondeterministic\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mor\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenize.ensure-deterministic\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TokenizationError(msg)\n",
      "\u001b[0;31mTokenizationError\u001b[0m: Failed to tokenize deterministically",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTokenizationError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Apply the sentiment_inference function in parallel using Dask\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProgressBar():\n\u001b[0;32m---> 13\u001b[0m     ddf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_llm_small\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mddf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_partitions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_tiny\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_tiny\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreview\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdask_sentiment_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreview\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt_baseline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     ddf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_llm_big\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ddf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap_partitions(\u001b[38;5;28;01mlambda\u001b[39;00m data_tiny: data_tiny\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m review: dask_sentiment_inference(review, llm_big, system_prompt_baseline), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Compute the results\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/dask_expr/_collection.py:1107\u001b[0m, in \u001b[0;36mFrameBase.map_partitions\u001b[0;34m(self, func, meta, enforce_metadata, transform_divisions, clear_divisions, align_dataframes, parent_meta, *args, **kwargs)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;129m@insert_meta_param_description\u001b[39m(pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_partitions\u001b[39m(\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    994\u001b[0m ):\n\u001b[1;32m    995\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply a Python function to each partition\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;124;03m    None as the division.\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_partitions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform_divisions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_divisions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclear_divisions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclear_divisions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign_dataframes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign_dataframes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparent_meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/dask_expr/_collection.py:6266\u001b[0m, in \u001b[0;36mmap_partitions\u001b[0;34m(func, meta, enforce_metadata, transform_divisions, clear_divisions, align_dataframes, parent_meta, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m align_dataframes:\n\u001b[1;32m   6259\u001b[0m     \u001b[38;5;66;03m# TODO: Handle alignment?\u001b[39;00m\n\u001b[1;32m   6260\u001b[0m     \u001b[38;5;66;03m# Perhaps we only handle the case that all `Expr` operands\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6263\u001b[0m     \u001b[38;5;66;03m# will need to call `Repartition` on operands that are not\u001b[39;00m\n\u001b[1;32m   6264\u001b[0m     \u001b[38;5;66;03m# aligned with `self.expr`.\u001b[39;00m\n\u001b[1;32m   6265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n\u001b[0;32m-> 6266\u001b[0m new_expr \u001b[38;5;241m=\u001b[39m \u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMapPartitions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6267\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6270\u001b[0m \u001b[43m    \u001b[49m\u001b[43menforce_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_divisions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclear_divisions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6273\u001b[0m \u001b[43m    \u001b[49m\u001b[43malign_dataframes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoken\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6277\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6278\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_collection(new_expr)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/dask_expr/_core.py:59\u001b[0m, in \u001b[0;36mExpr.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m inst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m     58\u001b[0m inst\u001b[38;5;241m.\u001b[39moperands \u001b[38;5;241m=\u001b[39m [_unpack_collections(o) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m operands]\n\u001b[0;32m---> 59\u001b[0m _name \u001b[38;5;241m=\u001b[39m \u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _name \u001b[38;5;129;01min\u001b[39;00m Expr\u001b[38;5;241m.\u001b[39m_instances:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Expr\u001b[38;5;241m.\u001b[39m_instances[_name]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/functools.py:993\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    991\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 993\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    995\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/dask_expr/_expr.py:616\u001b[0m, in \u001b[0;36mMapPartitions._name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    615\u001b[0m     head \u001b[38;5;241m=\u001b[39m funcname(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m--> 616\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m head \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43m_tokenize_deterministic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/dask_expr/_util.py:102\u001b[0m, in \u001b[0;36m_tokenize_deterministic\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tokenize_deterministic\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# Utility to be strict about deterministic tokens\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_deterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/dask/tokenize.py:76\u001b[0m, in \u001b[0;36mtokenize\u001b[0;34m(ensure_deterministic, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     token \u001b[38;5;241m=\u001b[39m _ENSURE_DETERMINISTIC\u001b[38;5;241m.\u001b[39mset(ensure_deterministic)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/dask/tokenize.py:34\u001b[0m, in \u001b[0;36m_tokenize\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tokenize\u001b[39m(\u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mobject\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28mobject\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 34\u001b[0m     token: \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_normalize_seq_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m     36\u001b[0m         token \u001b[38;5;241m=\u001b[39m token, _normalize_seq_func(\u001b[38;5;28msorted\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/dask/tokenize.py:152\u001b[0m, in \u001b[0;36m_normalize_seq_func\u001b[0;34m(seq)\u001b[0m\n\u001b[1;32m    150\u001b[0m _SEEN[\u001b[38;5;28mid\u001b[39m(seq)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(_SEEN), seq\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_inner_normalize_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _SEEN[\u001b[38;5;28mid\u001b[39m(seq)]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/dask/tokenize.py:146\u001b[0m, in \u001b[0;36m_normalize_seq_func.<locals>._inner_normalize_token\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _IDENTITY_DISPATCH):\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m item\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnormalize_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/dask/utils.py:772\u001b[0m, in \u001b[0;36mDispatch.__call__\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;124;03mCall the corresponding method based on type of argument.\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    771\u001b[0m meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(\u001b[38;5;28mtype\u001b[39m(arg))\n\u001b[0;32m--> 772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/dask/tokenize.py:210\u001b[0m, in \u001b[0;36mnormalize_object\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _normalize_pickle(o)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     \u001b[43m_maybe_raise_nondeterministic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mObject \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mo\u001b[49m\u001b[38;5;132;43;01m!r}\u001b[39;49;00m\u001b[38;5;124;43m cannot be deterministically hashed. See \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://docs.dask.org/en/latest/custom-collections.html#implementing-deterministic-hashing \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfor more information.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uuid\u001b[38;5;241m.\u001b[39muuid4()\u001b[38;5;241m.\u001b[39mhex\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.7/lib/python3.12/site-packages/dask/tokenize.py:89\u001b[0m, in \u001b[0;36m_maybe_raise_nondeterministic\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m     87\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mor\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenize.ensure-deterministic\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TokenizationError(msg)\n",
      "\u001b[0;31mTokenizationError\u001b[0m: Object <function <lambda> at 0x11cdec7c0> cannot be deterministically hashed. See https://docs.dask.org/en/latest/custom-collections.html#implementing-deterministic-hashing for more information."
     ]
    }
   ],
   "source": [
    "# Also couldn't get Dask to work so I guess we're stuck with the slow pandas apply\n",
    "\n",
    "# import dask.dataframe as dd\n",
    "# from dask.diagnostics import ProgressBar\n",
    "\n",
    "# # Convert the DataFrame to a Dask DataFrame\n",
    "# ddf = dd.from_pandas(data_tiny, npartitions=4, chunksize=None)\n",
    "\n",
    "# # Define a wrapper function for Dask to use\n",
    "# def dask_sentiment_inference(review, llm_model, system_prompt):\n",
    "#     return sentiment_inference(llm_model=llm_model, review=review, system_prompt=system_prompt)\n",
    "\n",
    "# # Apply the sentiment_inference function in parallel using Dask\n",
    "# with ProgressBar():\n",
    "#     ddf['sentiment_llm_small'] = ddf['review'].map_partitions(lambda data_tiny: data_tiny.apply(lambda review: dask_sentiment_inference(review, llm_small, system_prompt_baseline), axis=1))\n",
    "#     ddf['sentiment_llm_big'] = ddf['review'].map_partitions(lambda data_tiny: data_tiny.apply(lambda review: dask_sentiment_inference(review, llm_big, system_prompt_baseline), axis=1))\n",
    "\n",
    "# # Compute the results\n",
    "# result = ddf.compute()\n",
    "\n",
    "# # Display the DataFrame with the new columns\n",
    "# result.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# This also crashes the kernel\n",
    "\n",
    "# from threading import Thread\n",
    "\n",
    "# def func1():\n",
    "#     data_tiny['sentiment_llm_small'] = data_tiny['review'].apply(lambda review: sentiment_inference(llm_small, review, system_prompt_baseline))\n",
    "\n",
    "# def func2():\n",
    "#     data_tiny['sentiment_llm_big'] = data_tiny['review'].apply(lambda review: sentiment_inference(llm_big, review, system_prompt_baseline))\n",
    "\n",
    "\n",
    "# Thread(target = func1).start()\n",
    "# Thread(target = func2).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK none of the concurrent approaches worked so going to draw a line under that one.\n",
    "\n",
    "I would probably do something with threads in bash if I had more time on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting hyperparameters\n",
    "\n",
    "In this task we are NOT looking for diversity in output, we want either a float score [-1, 1] or a binary (0, 1). \n",
    "\n",
    "Given this:\n",
    "\n",
    "- `top_k` limits model's output to most likely words (larger k = more diversity). Thus we want a lower k \n",
    "- `top_p` dynamically adjusts #tokens considered based on a cumulative probability. p in [0, 1]. We want a higher p \n",
    "- Not recommended to adjust both `top_p` and temperature so let's leave temperature at the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to put results for the two different models in two different dataframes\n",
    "df_big = data_tiny.copy()\n",
    "df_small = data_tiny.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "top_k values: 100%|| 3/3 [08:20<00:00, 166.95s/it]\n",
      "top_k values: 100%|| 3/3 [28:14<00:00, 565.00s/it]\n"
     ]
    }
   ],
   "source": [
    "top_k_values = [20, 40, 60]  # smaller probably better\n",
    "top_p_values = [0.8, 0.9, 0.95]  # bigger probably better \n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "results = []\n",
    "\n",
    "# Apply sentiment_inference for each combination of top_k and top_p\n",
    "tqdm.pandas()\n",
    "\n",
    "results_small = []\n",
    "results_big = []\n",
    "\n",
    "# Apply sentiment_inference for each combination of top_k and top_p\n",
    "for top_k in tqdm(top_k_values, desc=\"top_k values\"):\n",
    "    for top_p in tqdm(top_p_values, desc=\"top_p values\", leave=False):\n",
    "        result_df = df_small.copy()\n",
    "        result_df['top_k'] = top_k\n",
    "        result_df['top_p'] = top_p\n",
    "        result_df['sentiment'] = df_small['review'].apply(lambda review: sentiment_inference(llm_small, review, system_prompt_baseline, top_p=top_p, top_k=top_k))\n",
    "        results_small.append(result_df)\n",
    "\n",
    "for top_k in tqdm(top_k_values, desc=\"top_k values\"):\n",
    "    for top_p in tqdm(top_p_values, desc=\"top_p values\", leave=False):\n",
    "        result_df = df_big.copy()\n",
    "        result_df['top_k'] = top_k\n",
    "        result_df['top_p'] = top_p\n",
    "        result_df['sentiment'] = df_big['review'].apply(lambda review: sentiment_inference(llm_big, review, system_prompt_baseline, top_p=top_p, top_k=top_k))\n",
    "        results_big.append(result_df)\n",
    "\n",
    "final_df_small = pd.concat(results_small, ignore_index=True)\n",
    "final_df_big = pd.concat(results_big, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>top_k</th>\n",
       "      <th>top_p</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They had an opportunity to make one of the bes...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multiply named and strangely casted, 'One Dark...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What's with Indonesian musical movies? Never h...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I waited quite awhile till I was able to watch...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I watch this movie without big expectations, I...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>When Uwe Boll, cinema con man extraordinaire, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>this episode is not incoherent like another pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>When I started watching the show I said 'Oh, n...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>With great expectations I went to see this fil...</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Simply awful slasher, molded from the I KNOW W...</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  label  top_k  top_p  \\\n",
       "0    They had an opportunity to make one of the bes...      1     20   0.80   \n",
       "1    Multiply named and strangely casted, 'One Dark...      0     20   0.80   \n",
       "2    What's with Indonesian musical movies? Never h...      1     20   0.80   \n",
       "3    I waited quite awhile till I was able to watch...      1     20   0.80   \n",
       "4    I watch this movie without big expectations, I...      0     20   0.80   \n",
       "..                                                 ...    ...    ...    ...   \n",
       "265  When Uwe Boll, cinema con man extraordinaire, ...      1     60   0.95   \n",
       "266  this episode is not incoherent like another pe...      0     60   0.95   \n",
       "267  When I started watching the show I said 'Oh, n...      0     60   0.95   \n",
       "268  With great expectations I went to see this fil...      1     60   0.95   \n",
       "269  Simply awful slasher, molded from the I KNOW W...      1     60   0.95   \n",
       "\n",
       "     sentiment  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "..         ...  \n",
       "265          0  \n",
       "266          0  \n",
       "267          0  \n",
       "268          0  \n",
       "269          0  \n",
       "\n",
       "[270 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   top_k  top_p  accuracy  f1_score\n",
      "0     20   0.80  0.366667  0.256667\n",
      "1     20   0.90  0.400000  0.273171\n",
      "2     20   0.95  0.366667  0.256667\n",
      "3     40   0.80  0.400000  0.273171\n",
      "4     40   0.90  0.333333  0.239316\n",
      "5     40   0.95  0.366667  0.256667\n",
      "6     60   0.80  0.400000  0.273171\n",
      "7     60   0.90  0.366667  0.256667\n",
      "8     60   0.95  0.366667  0.256667\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(group):\n",
    "    return accuracy_score(group['label'], group['sentiment'])\n",
    "\n",
    "def calculate_f1(group):\n",
    "    return f1_score(group['label'], group['sentiment'], average=\"weighted\")\n",
    "\n",
    "accuracy_results_small = final_df_small.groupby(['top_k', 'top_p']).agg(\n",
    "    accuracy=('label', lambda x: calculate_accuracy(final_df_small.loc[x.index])),\n",
    "    precision=('label', lambda x: calculate_f1(final_df_small.loc[x.index]))\n",
    ").reset_index()\n",
    "accuracy_results_small.columns = ['top_k', 'top_p', 'accuracy', 'f1_score']\n",
    "print(accuracy_results_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   top_k  top_p  accuracy  f1_score\n",
      "0     20   0.80  0.566667  0.441481\n",
      "1     20   0.90  0.533333  0.371014\n",
      "2     20   0.95  0.533333  0.371014\n",
      "3     40   0.80  0.533333  0.371014\n",
      "4     40   0.90  0.566667  0.441481\n",
      "5     40   0.95  0.533333  0.371014\n",
      "6     60   0.80  0.533333  0.371014\n",
      "7     60   0.90  0.533333  0.371014\n",
      "8     60   0.95  0.533333  0.371014\n"
     ]
    }
   ],
   "source": [
    "accuracy_results_big = final_df_big.groupby(['top_k', 'top_p']).agg(\n",
    "    accuracy=('label', lambda x: calculate_accuracy(final_df_big.loc[x.index])),\n",
    "    precision=('label', lambda x: calculate_f1(final_df_big.loc[x.index]))\n",
    ").reset_index()\n",
    "accuracy_results_big.columns = ['top_k', 'top_p', 'accuracy', 'f1_score']\n",
    "print(accuracy_results_big)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK I can't afford to run this again since it took nearly 40 mins but I will settle on \n",
    "\n",
    "| Model | `top_k` | `top_p` |\n",
    "| - | - | - | \n",
    "| small | 20 | 0.9 |\n",
    "| big | 40 | 0.9 | \n",
    "\n",
    "which is broadly as expected. This isn't a brilliant experience (especially as I forgot to properly sample the data) but it will have to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt crafting \n",
    "\n",
    "So far the baseline prompt has been pretty bad, with the small model tending positive (in terms of sentiment) and the big model tending negative.\n",
    "\n",
    "Here are a few experiments I want to try (with my small amount of examples)\n",
    "\n",
    "- End prompt with \"this is the review\"\n",
    "- Few shot examples of -ve and +ve reviews \n",
    "- Getting the model to return a float between -1 and 1 for negative / postive then mapping that to the (0, 1) binary score the labels have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "HYPERPARAMS = {\"small\": {\"top_k\": 20, \"top_p\": 0.9}, \"big\": {\"top_k\": 40, \"top_p\": 0.9}}\n",
    "MODELS = {\"small\": llm_small, \"big\": llm_big}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df,\n",
    "    df[[\"review_length\", \"label\"]],\n",
    "    stratify=df[[\"review_length_bin\", \"label\"]],\n",
    "    test_size=50,\n",
    ")\n",
    "data = X_test[['review', 'label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put existing results in to a dict\n",
    "results = {\n",
    "    \"small\": [{\n",
    "        \"prompt\": \"system_prompt_baseline\",\n",
    "        \"accuracy\": 0.4,\n",
    "        \"f1_score\": 0.273171,\n",
    "    }],\n",
    "    \"big\": [{\n",
    "        \"prompt\": \"system_prompt_baseline\",\n",
    "        \"accuracy\": 0.566667,\n",
    "        \"f1_score\": 0.441481,\n",
    "    }],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_extended = \"You are doing sentiment analysis on movie reviews. Classify the review as positive (0) or negative (1). Only return a 0 or a 1. Here is the movie review to analyse:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l8/nxqb7fdj4h79rs4h1s8k5zyr0000gn/T/ipykernel_13054/1002161558.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[f\"{size}_extended\"] = data[\"review\"].apply(\n"
     ]
    }
   ],
   "source": [
    "for size in [\"small\", \"big\"]:\n",
    "    llm_model = MODELS[size]\n",
    "    data[f\"{size}_extended\"] = data[\"review\"].apply(\n",
    "        lambda review: sentiment_inference(\n",
    "            llm_model=MODELS[size],\n",
    "            review=review,\n",
    "            system_prompt=system_prompt_extended,\n",
    "            top_k=HYPERPARAMS[size][\"top_k\"],\n",
    "            top_p=HYPERPARAMS[size][\"top_p\"],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(data, column_name):\n",
    "    accuracy = accuracy_score(data[\"label\"], data[column_name])\n",
    "    f1 = f1_score(data[\"label\"], data[column_name], average=\"weighted\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\n",
    "        f\"Precision: {precision_score(\n",
    "        data[\"label\"], data[column_name], average=\"weighted\", zero_division=0\n",
    "    )}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Recall: {recall_score(\n",
    "        data[\"label\"], data[column_name], average=\"weighted\", zero_division=0\n",
    "    )}\"\n",
    "    )\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"Confusion matrix:\\n{confusion_matrix(data['label'], data[column_name])}\")\n",
    "    print(\n",
    "        f\"Classification report:\\n{classification_report(data['label'], data[column_name], zero_division=0)}\"\n",
    "    )\n",
    "    return accuracy, float(f1)\n",
    "\n",
    "def get_metrics(data, column_name):\n",
    "    accuracy = accuracy_score(data[\"label\"], data[column_name])\n",
    "    f1 = f1_score(data[\"label\"], data[column_name], average=\"weighted\")\n",
    "    return accuracy, float(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.32\n",
      "Precision: 0.16\n",
      "Recall: 0.32\n",
      "F1 Score: 0.21333333333333335\n",
      "Confusion matrix:\n",
      "[[16  6]\n",
      " [28  0]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.73      0.48        22\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.32        50\n",
      "   macro avg       0.18      0.36      0.24        50\n",
      "weighted avg       0.16      0.32      0.21        50\n",
      "\n",
      "Accuracy: 0.6\n",
      "Precision: 0.7666666666666667\n",
      "Recall: 0.6\n",
      "F1 Score: 0.48596491228070177\n",
      "Confusion matrix:\n",
      "[[ 2 20]\n",
      " [ 0 28]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.09      0.17        22\n",
      "           1       0.58      1.00      0.74        28\n",
      "\n",
      "    accuracy                           0.60        50\n",
      "   macro avg       0.79      0.55      0.45        50\n",
      "weighted avg       0.77      0.60      0.49        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for size in [\"small\", \"big\"]:\n",
    "    accuracy, f1 = print_metrics(data, f\"{size}_extended\")\n",
    "    results[size].append({\n",
    "        \"prompt\": \"system_prompt_extended\",\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_results(results: dict) -> None:\n",
    "    # Flatten the dictionary structure\n",
    "    flattened_data = []\n",
    "    for model_size, metrics in results.items():\n",
    "        for metric in metrics:\n",
    "            metric['model_size'] = model_size\n",
    "            flattened_data.append(metric)\n",
    "\n",
    "    # Create a DataFrame from the flattened structure\n",
    "    df_results = pd.DataFrame(flattened_data)\n",
    "\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   prompt  accuracy  f1_score model_size\n",
      "0  system_prompt_baseline  0.400000  0.273171      small\n",
      "1  system_prompt_extended  0.320000  0.213333      small\n",
      "2  system_prompt_baseline  0.566667  0.441481        big\n",
      "3  system_prompt_extended  0.600000  0.485965        big\n"
     ]
    }
   ],
   "source": [
    "render_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this improved the outcome for the big model a bit but actively made the small model worse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_float = \"\"\"\n",
    "You are doing sentiment analysis on movie reviews. \n",
    "Classify the sentiment of the review as a float between -1 (most negative) and 1 (most positive). \n",
    "Do not return anything else apart from this float. \n",
    "Here is the movie review to classify:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in [\"small\", \"big\"]:\n",
    "    llm_model = MODELS[size]\n",
    "    data[f\"{size}_float\"] = data[\"review\"].apply(\n",
    "        lambda review: sentiment_inference(\n",
    "            llm_model=MODELS[size],\n",
    "            review=review,\n",
    "            system_prompt=system_prompt_float,\n",
    "            top_k=HYPERPARAMS[size][\"top_k\"],\n",
    "            top_p=HYPERPARAMS[size][\"top_p\"],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>small_extended</th>\n",
       "      <th>big_extended</th>\n",
       "      <th>small_float</th>\n",
       "      <th>big_float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>I first saw the film when it landed on US cabl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19005</th>\n",
       "      <td>Tom the cat, Jerry the mouse, and Spike the Do...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21690</th>\n",
       "      <td>Average viewers looking for any sense of inter...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10326</th>\n",
       "      <td>This movie made me so angry!! Here I am thinki...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12590</th>\n",
       "      <td>After having seen Deliverance, movies like Pul...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label  \\\n",
       "709    I first saw the film when it landed on US cabl...      0   \n",
       "19005  Tom the cat, Jerry the mouse, and Spike the Do...      0   \n",
       "21690  Average viewers looking for any sense of inter...      1   \n",
       "10326  This movie made me so angry!! Here I am thinki...      1   \n",
       "12590  After having seen Deliverance, movies like Pul...      0   \n",
       "\n",
       "       small_extended  big_extended  small_float  big_float  \n",
       "709                 1             1           -2         -2  \n",
       "19005               0             0           -2         -2  \n",
       "21690               0             1           -2         -2  \n",
       "10326               0             1           -1         -2  \n",
       "12590               0             1           -2         -2  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK apparently the LLM does not know what a float is! We still need to map the results to the original scores though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(value):\n",
    "    \"\"\"\n",
    "    Converts a value in the range [-1, 1] to binary (0, 1).\n",
    "    If the value is > 0, the result is 0.\n",
    "    Otherwise, the result is 1.\n",
    "    \"\"\"\n",
    "    if value == SENTINAL_VALUE:\n",
    "        return SENTINAL_VALUE\n",
    "    return 0 if value > 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in [\"small\", \"big\"]:\n",
    "    data[f\"{size}_float_binary\"] = data[f\"{size}_float\"].apply(\n",
    "        lambda fl: convert_to_binary(fl)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.18\n",
      "Precision: 0.56\n",
      "Recall: 0.18\n",
      "F1 Score: 0.2724324324324325\n",
      "Confusion matrix:\n",
      "[[ 0  0  0]\n",
      " [22  0  0]\n",
      " [19  0  9]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.00      0.00      0.00         0\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       1.00      0.32      0.49        28\n",
      "\n",
      "    accuracy                           0.18        50\n",
      "   macro avg       0.33      0.11      0.16        50\n",
      "weighted avg       0.56      0.18      0.27        50\n",
      "\n",
      "Accuracy: 0.0\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "Confusion matrix:\n",
      "[[ 0  0  0]\n",
      " [22  0  0]\n",
      " [28  0  0]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.00      0.00      0.00       0.0\n",
      "           0       0.00      0.00      0.00      22.0\n",
      "           1       0.00      0.00      0.00      28.0\n",
      "\n",
      "    accuracy                           0.00      50.0\n",
      "   macro avg       0.00      0.00      0.00      50.0\n",
      "weighted avg       0.00      0.00      0.00      50.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for size in [\"small\", \"big\"]:\n",
    "    accuracy, f1 = print_metrics(data, f\"{size}_float_binary\")\n",
    "    results[size].append({\n",
    "        \"prompt\": \"system_prompt_float\",\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   prompt  accuracy  f1_score model_size\n",
      "0  system_prompt_baseline  0.400000  0.273171      small\n",
      "1  system_prompt_extended  0.320000  0.213333      small\n",
      "2     system_prompt_float  0.540000  0.514328      small\n",
      "3     system_prompt_float  0.180000  0.272432      small\n",
      "4  system_prompt_baseline  0.566667  0.441481        big\n",
      "5  system_prompt_extended  0.600000  0.485965        big\n",
      "6     system_prompt_float  0.560000  0.402051        big\n",
      "7     system_prompt_float  0.000000  0.000000        big\n"
     ]
    }
   ],
   "source": [
    "render_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK the float was a bad idea. Let's make a prompt now based on trying a few shot approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_few_shot = \"\"\"\n",
    "You are doing sentiment analysis on movie reviews. \n",
    "Classify the review as positive (0) or negative (1). \n",
    "Only return a 0 or a 1. \n",
    "Here are some examples: \n",
    "1. \"This movie was absolutely terrible in every way possible!\" (negative: 1)\n",
    "2. \"I really enjoyed the plot and the characters were amazing.\" (positive: 0)\n",
    "3. \"The acting was subpar but the movie was still enjoyable.\" (slightly negative: 1)\n",
    "\n",
    "Here is the movie review to analyse:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in [\"small\", \"big\"]:\n",
    "    llm_model = MODELS[size]\n",
    "    data[f\"{size}_few_shot\"] = data[\"review\"].apply(\n",
    "        lambda review: sentiment_inference(\n",
    "            llm_model=MODELS[size],\n",
    "            review=review,\n",
    "            system_prompt=system_prompt_few_shot,\n",
    "            top_k=HYPERPARAMS[size][\"top_k\"],\n",
    "            top_p=HYPERPARAMS[size][\"top_p\"],\n",
    "        )\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n",
      "Precision: 0.18333333333333335\n",
      "Recall: 0.4\n",
      "F1 Score: 0.25142857142857145\n",
      "Confusion matrix:\n",
      "[[20  2]\n",
      " [28  0]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.91      0.57        22\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.40        50\n",
      "   macro avg       0.21      0.45      0.29        50\n",
      "weighted avg       0.18      0.40      0.25        50\n",
      "\n",
      "Accuracy: 0.26\n",
      "Precision: 0.65\n",
      "Recall: 0.26\n",
      "F1 Score: 0.2622608695652174\n",
      "Confusion matrix:\n",
      "[[ 0  0  0]\n",
      " [ 1  1 20]\n",
      " [16  0 12]]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -2       0.00      0.00      0.00         0\n",
      "           0       1.00      0.05      0.09        22\n",
      "           1       0.38      0.43      0.40        28\n",
      "\n",
      "    accuracy                           0.26        50\n",
      "   macro avg       0.46      0.16      0.16        50\n",
      "weighted avg       0.65      0.26      0.26        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for size in [\"small\", \"big\"]:\n",
    "    accuracy, f1 = print_metrics(data, f\"{size}_few_shot\")\n",
    "    results[size].append({\n",
    "        \"prompt\": \"system_prompt_few_shot\",\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   prompt  accuracy  f1_score model_size\n",
      "0  system_prompt_baseline  0.400000  0.273171      small\n",
      "1  system_prompt_extended  0.320000  0.213333      small\n",
      "2     system_prompt_float  0.180000  0.272432      small\n",
      "3  system_prompt_few_shot  0.400000  0.251429      small\n",
      "4  system_prompt_baseline  0.566667  0.441481        big\n",
      "5  system_prompt_extended  0.600000  0.485965        big\n",
      "6     system_prompt_float  0.000000  0.000000        big\n",
      "7  system_prompt_few_shot  0.260000  0.262261        big\n"
     ]
    }
   ],
   "source": [
    "render_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK so the large model is only beating random chance for `system_prompt_extended` (and the small model never is). I wonder if the length of the prompt (both system prompt and review) is to blame?\n",
    "\n",
    "Few ways to reduce length of review:\n",
    "\n",
    "- Take last `n` tokens from the review \n",
    "- Take first `n` tokens from the review \n",
    "- Take random window of `n` tokens from the review \n",
    "- Only keep \"important\" words (ditching works with not sentiment attached like `the` etc.)\n",
    "\n",
    "Given everything takes so long to run I am just going to do a simple experiment with review length for (a) the big model and (b) the first of these ideas. Helpfully we can then make a nice graph out of it too. I will stick with the `system_prompt_extended` prompt. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It would be smarter to do this by tokens instead of characters but I don't have a huge amount more time and this should a signal\n",
    "review_length = [200, 600, 1000, 1500, 2000, 3000, 5000, 10000]\n",
    "size = \"big\"\n",
    "\n",
    "for l in review_length:\n",
    "    data[f\"review_length_{l}_end\"] = data[\"review\"].apply(\n",
    "        lambda review: sentiment_inference(\n",
    "            llm_model=MODELS[size],\n",
    "            review=review[l:],\n",
    "            system_prompt=system_prompt_extended,\n",
    "            top_k=HYPERPARAMS[size][\"top_k\"],\n",
    "            top_p=HYPERPARAMS[size][\"top_p\"],\n",
    "        )\n",
    "   )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in review_length:\n",
    "    accuracy, f1 = get_metrics(data, f\"review_length_{l}_end\")\n",
    "    results[size].append({\n",
    "        \"prompt\": f\"system_prompt_extended + review_length {l}\",\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          prompt  accuracy  f1_score  \\\n",
      "0                         system_prompt_baseline  0.400000  0.273171   \n",
      "1                         system_prompt_extended  0.320000  0.213333   \n",
      "2                            system_prompt_float  0.180000  0.272432   \n",
      "3                         system_prompt_few_shot  0.400000  0.251429   \n",
      "4                         system_prompt_baseline  0.566667  0.441481   \n",
      "5                         system_prompt_extended  0.600000  0.485965   \n",
      "6                            system_prompt_float  0.000000  0.000000   \n",
      "7                         system_prompt_few_shot  0.260000  0.262261   \n",
      "8     system_prompt_extended + review_length 200  0.580000  0.445534   \n",
      "9     system_prompt_extended + review_length 600  0.500000  0.373333   \n",
      "10   system_prompt_extended + review_length 1000  0.540000  0.448747   \n",
      "11   system_prompt_extended + review_length 1500  0.640000  0.592000   \n",
      "12   system_prompt_extended + review_length 2000  0.600000  0.546667   \n",
      "13   system_prompt_extended + review_length 3000  0.460000  0.377387   \n",
      "14   system_prompt_extended + review_length 5000  0.460000  0.438919   \n",
      "15  system_prompt_extended + review_length 10000  0.580000  0.515746   \n",
      "\n",
      "   model_size  \n",
      "0       small  \n",
      "1       small  \n",
      "2       small  \n",
      "3       small  \n",
      "4         big  \n",
      "5         big  \n",
      "6         big  \n",
      "7         big  \n",
      "8         big  \n",
      "9         big  \n",
      "10        big  \n",
      "11        big  \n",
      "12        big  \n",
      "13        big  \n",
      "14        big  \n",
      "15        big  \n"
     ]
    }
   ],
   "source": [
    "render_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataframe of the results so we can plot them\n",
    "flattened_data = []\n",
    "for model_size, metrics in results.items():\n",
    "    for metric in metrics:\n",
    "        metric['model_size'] = model_size\n",
    "        flattened_data.append(metric)\n",
    "\n",
    "df_results = pd.DataFrame(flattened_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>model_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>system_prompt_baseline</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.273171</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>system_prompt_extended</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>system_prompt_float</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.272432</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>system_prompt_few_shot</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.251429</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>system_prompt_baseline</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.441481</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>system_prompt_extended</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.485965</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>system_prompt_float</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>system_prompt_few_shot</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.262261</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>system_prompt_extended + review_length 200</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.445534</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>system_prompt_extended + review_length 600</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>system_prompt_extended + review_length 1000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.448747</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>system_prompt_extended + review_length 1500</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>system_prompt_extended + review_length 2000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>system_prompt_extended + review_length 3000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.377387</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>system_prompt_extended + review_length 5000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.438919</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>system_prompt_extended + review_length 10000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.515746</td>\n",
       "      <td>big</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          prompt  accuracy  f1_score  \\\n",
       "0                         system_prompt_baseline  0.400000  0.273171   \n",
       "1                         system_prompt_extended  0.320000  0.213333   \n",
       "2                            system_prompt_float  0.180000  0.272432   \n",
       "3                         system_prompt_few_shot  0.400000  0.251429   \n",
       "4                         system_prompt_baseline  0.566667  0.441481   \n",
       "5                         system_prompt_extended  0.600000  0.485965   \n",
       "6                            system_prompt_float  0.000000  0.000000   \n",
       "7                         system_prompt_few_shot  0.260000  0.262261   \n",
       "8     system_prompt_extended + review_length 200  0.580000  0.445534   \n",
       "9     system_prompt_extended + review_length 600  0.500000  0.373333   \n",
       "10   system_prompt_extended + review_length 1000  0.540000  0.448747   \n",
       "11   system_prompt_extended + review_length 1500  0.640000  0.592000   \n",
       "12   system_prompt_extended + review_length 2000  0.600000  0.546667   \n",
       "13   system_prompt_extended + review_length 3000  0.460000  0.377387   \n",
       "14   system_prompt_extended + review_length 5000  0.460000  0.438919   \n",
       "15  system_prompt_extended + review_length 10000  0.580000  0.515746   \n",
       "\n",
       "   model_size  \n",
       "0       small  \n",
       "1       small  \n",
       "2       small  \n",
       "3       small  \n",
       "4         big  \n",
       "5         big  \n",
       "6         big  \n",
       "7         big  \n",
       "8         big  \n",
       "9         big  \n",
       "10        big  \n",
       "11        big  \n",
       "12        big  \n",
       "13        big  \n",
       "14        big  \n",
       "15        big  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l8/nxqb7fdj4h79rs4h1s8k5zyr0000gn/T/ipykernel_13054/3757823590.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_review_length[\"review_length\"] = review_length\n"
     ]
    }
   ],
   "source": [
    "df_review_length = df_results[df_results['prompt'].str.contains('review_length')]\n",
    "df_review_length[\"review_length\"] = review_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the results for the unrestricted review length from before\n",
    "new_row = pd.DataFrame({\n",
    "    \"prompt\": [\"system_prompt_extended + unrestricted review length\"],\n",
    "    \"accuracy\": [df_results[(df_results['prompt'] == \"system_prompt_extended\") & (df_results['model_size'] == \"big\")]['accuracy'].values[0]],\n",
    "    \"f1_score\": [df_results[(df_results['prompt'] == \"system_prompt_extended\") & (df_results['model_size'] == \"big\")]['f1_score'].values[0]],\n",
    "    \"model_size\": [\"big\"],\n",
    "    \"review_length\":[ \"32000\"]\n",
    "})\n",
    "df_review_length = pd.concat([df_review_length, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>model_size</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>system_prompt_extended + review_length 200</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.445534</td>\n",
       "      <td>big</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>system_prompt_extended + review_length 600</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>big</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>system_prompt_extended + review_length 1000</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.448747</td>\n",
       "      <td>big</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>system_prompt_extended + review_length 1500</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>big</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>system_prompt_extended + review_length 2000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.546667</td>\n",
       "      <td>big</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>system_prompt_extended + review_length 3000</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.377387</td>\n",
       "      <td>big</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>system_prompt_extended + review_length 5000</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.438919</td>\n",
       "      <td>big</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>system_prompt_extended + review_length 10000</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.515746</td>\n",
       "      <td>big</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>system_prompt_extended + unrestricted review l...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.485965</td>\n",
       "      <td>big</td>\n",
       "      <td>32000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  accuracy  f1_score  \\\n",
       "0         system_prompt_extended + review_length 200      0.58  0.445534   \n",
       "1         system_prompt_extended + review_length 600      0.50  0.373333   \n",
       "2        system_prompt_extended + review_length 1000      0.54  0.448747   \n",
       "3        system_prompt_extended + review_length 1500      0.64  0.592000   \n",
       "4        system_prompt_extended + review_length 2000      0.60  0.546667   \n",
       "5        system_prompt_extended + review_length 3000      0.46  0.377387   \n",
       "6        system_prompt_extended + review_length 5000      0.46  0.438919   \n",
       "7       system_prompt_extended + review_length 10000      0.58  0.515746   \n",
       "8  system_prompt_extended + unrestricted review l...      0.60  0.485965   \n",
       "\n",
       "  model_size review_length  \n",
       "0        big           200  \n",
       "1        big           600  \n",
       "2        big          1000  \n",
       "3        big          1500  \n",
       "4        big          2000  \n",
       "5        big          3000  \n",
       "6        big          5000  \n",
       "7        big         10000  \n",
       "8        big         32000  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACRIUlEQVR4nO3dd3zT1f4/8FeSJulelE5KW8reWoZsVKaIshTHvQwRFOU6cCB6BQEvfB0/1KtecIFcLwiCiIMhiBZREJSNzCJQVksH3StNzu+PT/Np0yRt02a2r+fjkQfpJ598cnKatm/e533OUQghBIiIiIiaEKWrG0BERETkbAyAiIiIqMlhAERERERNDgMgIiIianIYABEREVGTwwCIiIiImhwGQERERNTkMAAiIiKiJocBEBERETU5DIDI41y4cAEKhQKffvqpq5tiYtu2bejevTu8vb2hUCiQk5Pj6iYRUS3i4+MxZcoUVzfDY73yyitQKBTIzMx0dVNsxgDIjRw7dgwTJkxAXFwcvL29ERMTg6FDh+Ldd9912GuuWbMGb7/9ttnxq1ev4pVXXsHhw4cd9trVJScnQ6FQyDe1Wo1WrVph0qRJ+Ouvv+zyGnv27MErr7xi9+AkKysL9957L3x8fPD+++/js88+g5+fX63P+89//gOFQoHevXvbtT1NSVJSEh577DGrj3/66acmn6uqtxdeeEE+b/v27Zg2bRo6d+4MlUqF+Ph4J7SeACkIqfp98fPzQ69evfDf//7X1U1zCuN/6t58801XN8WqxYsXY9OmTa5uhl15uboBJNmzZw9uvfVWtGzZEtOnT0dkZCQuXbqE3377De+88w7+8Y9/OOR116xZg+PHj+Opp54yOX716lUsWLAA8fHx6N69u0Ne25onnngCPXv2hE6nw8GDB/Hhhx9i8+bNOHbsGKKjoxt07T179mDBggWYMmUKgoOD7dNgAL///jvy8/OxaNEiDBkypM7PW716NeLj47F//36kpKSgdevWdmtTU3Dt2jUcOnQICxcurPXchQsXIiEhweRY586d5ftr1qzBunXrcPPNNzf4c0a26969O5555hkA0vf1448/xuTJk1FaWorp06c77HVPnz4NpZK5gNosXrwYEyZMwJgxY1zdFLthAOQm/vWvfyEoKAi///672R/m69evu6ZRDlBYWFhrZmTAgAGYMGECAGDq1Klo27YtnnjiCaxatQpz5851RjNtZvwe2RJUnT9/Hnv27MHGjRvxyCOPYPXq1Zg/f76DWtgwdfm+ucLWrVvh7e2N2267rdZzR44ciR49elh9fPHixfjoo4+gVqtx55134vjx4/ZsqsOVl5fDYDBAo9G4uin1EhMTg7/97W/y11OmTEGrVq3w1ltvOTQA0mq1Drs2uTeGvW7i3Llz6NSpk8U/oOHh4WbH/ve//6FXr17w9fVFSEgIBg4ciO3bt8uPf/311xg1ahSio6Oh1WqRmJiIRYsWQa/Xy+cMHjwYmzdvxsWLF+XUc3x8PJKTk9GzZ08AUgBifKxqzc2+ffswYsQIBAUFwdfXF4MGDcKvv/5q0kbj2PCJEyfwwAMPICQkBP3797e5b4x/3M6fP1/jeT/++CMGDBgAPz8/BAcH4+6778bJkydN2vPcc88BABISEuT3deHChRqvu379eiQlJcHHxwdhYWH429/+hitXrsiPDx48GJMnTwYA9OzZEwqFok41BatXr0ZISAhGjRqFCRMmYPXq1RbPy8nJwdNPP434+HhotVq0aNECkyZNMhlzLykpwSuvvIK2bdvC29sbUVFRGDduHM6dOwegcngxOTnZ5NqW6qmmTJkCf39/nDt3DnfccQcCAgLw4IMPAgB2796Ne+65By1btoRWq0VsbCyefvppFBcXm7X71KlTuPfee9G8eXP4+PigXbt2eOmllwAAP/30ExQKBb766iuz561ZswYKhQJ79+6ttQ83b96MW2+9FT4+PrWeW5vo6Gio1ep6P3/t2rVISkpCQEAAAgMD0aVLF7zzzjsm59Tle3n9+nVMmzYNERER8Pb2Rrdu3bBq1SqT61QdMnn77beRmJgIrVaLEydOAJD6fsKECQgNDYW3tzd69OiBb775psb263Q6hIaGYurUqWaP5eXlwdvbG88++6x87N1330WnTp3k30E9evTAmjVrbO43a5o3b4727dvLn2Ejg8GAt99+G506dYK3tzciIiLwyCOP4MaNG/I5d955J1q1amXxun369DEJhC3VAOXk5OCpp55CbGwstFotWrdujddeew0Gg0E+5+abb8a4ceNMntelSxcoFAocPXpUPrZu3TooFAqT30X1VVpaivnz56N169byz9/zzz+P0tJSk/MUCgVmzZqFTZs2oXPnztBqtejUqRO2bdtmds3k5GT06NED3t7eSExMxAcffCD/7q56vcLCQqxatUr+vWmpz4yZ9aCgIEydOhVFRUUNfs+OxAyQm4iLi8PevXtx/Phxk7S8JQsWLMArr7yCvn37YuHChdBoNNi3bx9+/PFHDBs2DIBU9+Dv74/Zs2fD398fP/74I+bNm4e8vDy88cYbAICXXnoJubm5uHz5Mt566y0AgL+/Pzp06ICFCxdi3rx5mDFjBgYMGAAA6Nu3LwAp0Bg5ciSSkpIwf/58KJVKrFy5Erfddht2796NXr16mbT3nnvuQZs2bbB48WIIIWzuG+MvwGbNmlk954cffsDIkSPRqlUrvPLKKyguLsa7776Lfv364eDBg4iPj8e4ceNw5swZfP7553jrrbcQFhYGQPpFa82nn36KqVOnomfPnliyZAnS09Pxzjvv4Ndff8WhQ4cQHByMl156Ce3atcOHH34oD7MkJibW+r5Wr16NcePGQaPR4P7778eyZcvw+++/y8EnABQUFGDAgAE4efIkHnroIdx8883IzMzEN998g8uXLyMsLAx6vR533nkndu7cifvuuw9PPvkk8vPzsWPHDhw/frxObamuvLwcw4cPR//+/fHmm2/C19cXgBQMFhUVYebMmWjWrBn279+Pd999F5cvX8b69evl5x89ehQDBgyAWq3GjBkzEB8fj3PnzuHbb7/Fv/71LwwePBixsbFYvXo1xo4da9YviYmJ6NOnT41t1Ol0+OGHH7B48eI6vafc3FyzQk3jZ6ChduzYgfvvvx+33347XnvtNQDAyZMn8euvv+LJJ58EULfvZXFxMQYPHoyUlBTMmjULCQkJWL9+PaZMmYKcnBz5WkYrV65ESUkJZsyYAa1Wi9DQUPz555/o168fYmJi8MILL8DPzw9ffPEFxowZgy+//NKsv43UajXGjh2LjRs34oMPPjDJJG3atAmlpaW47777AAAfffQRnnjiCUyYMAFPPvkkSkpKcPToUezbtw8PPPCAXfq0vLwcly9fRkhIiMnxRx55RP65fOKJJ3D+/Hm89957OHToEH799Veo1WpMnDgRkyZNMvt5unjxIn777Tf5d6AlRUVFGDRoEK5cuYJHHnkELVu2xJ49ezB37lxcu3ZNrpkcMGAAPv/8c/l52dnZ+PPPP6FUKrF792507doVgPSfhubNm6NDhw4N6g+DwYC77roLv/zyC2bMmIEOHTrg2LFjeOutt3DmzBmz+pxffvkFGzduxGOPPYaAgAD8+9//xvjx45Gamir/Lj106BBGjBiBqKgoLFiwAHq9HgsXLjT7nfjZZ5/h4YcfRq9evTBjxgwAMPu9cu+99yIhIQFLlizBwYMH8fHHHyM8PFz+eXBLgtzC9u3bhUqlEiqVSvTp00c8//zz4vvvvxdlZWUm5509e1YolUoxduxYodfrTR4zGAzy/aKiIrPXeOSRR4Svr68oKSmRj40aNUrExcWZnfv7778LAGLlypVmr9GmTRsxfPhws9dLSEgQQ4cOlY/Nnz9fABD3339/nfrgp59+EgDEihUrREZGhrh69arYvHmziI+PFwqFQvz+++9CCCHOnz9v1rbu3buL8PBwkZWVJR87cuSIUCqVYtKkSfKxN954QwAQ58+fr7U9ZWVlIjw8XHTu3FkUFxfLx7/77jsBQMybN08+tnLlSgFAbmNt/vjjDwFA7NixQwgh9WuLFi3Ek08+aXLevHnzBACxceNGs2sY+3/FihUCgFi6dKnVc4x9+9NPP5k8bqkvJ0+eLACIF154wex6lj5XS5YsEQqFQly8eFE+NnDgQBEQEGByrGp7hBBi7ty5QqvVipycHPnY9evXhZeXl5g/f77Z61S3c+fOOn0vjd8bSzdrrP1cWPPkk0+KwMBAUV5ebvWcunwv3377bQFA/O9//5MfKysrE3369BH+/v4iLy9PCFH5fQsMDBTXr183udbtt98uunTpYvJzbjAYRN++fUWbNm1qfB/ff/+9ACC+/fZbk+N33HGHaNWqlfz13XffLTp16lTjtWwRFxcnhg0bJjIyMkRGRoY4duyY+Pvf/y4AiMcff1w+b/fu3QKAWL16tcnzt23bZnI8NzdXaLVa8cwzz5ic9/rrr5t9VuPi4sTkyZPlrxctWiT8/PzEmTNnTJ77wgsvCJVKJVJTU4UQQqxfv14AECdOnBBCCPHNN98IrVYr7rrrLjFx4kT5eV27dhVjx46t8f0bv59vvPGG1XM+++wzoVQqxe7du02OL1++XAAQv/76q3wMgNBoNCIlJUU+duTIEQFAvPvuu/Kx0aNHC19fX3HlyhX52NmzZ4WXl5fZz4efn59JPxkZf88/9NBDJsfHjh0rmjVrVuP7djUOgbmJoUOHYu/evbjrrrtw5MgRvP766xg+fDhiYmJMUtebNm2CwWDAvHnzzAr3qqYsqw4J5OfnIzMzEwMGDEBRURFOnTpV73YePnwYZ8+exQMPPICsrCxkZmYiMzMThYWFuP322/Hzzz+bpIkB4NFHH7XpNR566CE0b94c0dHRGDVqlJx6tVa/ce3aNRw+fBhTpkxBaGiofLxr164YOnQotmzZYvsbBfDHH3/g+vXreOyxx+Dt7S0fHzVqFNq3b4/NmzfX67qAlOWIiIjArbfeCkD63k2cOBFr1641Gab88ssv0a1bN4v/azd+v7/88kuEhYVZLJSv+pmw1cyZM82OVf1cFRYWIjMzE3379oUQAocOHQIAZGRk4Oeff8ZDDz2Eli1bWm3PpEmTUFpaig0bNsjH1q1bh/LycpNaEGu2bNmCjh071nm21vvvv48dO3aY3OwlODgYhYWFNV6zLt/LLVu2IDIyEvfff7/8mFqtxhNPPIGCggLs2rXL5Hnjx483+d96dnY2fvzxR9x7773yz31mZiaysrIwfPhwnD171mT4trrbbrsNYWFhWLdunXzsxo0b2LFjByZOnGjyfi9fvozff/+9hl6xzfbt29G8eXM0b94cXbp0wWeffYapU6eaZGvWr1+PoKAgDB06VH5vmZmZSEpKgr+/P3766ScAQGBgIEaOHIkvvvjCJOu8bt063HLLLWafy6rWr1+PAQMGICQkxOQ1hgwZAr1ej59//hkA5My48evdu3ejZ8+eGDp0KHbv3g1AGhY6fvy4fG5DrF+/Hh06dED79u1N2mUsETC+d6MhQ4aYZGm6du2KwMBAeUatXq/HDz/8gDFjxpgU/bdu3RojR460uX3Vf88PGDAAWVlZyMvLs/lazsIAyI307NkTGzduxI0bN7B//37MnTsX+fn5mDBhgjy2f+7cOSiVSnTs2LHGa/35558YO3YsgoKCEBgYiObNm8t/VHJzc+vdxrNnzwIAJk+eLP+yMt4+/vhjlJaWml2/+syb2sybNw87duzAjz/+iKNHj+Lq1av4+9//bvX8ixcvAgDatWtn9liHDh3kAM1WNV23ffv28uO20uv1WLt2LW699VacP38eKSkpSElJQe/evZGeno6dO3fK5547d67WIdFz586hXbt28PKy34i2l5cXWrRoYXY8NTVVDjT9/f3RvHlzDBo0CEDl58r4C7a2drdv3x49e/Y0qX1avXo1brnlljrNhtu8eTNGjRpV5/fUq1cvDBkyxORmL4899hjatm2LkSNHokWLFnjooYfM6i3q8r28ePEi2rRpY/afG+PwSfXPXPWfrZSUFAgh8PLLL5v9fBoL7GuaVOHl5YXx48fj66+/lutKNm7cCJ1OZxIAzZkzB/7+/ujVqxfatGmDxx9/3KwG0Fa9e/fGjh07sG3bNrz55psIDg7GjRs3TIbizp49i9zcXISHh5u9v4KCApP3NnHiRFy6dEmuJTt37hwOHDhg8j4sOXv2LLZt22Z2fePnxfgaERERaNOmjRzs7N69GwMGDMDAgQNx9epV/PXXX/j1119hMBjsEgCdPXsWf/75p1m72rZta9IuI0tBXkhIiFwrdf36dRQXF1v8WavPbNTqr2ccuqxam+VuWAPkhjQaDXr27ImePXuibdu2mDp1KtavX1/nGUI5OTkYNGgQAgMDsXDhQiQmJsLb2xsHDx7EnDlzzDI0tjA+94033rA6Pd7f39/ka1sLVLt06WLXP07u5scff8S1a9ewdu1arF271uzx1atXy7Vc9mItE1Q121SVVqs1+yOs1+sxdOhQZGdnY86cOWjfvj38/Pxw5coVTJkypV6fq0mTJuHJJ5/E5cuXUVpait9++w3vvfderc87f/48Tp06hWXLltn8mo4QHh6Ow4cP4/vvv8fWrVuxdetWrFy5EpMmTTIrYLan6j9bxu/Bs88+i+HDh1t8Tm1/3O677z588MEH2Lp1K8aMGYMvvvgC7du3R7du3eRzOnTogNOnT+O7777Dtm3b8OWXX+I///kP5s2bhwULFtTrvYSFhck/98OHD0f79u1x55134p133sHs2bPl9xceHm51wkDVbNjo0aPh6+uLL774An379sUXX3wBpVKJe+65p8Z2GAwGDB06FM8//7zFx40BBwD0798fO3fuRHFxMQ4cOIB58+ahc+fOCA4Oxu7du3Hy5En4+/vjpptusqkvrLWrS5cuWLp0qcXHY2NjTb5WqVQWzxP1qMOsC2e/nj0wAHJzxmGfa9euAZAKzwwGA06cOGE1AElOTkZWVhY2btyIgQMHysctzaKy9ofR2nFjSjUwMNBtgpS4uDgA0noe1Z06dQphYWHyFG5bhoSqXrf6NOvTp0/Lj9tq9erVCA8Px/vvv2/22MaNG/HVV19h+fLl8PHxQWJiYq3TsRMTE7Fv3z7odDqrs5iM/xurvgCkLVmsY8eO4cyZM1i1ahUmTZokH68+7GOcfVOXaeT33XcfZs+ejc8//xzFxcVyAWttNm/ejKCgoHrNKnQUjUaD0aNHY/To0TAYDHjsscfwwQcf4OWXX0br1q3r9L2Mi4vD0aNHYTAYTAJQ47B1bZ85Y9+r1ep6/3wOHDgQUVFRWLduHfr3748ff/xRnr1XlZ+fHyZOnIiJEyeirKwM48aNw7/+9S/MnTvXZMi4vkaNGoVBgwZh8eLFeOSRR+Dn54fExET88MMP6NevX63/sfLz88Odd96J9evXY+nSpVi3bh0GDBhQ6xpPiYmJKCgoqFP/DRgwACtXrpSHrvv27QulUon+/fvLAVDfvn2tBge2SExMxJEjR3D77bc3aGjbKDw8HN7e3khJSTF7zNIxe7ymu+EQmJv46aefLEbKxvoV4zDMmDFjoFQqsXDhQrP/cRufb/xhq3q9srIy/Oc//zG7vp+fn8UhMWPAUP0PZlJSEhITE/Hmm2+ioKDA7HkZGRlW36OjREVFoXv37li1apVJe48fP47t27fjjjvukI9Ze1+W9OjRA+Hh4Vi+fLnJNNOtW7fi5MmTNg2/GBUXF2Pjxo248847MWHCBLPbrFmzkJ+fL9d9jR8/HkeOHLE4Xdz4/R0/fjwyMzMtZk6M58TFxUGlUsn1CkaWPhPWWPpcCSHMpno3b94cAwcOxIoVK5CammqxPUZhYWEYOXIk/ve//2H16tUYMWJEnWZmbdmyBcOGDbPrsF9DZGVlmXytVCrlWUDGz05dvpd33HEH0tLSTGpwysvL8e6778Lf318ebrQmPDwcgwcPxgcffCD/p6mquvx8KpVKTJgwAd9++y0+++wzlJeXmwWl1d+vRqNBx44dIYSATqcDALnesCFbJMyZMwdZWVn46KOPAEgzjfR6PRYtWmR2bnl5udnP9cSJE3H16lV8/PHHOHLkSJ2C63vvvRd79+7F999/b/ZYTk4OysvL5a+NQ1uvvfYaunbtiqCgIPn4zp078ccff9hl+MvYritXrsh9UVVxcbHNw/wqlQpDhgzBpk2bcPXqVfl4SkoKtm7dana+n59fo9vexz1+exD+8Y9/oKioCGPHjkX79u1RVlaGPXv2YN26dYiPj5fX5mjdujVeeuklLFq0CAMGDMC4ceOg1Wrx+++/Izo6GkuWLEHfvn0REhKCyZMn44knnoBCocBnn31mMcBKSkrCunXrMHv2bPTs2RP+/v4YPXo0EhMTERwcjOXLlyMgIAB+fn7o3bs3EhIS8PHHH2PkyJHo1KkTpk6dipiYGFy5cgU//fQTAgMD8e233zq7+/DGG29g5MiR6NOnD6ZNmyZPgw8KCsIrr7xi8n4BaQmA++67D2q1GqNHj7a4yJ9arcZrr72GqVOnYtCgQbj//vvlafDx8fF4+umnbW7nN998g/z8fNx1110WH7/lllvQvHlzrF69GhMnTsRzzz2HDRs24J577sFDDz2EpKQkZGdn45tvvsHy5cvRrVs3TJo0Cf/9738xe/Zs7N+/HwMGDEBhYSF++OEHPPbYY7j77rsRFBSEe+65B++++y4UCgUSExPx3Xff2bTIZvv27ZGYmIhnn30WV65cQWBgIL788kuLY/z//ve/0b9/f9x8882YMWMGEhIScOHCBWzevNlse5VJkybJC19a+sNWXXFxMX766ScsX768zm2vi6NHj8qBZ0pKCnJzc/Hqq68CALp164bRo0dbfe7DDz+M7Oxs3HbbbWjRogUuXryId999F927d5frd+ryvZwxYwY++OADTJkyBQcOHEB8fDw2bNiAX3/9FW+//TYCAgJqfR/vv/8++vfvjy5dumD69Olo1aoV0tPTsXfvXly+fBlHjhyp9RoTJ07Eu+++i/nz56NLly5mU7iHDRuGyMhI9OvXDxERETh58iTee+89jBo1Sm7j/v37ceutt2L+/PkmP4O2GDlyJDp37oylS5fi8ccfx6BBg/DII49gyZIlOHz4MIYNGwa1Wo2zZ89i/fr1eOedd+TPEgB5Hatnn30WKpUK48ePr/U1n3vuOXzzzTe48847MWXKFCQlJaGwsBDHjh3Dhg0bcOHCBTlIb926NSIjI3H69GmTSQgDBw7EnDlzAMCmAGjnzp0oKSkxOz5mzBj8/e9/xxdffIFHH30UP/30E/r16we9Xo9Tp07hiy++wPfff1/jQp+WvPLKK9i+fTv69euHmTNnQq/X47333kPnzp3Nfk6TkpLwww8/YOnSpYiOjkZCQoLnb+Hj/IlnZMnWrVvFQw89JNq3by/8/f2FRqMRrVu3Fv/4xz9Eenq62fkrVqwQN910k9BqtSIkJEQMGjRInlIthBC//vqruOWWW4SPj4+Ijo6Wp9Wj2lTogoIC8cADD4jg4GABwGTq79dffy06duwoT4msOlX60KFDYty4caJZs2ZCq9WKuLg4ce+994qdO3fK5xinR2ZkZNSpD4xTtdevX1/jeZambgshxA8//CD69esnfHx8RGBgoBg9erQ8RbWqRYsWiZiYGKFUKus0jXrdunVyX4eGhooHH3xQXL582eScuk6DHz16tPD29haFhYVWz5kyZYpQq9UiMzNTCCFEVlaWmDVrloiJiREajUa0aNFCTJ48WX5cCGl6+ksvvSQSEhKEWq0WkZGRYsKECeLcuXPyORkZGWL8+PHC19dXhISEiEceeUQcP37c4jR4Pz8/i207ceKEGDJkiPD39xdhYWFi+vTp8vTa6t+P48ePi7Fjx4rg4GDh7e0t2rVrJ15++WWza5aWloqQkBARFBRkstyANd99951QKBQWfy4sqev3pqbp8pam/1a1YcMGMWzYMBEeHi40Go1o2bKleOSRR8S1a9dMzqvL9zI9PV1MnTpVhIWFCY1GI7p06WLWt7VNmz537pyYNGmSiIyMFGq1WsTExIg777xTbNiwocb3YWQwGERsbKwAIF599VWzxz/44AMxcOBA+ec/MTFRPPfccyI3N1c+x/jzXJclDeLi4sSoUaMsPvbpp5+afb4+/PBDkZSUJHx8fERAQIDo0qWLeP7558XVq1fNnv/ggw8KAGLIkCFWX7v69zc/P1/MnTtXtG7dWmg0GhEWFib69u0r3nzzTbOlSe655x4BQKxbt04+VlZWJnx9fYVGo6nTZ9r4/bR2++yzz+Trvvbaa6JTp07y7/6kpCSxYMECk75HteUDanqvO3fuFDfddJPQaDQiMTFRfPzxx+KZZ54R3t7eJuedOnVKDBw4UPj4+Jj8TFj7PW/8earLkiOuohDCjSuUiKjRKy8vR3R0NEaPHo1PPvmk1vMfe+wx/PHHH9i/f78TWkfU9IwZMwZ//vmnPOu3seIQGBG51KZNm5CRkWFSWF2T7t271zgcRUR1V1xcbFJQfvbsWWzZskXe3qcxYwaIiFxi3759OHr0KBYtWoSwsDAcPHjQ1U0ianKioqLkjWcvXryIZcuWobS0FIcOHUKbNm1c3TyHYgaIiFxi2bJl+N///ofu3bubbMZKRM4zYsQIfP7550hLS4NWq0WfPn2wePHiRh/8AMwAERERURPEdYCIiIioyWEARERERE0Oa4AsMBgMuHr1KgICAhrl8t9ERESNkRAC+fn5iI6ONtvP0NLJLvXee++JuLg4odVqRa9evcS+fftqPP/GjRviscceE5GRkUKj0Yg2bdqIzZs3y48bF2WqemvXrp1Nbbp06VKNi1LxxhtvvPHGG2/ue7t06VKtf+tdmgEybsGwfPly9O7dG2+//TaGDx+O06dPIzw83Oz8srIyDB06FOHh4diwYQNiYmJw8eJFBAcHm5zXqVMn/PDDD/LXtu4XZFzK/dKlSwgMDLT9jVWj0+mwfft2edl2qsS+sY59Yxn7xTr2jXXsG+saU9/k5eUhNja2TtvGuDQAWrp0KaZPny7vc7V8+XJs3rwZK1aswAsvvGB2/ooVK5CdnY09e/bI36T4+Hiz87y8vBAZGVnvdhmHvQIDA+0WAPn6+iIwMNDjP1z2xr6xjn1jGfvFOvaNdewb6xpj39SlfMVlAVBZWRkOHDiAuXPnyseUSiWGDBmCvXv3WnzON998gz59+uDxxx/H119/jebNm+OBBx7AnDlz5J2qAWkly+joaHh7e6NPnz5YsmQJWrZsabUtpaWlJrt95+XlAZA+FMadjRvCeA17XKuxYd9Yx76xjP1iHfvGOvaNdY2pb2x5Dy5bB+jq1auIiYnBnj170KdPH/n4888/j127dmHfvn1mz2nfvj0uXLiABx98EI899hhSUlLw2GOP4YknnsD8+fMBAFu3bkVBQQHatWuHa9euYcGCBbhy5QqOHz9uNSX2yiuvYMGCBWbH16xZA19fXzu9YyIiInKkoqIiPPDAA8jNza11BMejAqC2bduipKQE58+flzM+S5cuxRtvvIFr165ZfJ2cnBzExcVh6dKlmDZtmsVzLGWAYmNjkZmZabchsB07dmDo0KGNJr1oL+wb69g3lrFfrGPfWMe+sa4x9U1eXh7CwsLqFAC5bAgsLCwMKpUK6enpJsfT09Ot1u9ERUVBrVabDHd16NABaWlpKCsrg0ajMXtOcHAw2rZti5SUFKtt0Wq10Gq1ZsfVarVdPwz2vl5jwr6xjn1jGfvFOvaNdewb6xpD39jSfpcthKjRaJCUlISdO3fKxwwGA3bu3GmSEaqqX79+SElJgcFgkI+dOXMGUVFRFoMfACgoKMC5c+cQFRVl3zdAREREHsulK0HPnj0bH330EVatWoWTJ09i5syZKCwslGeFTZo0yaRIeubMmcjOzsaTTz6JM2fOYPPmzVi8eDEef/xx+Zxnn30Wu3btwoULF7Bnzx6MHTsWKpUK999/v9PfHxEREbknl06DnzhxIjIyMjBv3jykpaWhe/fu2LZtGyIiIgAAqampJis5xsbG4vvvv8fTTz+Nrl27IiYmBk8++STmzJkjn3P58mXcf//9yMrKQvPmzdG/f3/89ttvaN68udPfHxEREbknl2+FMWvWLMyaNcviY8nJyWbH+vTpg99++83q9dauXWuvphEREVEjxc1QiYiIqMlhAERERERNDgMgIiIianIYABEREVGTwwDIQ5WVG6DTG2o/kYiIiMwwAPJABoPAqH/vxvC3f0Y5gyAiIiKbuXwaPNkut1iHs9cLAACXbxQjPszPxS0iIiLyLMwAeaCC0nL5/oWsQhe2hIiIyDMxAPJAeSU6+f7FrCIXtoSIiMgzMQDyQAUlzAARERE1BAMgD1R1CIwZICIiItsxAPJA+cwAERERNQgDIA+UXyUDdCm7CHqDcGFriIiIPA8DIA+UX6UIWqcXuJpT7MLWEBEReR4GQB6oahE0wDogIiIiWzEA8kBVi6AB1gERERHZigGQBzIWQauUCgDARQZARERENmEA5IGMAVCbcH8AwAUOgREREdmEAZAHMhZBd44JAsAMEBERka0YAHkgYw1QFzkAKoKBU+GJiIjqjAGQBzIGQO0iA+ClVKC03ID0/BIXt4qIiMhzMADyQMYaoGBfNVqE+AAALmSyDoiIiKiuGAB5IOM6QAHeasQ18wPAOiAiIiJbMADyMCU6Pcr0BgCAv9YL8c18AXAmGBERkS0YAHmYqosg+mu9mAEiIiKqBwZAHsY4/OWnUUGlVCA+jBkgIiIiWzEA8jDGAmh/by8AMMkACcGp8ERERHXBAMjD5JdKiyAGeKsBAC1CfKBUAEVlemQUlLqyaURERB6DAZCHkTNAWikDpPVSITpYmgrPXeGJiIjqhgGQh6mcAu8lH4uvGAa7kMlCaCIiorpgAORhjLPAqgZAcRVT4ZkBIiIiqhsGQB7GuBGqcQgMqJIB4lR4IiKiOmEA5GHySytXgTZiBoiIiMg2DIA8TPUiaACID6vMAHEqPBERUe0YAHkYS0XQLUOlDFB+STluFOlc0i4iIiJPwgDIw1gqgvZWqxAV5A2AdUBERER1wQDIw1QWQatNjlfWATEAIiIiqg0DIA+Tb2EIDAASjHVAmSyEJiIiqg0DIA9TfS8wI+4KT0REVHcMgDyMsQYosFoAFN+Mu8ITERHVFQMgDyKEkAMg8xogZoCIiIjqigGQBynW6aE3SOv8VK8BMhZB3yjSIZdT4YmIiGrEAMiDGNcAUigAX43K5DFfjRfCA7QAgIvZzAIRERHVhAGQB8mrsgq0QqEwe7xyTzDWAREREdWEAZAHqSyAVlt8XF4LKJMZICIiopowAPIgBRb2Aauqck8wZoCIiIhqwgDIgxhXga5eAG3E1aCJiIjqhgGQB8kvtbwIohFrgIiIiOqGAZAHya9lCKxlRQYos6BUrhciIiIicwyAPEiBvA+Y5SLoQG81mvlpAHAYjIiIqCYMgDxIQWnNNUBA1TogDoMRERFZwwDIg8g7wVsZAgOq1gExA0RERGSNywOg999/H/Hx8fD29kbv3r2xf//+Gs/PycnB448/jqioKGi1WrRt2xZbtmxp0DU9RW1F0ECVPcEymQEiIiKyxqUB0Lp16zB79mzMnz8fBw8eRLdu3TB8+HBcv37d4vllZWUYOnQoLly4gA0bNuD06dP46KOPEBMTU+9repLaiqABID7MuCs8M0BERETWuDQAWrp0KaZPn46pU6eiY8eOWL58OXx9fbFixQqL569YsQLZ2dnYtGkT+vXrh/j4eAwaNAjdunWr9zU9SYG8DpDlImig6q7wzAARERFZYz2V4GBlZWU4cOAA5s6dKx9TKpUYMmQI9u7da/E533zzDfr06YPHH38cX3/9NZo3b44HHngAc+bMgUqlqtc1AaC0tBSlpaXy13l5eQAAnU4Hna7hO6sbr9HQaxkXQvTxsn6tmEBpFlhaXgnyCkvgU23TVHdjr75pjNg3lrFfrGPfWMe+sc7efaM3COQU65BdWIYbRWXILjTel/413r+rWyTG3RRT+wVtYMt7cFkAlJmZCb1ej4iICJPjEREROHXqlMXn/PXXX/jxxx/x4IMPYsuWLUhJScFjjz0GnU6H+fPn1+uaALBkyRIsWLDA7Pj27dvh6+tbj3dn2Y4dOxr0/IwcFQAFjh7Yh5zT1s/zVqlQoldg7bffI8KnQS/pNA3tm8aMfWMZ+8U69o117BvrrPWNzgAU6KRbYblCul8OFOqq3S+XzikqBwTMN+yuTluUAe9rR+z6HoqK6j764bIAqD4MBgPCw8Px4YcfQqVSISkpCVeuXMEbb7yB+fPn1/u6c+fOxezZs+Wv8/LyEBsbi2HDhiEwMLDB7dbpdNixYweGDh0Ktdr68FVtXjr4I4ByDL9tEBIq9v2yZOnpX3AxuwhdevRBj7iQer+eM9irbxoj9o1l7Bfr2DfWsW8kQgjkl5Qju6gMNyoyMxn5xdh/5ASaRccjt6Qc2UU63KjI1GQX6VBUpq/XawX5eCHEV4NQPw1CfdUI8dMg1FeDUD81Qnw16BAVgPaRAXZ9f8YRnLpwWQAUFhYGlUqF9PR0k+Pp6emIjIy0+JyoqCio1WqoVJXDOh06dEBaWhrKysrqdU0A0Gq10Gq1ZsfVarVdf1Aacj2DQaCwTCqCDvb3rvE6zfw1uJhdhNwSg8f8oNu7rxsT9o1l7Bfr2DfWNba+KdcbkF1UJg8tVb9lFZbJwYzxfrlBWLiSCki9ZPV1vJQKhPhp0MxPCmiq3m9W8bV0X4uQigBHrXJ+mbEt31uXBUAajQZJSUnYuXMnxowZA0DK8OzcuROzZs2y+Jx+/fphzZo1MBgMUCqljj1z5gyioqKg0Ui1L7Ze01MUlpVDVHxmA2soggaA0IrVoLMLyxzdLCIisqOisnJkFUi1M1mFZciudr96sJNbXL+6HT+NSg5ign3VKLpxHV3bJiAswAehfmqE+mmlzE3FLdDbCwpF7cNansSlQ2CzZ8/G5MmT0aNHD/Tq1Qtvv/02CgsLMXXqVADApEmTEBMTgyVLlgAAZs6ciffeew9PPvkk/vGPf+Ds2bNYvHgxnnjiiTpf01MZ9/byUiqg9ao5qjYGQDeKGAAREbmKwSCQW6yTgxZjYGO8n11YiuwinfRvRXBTojPY/DoKBRDsozbJwIT6aeUMjaWbt7pyJEWn02HLli24Y0S7RpUdq41LA6CJEyciIyMD8+bNQ1paGrp3745t27bJRcypqalypgcAYmNj8f333+Ppp59G165dERMTgyeffBJz5syp8zU9lbwKdB2i8JCKACirgAEQEZG9lJUbqg0vlZoOLxUZAxvp/o0iHfQWh5tqplEp5UClmb9GrqNpVm3oyXgL9tVApWxc2RlncHkR9KxZs6wOTyUnJ5sd69OnD3777bd6X9NTyYsg1rAKtFEzZoCIiGokhEBBaTluFOqQVVhqtXYmyzhtu7BMXo3fVgFaL4T6G4uBK/71rwhofKUgJ9RPKz3mr4GfRtXohpvckcsDIKob4xpA/tra05OhflJBdxZrgIioidAbhJR1qRK0VL1l5pfgTKoSy87vRU7FejRletuHm1RKBUJ81RaGlbQI9VUj1F9rEtiE+GqgqaVsgVyDAZCHMNYA1bQTvFGonxQk3WAAREQeqkSnt5KNKbWYqckp1skTRaxTArn5Jke81Uo0q1bwW/1Wdegp0FsNJYebGgUGQB6ioPpO8Af/CwgBJE02O9eYAeIsMCJyB0II5BWXVxQDl5rNcrI0jbv+a8+oLU7VDvJW4VLKSdzatyeaB/rIBcPuvlo+OQ4DIA9RtQgaumLg26cAYQA63g34BJucG+pbUQRdWAoiInvT6Q3ybKaqAYxZYFNYVrHgnrW1Z2qmVikqC4ArhpOaGYebLEzVDvFVw8vK2jM6nQ5bck9gYJuwJjXTiaxjAOQhjMV3/t5eQFkhICr+d5Rz0TwA8pcCoBKdAcVlev4Ph4isEkKgqExvloGxNPR0o0iHrIJS5JXUrxjYT6OqKAauqJfx01YLbKpkbfw1CNA2vrVnyH0wAPIQJkXQuip7neRcAqK6mZzrp1FBo1KiTG9AVmEpWmjst58ZEbk3g5BmgOaVVp/ZVFqxKWWpPGU7u0AKbkrL67f2jLzNgXF2k9nMJtNi4KprzxC5GgMgD1FQfQjMKCfV7FyFQoFQPw3S8kpwo1CHFu69HRgR1aC0XG91qrZ5pqYUNwpVEL8l2/w6Gi+l5YXzLAY2WgT5qLn2DHk0BkAewmQWmK7KLAYLARAAOQBiHRCR+zCuPWNtnRlL07cLbF57RgpKAry9LAQ0lbUz1RfV8+XaM9TEMADyEGZF0EY1BEAAF0MkciTj2jOWCoDl+1WGnm4U6hqw9oxxOrZanrZdfVXgQK0Sh37bjfF3joCfj/kGz0RUiQGQh5CLoKvXAOXWHABxOwyiuivR6atNzS4127+pMrCRNqKsfe0Zcz5qlYWZTZa3OWjmp0WAt1ed1p7R6XT4SwMuvEdUBwyAPERlEbQXUFb3DBDXAqKmyrj2TFZhqckeTcahJ0v7NxXr6rf2TLBxZeBqU7aN96tucxDqq+HMTCI3wADIQ5gUQRdWCYBKcoHiHPOp8BwCo0ZGpzfgRmEZ0nOLcCZXAXEsDbkl1qdv5xTVf+0Zi/UyVmY5BftYX3uGiNwXAyAPYVoEXWT6YO4lswCIO8KTO7O09kxt2x3km6w9owJOHK3Ta/lrvawOL1Wf5RTqp4E/154hahIYAHmAcr1BXhY+wFttWgQNSMNgkV1MDnFHeHImg0Egp1hnvtaMlZlN2fVce0apkIabNIYyxEaEIszf+h5Ozfy0CPZVc+0ZIrKIAZAHKCytrEvw06qklaCryrlk9hy5CJo1QFQPpeWWh5aM2Zjq+zflFJWhHqNN0FasPRNiYdPJ6tsdNPPTINBHDYO+HFu2bMEdd/TklgZEVG8MgDxAXkUBtMZLCa2XynIGqBoWQZOREAL5peWVQUuVPZrMZzZJU7VtX3tGEujthWb+WoT4Wl5rpvqtPmvPGOpXp0xEZIIBkAcw/jEK9K74dhkDII0/UFYg7QdWjTEAyi3WoVxvYJFmI1KuN+BGkc5k9lJlYFOK7CKdPH07u2KWk05ve3rGS6mQMjPG7Q78TWc5Va2fMW55oObnjIg8BAMgJ9p3Pht7z99A5+ggjOwSVefnFchrABkDoIoi6LC2wNWDFjNAwT7S0IAQQE6xDmH+XBTNk+QUlWHF7r/w+zklvltzGDeKdHKgk1Okq9c1fTWqOm9zEOqrQaAPi4GJqPFiAOREh1Jz8P5P53BvjxY2BUDGNYACvCvqHYwZoObtpQAo17wGyEulRLCvGjlFOtwoLGMA5GGWbDmFdX9cAqAErl83e1yhkIJc0+El69schPpxI0oioqoYADlRQMUQlul03toZzzfLADVvK/1bfAMoyQO8A02eF+qrQU6RDlmFZWhT/2aTk6XllmDjocsAgNuiDRiU1AnNA31MioS59gwRUcMwAHIiYwBja4GpyT5gQGUGyC8c8AkFirOlLJB3J5Pnhfpp8FdmIW6wENqjfPLLX9DpBXrGh+DuqAzc0SuWs52IiOyM/4V0ImMAZGsGSK4Bqh4AqX2A4JbS/RpmgnEqvOfIKSrDmn3S9/KRAfGubQwRUSPGAMiJ/OUhMNuKWOVtMKoPgal9geBY6T6nwjcKn+29iMIyPdpHBmBgmzBXN4eIqNFiAORE9R8Cs1IErfYBguOk+wyAPF5xmR4r91wAAMwcnMgZWEREDsQAyInqXQRtNgRWNQNU+xAYAyDP8MUfl5BdWIbYUB+MsmGWIBER2Y4BkBMZM0BFZXrobdg3wGoRdB1rgLgfmPvT6Q348Oe/AAAzBiZyhhcRkYPxt6wTydPYYdswWIHZNPgqAVBQ7TVA3BHe/X139Cqu5BQjzF+De5JauLo5RESNHgMgJ5L28pK63JZCaGOwFODtJS3tbKkIujgbKC0weR4zQJ7BYBBYlnwOADC1XwIXLCQicgIGQE5mHMayJQNkUgSt1wGiYjdItQ/gHQR4B0tfV1sRuuo0eCHqsVU3OcWPp67jTHoB/LVe+Nstca5uDhFRk8AAyMnqsxaQyV5gxuwPIGWAAKt1QMYAqKzcgMIybqHtjoQQ+E9yCgDgwVtaIsiHCx4SETkDAyAnM05lL7AhAMqrWgRtrP9RqABVxR9LKwGQr8YL3mrpW8zVoN3T7xdu4GBqDjReSkzrl+Dq5hARNRkMgJxMzgDVcQistFyPsnIDACBAqzat/zGuEyMHQBfNnh/qy9Wg3dmyiuzPhKQWCA/0dnFriIiaDgZAThZg42rQhaWVQ1d+WlWVAMin8iQ5ADLfFT7Uv6IQmgGQ2zl5LQ8/nc6AUgHMGNDK1c0hImpSGAA5mXExw7oOgRkDJV+NSlobpuoUeKMa1wLSAmAGyB0t3yXN/LqjSxTiw/xc3BoioqaFAZCTBdhYBJ1vtgZQlSEwo5oCIF+pTii7sLQerSVHSc0qwrdHrgIAHh2U6OLWEBE1PQyAnEwugq5jDVCNq0AbGRdDLMoEygpNnm/MAGUX2rYBKznWR7v/gkEAA9s2R+eYIFc3h4ioyWEA5GT+Nu4HJk+BlzdCrcgAaaoMmfgEA9qKP6K5l02eH+rHDJC7ycgvxRd/SPVaM5n9ISJyCQZATmZrEXRBacUiiJa2wajK6lpAzAC5m0/3nEdpuQHdY4NxS6tQVzeHiKhJYgDkZMZaHrsOgQFWp8IzA+Re8kt0+O9e6Xs0c3AiFMalDIiIyKkYADlZgI1DYHUqggYq9wSzkgG6UcQMkDtYsy8V+SXlSGzuh6EdIlzdHCKiJosBkJPVvwjaWANk6xCYcUd4ZoBcrUSnx8e/nAcgzfxSKpn9ISJyFQZATmbrXmDGGiB/79oyQJYXQzQGQHkl5dDpDfVoMdnLV4euICO/FFFB3ri7e4yrm0NE1KQxAHIym4ugjRmgehZBB/moYUw03CjiYoiuojcIfFCx8OHDA1pB48UfPSIiV+JvYScL0EpDWaXlBnmPr5qYF0Fb2AoDqFwLqPB6ZZAEQKVUILhiP7BsrgbtMtuOp+FCVhGCfdW4r2esq5tDRNTkMQByMj+tSr5flzqgfHkdoOoZoGpDYD4hgCZAum9lGIwBkGsIIbBsl7Tp6eQ+8fAzZvOIiMhlGAA5mZdKCV+NFATVZT+wOhdBKxSVw2C51QqhmQFyqV9SMnH8Sh581CpM7hvv6uYQEREYALmEXAhdWnsdkFwEXds0eKDWmWDcEd41liVLtT/39YqVvxdERORaDIBcwJa1gArquhAiYD0A8q+YCs8AyOkOX8rBnnNZ8FIq8PCAVq5uDhERVWAA5ALGfb1qGwITQtS9CBqwvhgih8BcZnlF9ufu7jGICbbwPSMiIpdgAOQCAXUcAistN6DcIABUHQKzUgQN1DoExgDIuVKuF+D7E2kAgEcHMftDROROGAC5gDGbU1sGKK9irSCFAvDTVARAZTVlgGpeDJEBkHN9+PM5CAEM7RiBNhEBrm4OERFVwQDIBSqLoGsOgIwBkr/Gq3LbhBqLoOMqnpgG6ErkwwyAnO9abjG+OnQFgLTpKRERuRe3CIDef/99xMfHw9vbG71798b+/futnvvpp59CoVCY3Ly9vU3OmTJlitk5I0aMcPTbqDPjlPbaiqALqq8BBNRcBO0TAqj9pPu5l+XDDICc75Pd56HTC/ROCMXNLUNc3RwiIqrG5QHQunXrMHv2bMyfPx8HDx5Et27dMHz4cFy/ft3qcwIDA3Ht2jX5dvHiRbNzRowYYXLO559/7si3YRP/Og6BmRVAG/SAvmJTU2OgU1XVtYByKvtEngZfVAYhRANaTnVxo7AMa/ZLdVjM/hARuSeXB0BLly7F9OnTMXXqVHTs2BHLly+Hr68vVqxYYfU5CoUCkZGR8i0iIsLsHK1Wa3JOSIj7/C9cLoKuZT8wYwBkVgANWM4AAVUWQ6ysAzIGQDq9qHXYjRruv3svoqhMjw5RgRjUtrmrm0NERBa4dE3+srIyHDhwAHPnzpWPKZVKDBkyBHv37rX6vIKCAsTFxcFgMODmm2/G4sWL0alTJ5NzkpOTER4ejpCQENx222149dVX0axZM4vXKy0tRWlpqfx1Xl4eAECn00Gnq9umpTUxXsP4r69aqufJK675+jmFUh2Pv1YlnVecB7XxmlABFp6rDGwBFQB91gUYKh5XAfDVqFBUpsf1nCL4NLNQP+Qi1fvG0xWVlePTPecBADP6x6G8vP4BZ2PrG3thv1jHvrGOfWNdY+obW96DSwOgzMxM6PV6swxOREQETp06ZfE57dq1w4oVK9C1a1fk5ubizTffRN++ffHnn3+iRYsWAKThr3HjxiEhIQHnzp3Diy++iJEjR2Lv3r1QqVRm11yyZAkWLFhgdnz79u3w9bVfsLBjxw4AwNlMBQAVUq9dx5YtW6yev/+adF5+dga2bNkCn9IMDANQrtBgy9ZtFp/TOr0AnQBcPfkbDhZXXttboUIRFNj8QzLi3XBCkrFvPN2uawrcKFKhmVZAXDqELZcPNfiajaVv7I39Yh37xjr2jXWNoW+KiorqfK7H7crYp08f9OnTR/66b9++6NChAz744AMsWrQIAHDffffJj3fp0gVdu3ZFYmIikpOTcfvtt5tdc+7cuZg9e7b8dV5eHmJjYzFs2DAEBgY2uM06nQ47duzA0KFDoVarEXA2E5+ePQi1byDuuKOP1eedT/4LuJCCNvGxuOOOTkDGaeAEoPL2xx133GHxOYqTOmDjOsT46RFZ5ZyPU39D9pU8tOvWA7e3D2/we7KX6n3jyXR6A/7vrV8AlODJ4R0xuoG7vjemvrEn9ot17Bvr2DfWNaa+MY7g1IVLA6CwsDCoVCqkp6ebHE9PT0dkZGSdrqFWq3HTTTchJSXF6jmtWrVCWFgYUlJSLAZAWq0WWq3W4rXt+WEwXi/IT5q1Vlimr/H6RToDACDIVyOdJ6RZXAq1r/XnNUsAAChzL0FZ5Zxm/tL7yys1uOUH3N597QrfHL2Ma7klCPPX4t6ecVCrzbON9dEY+sYR2C/WsW+sY99Y1xj6xpb2u7QIWqPRICkpCTt37pSPGQwG7Ny50yTLUxO9Xo9jx44hKirK6jmXL19GVlZWjec4U+VeYHUtgq5lJ/iqjGsB5acB5ZV1TZwK71gGg8DyXdK2F9P6J8DbTsEPERE5hstngc2ePRsfffQRVq1ahZMnT2LmzJkoLCzE1KlTAQCTJk0yKZJeuHAhtm/fjr/++gsHDx7E3/72N1y8eBEPP/wwAKlA+rnnnsNvv/2GCxcuYOfOnbj77rvRunVrDB8+3CXvsTp5JejS8hqnpRsDpDpthGrk2wzw8gEggLyr8mHuB+ZYO09dx9nrBQjQeuHBW1q6ujlERFQLl9cATZw4ERkZGZg3bx7S0tLQvXt3bNu2TS6MTk1NhVJZGafduHED06dPR1paGkJCQpCUlIQ9e/agY8eOAACVSoWjR49i1apVyMnJQXR0NIYNG4ZFixZZHOZyBeO0dp1eoLTcYDVbYLYQYk2rQBspFIBvKJB3BSi+AUAaEjPuCM8AyP6EEPhPsjQE+7c+cQj09uwUMhFRU+DyAAgAZs2ahVmzZll8LDk52eTrt956C2+99ZbVa/n4+OD777+3Z/Pszk/jBYUCEEIa5rIaABkXQjTbCLWWXcW9g6UAqCRHPsQMkOPsP5+NQ6k50HgpMbVfvKubQ0REdeDyIbCmSKlUwF9TOQxmTeVK0MYaoDpkgADAJ1j6tzhHPsQaIMdZVlH7c09SC4QHeNdyNhERuQMGQC7iX4dCaPMhMBsyQIBpBogBkEOcuJqH5NMZUCqAGQNbubo5RERURwyAXCSgDvuB5ZkVQRszQLUEQDVkgG4wALIr48yvUV2jEdfMwv5sRETklhgAuYixENra3lxCCDkDZF4DVMsQmIUMUDM/rfx6peX6erWZTKVmFeG7o9JMu0cHMftDRORJGAC5iH9FXU++lQxQUZkexhnylTVAdRwCs5ABCvD2gkop7UF2o9Dz93txBx/uPgeDAAa1bY5O0UGubg4REdmAAZCLVA6BWQ5GjIGRSqmAt7ri26QrlP6tRwZIqVQghDPB7CYjvxRf/HEZADBzcKKLW0NERLZiAOQixmEtaxmgjHxpFedQPw0UCilz05AMkHQtKZPEAKjhVv56HmXlBtzUMhi9E0Jd3RwiIrIRAyAXqboatCVXc6VgJzqoyrTquhZBGzNAxTdMDsszwYoYADVEXokOn+29CACYOSixMkAlIiKPwQDIRYz7e1krgr6WIwVAUUFVgh1jBkhTy2wjYwaoyhAYUCUAKigF1d+afanILy1H63B/DOkQ4ermEBFRPTAAcpHKdYCsBEC5JQCAqOCqGSAb1wEqzjU5zLWAGq5Ep8cnv5wHADw6KBFKJbM/RESeiAGQi9RWBC0HQBaHwOq4EnRpLmConPIeWjEVnkNg9bfx4BVk5JciOsgbd3WLdnVziIionhgAuUhtRdDXcmsYAqtrBggASiqzQKG+LIJuCL1B4IOfpYUPHx7QChov/vgQEXkq/gZ3EePaPlaLoHOkDFB0cD0yQF6aynOqbofhX5EBYgBUL1uPX8PFrCIE+6pxX69YVzeHiIgagAGQi9RUA6Q3CKTnGYfA6pEBAqrUAeXIh7gjfP0JIbAsWcr+TOkbD9+KzWyJiMgzMQByEXkrDAs1QJkFpSg3CCgVQHiAtvIBWwIgCzPBKouguRK0rXafzcSfV/Pgo1Zhcp94VzeHiIgaiAGQiwRWWQdIGPe8qGAsgA4P8IaXquJbJETdh8AAyxkg44aoRWUwGIT5c8gqY/bn/l4tEVLRj0RE5LkYALmIcQjMIKR9v6qS1wCqWv+jLwOEQbpfzwxQSMVK0HqDkHeap9odSr2BvX9lwUupwMMDElzdHCIisgMGQC7io1bJm5NWL4S+WpEBijap/ymqvF/PDJDWSyXPPmMdUN0Zsz9jbopBdHAdgk8iInJ7DIBcRKFQVKkDMg2AKleBtrAIotILUKlrfwErq0GHcDFEm6Rcz8f2E+kAgEcHtXJxa4iIyF5sDoDi4+OxcOFCpKamOqI9TYq1QujKVaAtzQCrQ/YHsJgBArgatK2W7/oLADCsYwRahwe4uDVERGQvNgdATz31FDZu3IhWrVph6NChWLt2LUpLubdUfVjbELVBG6Ea1bYfGAOgWl3NKcamQ1cAADMHJ7q4NUREZE/1CoAOHz6M/fv3o0OHDvjHP/6BqKgozJo1CwcPHnREGxutACtrAaVVZIAiLQ2B1TUAqi0DxO0wavXx7vMoNwj0adUMN7UMcXVziIjIjupdA3TzzTfj3//+N65evYr58+fj448/Rs+ePdG9e3esWLHCbGo3mZNXg64SAJXrDfIiiCYFt7ZMgQesZoCayTvCMwCqyY3CMny+XxrmZfaHiKjxqfdytjqdDl999RVWrlyJHTt24JZbbsG0adNw+fJlvPjii/jhhx+wZs0ae7a10ZFrgKoMgV3PL4VBAF5KBcL8qyyCWGbrEFhFxqJaBohF0HWzau8FFOv06BQdiAFtwlzdHCIisjObA6CDBw9i5cqV+Pzzz6FUKjFp0iS89dZbaN++vXzO2LFj0bNnT7s2tDGq3A6jsgjauAlqRKC3PE0egO0ZIOMQmLUaIA6BWVVUVo5P91wAIGV/FApFzU8gIiKPY3MA1LNnTwwdOhTLli3DmDFjoFabT8lOSEjAfffdZ5cGNmZyEXSVITCLm6ACts8Ck4fA8gCDAVBKo53cD6x2a/dfQk6RDnHNfDGyc5Srm0NERA5gcwD0119/IS4ursZz/Pz8sHLlyno3qqkIsLAOUGUBdLWhrvoWQUMApbnykFioPwOgmpSVG/Dxbmnq+yMDE02zcERE1GjYXAR9/fp17Nu3z+z4vn378Mcff9ilUU2FXARdpQbI4hR4wPYhMC9N5bncEb7OvjlyFVdzS9A8QItxN8e4ujlEROQgNgdAjz/+OC5dumR2/MqVK3j88cft0qimwlIR9LWKIbAoswDIxgwQYLEOyJgBKirTo0SnN39OE2YwCCzfJW17Ma1/ArzVKhe3iIiIHMXmAOjEiRO4+eabzY7fdNNNOHHihF0a1VTUVAQdVX3PKVsXQgQq64CqZIACtF5Qq6RhHWaBTP1wMh0p1wsQ4O2FB3u3dHVziIjIgWwOgLRaLdLT082OX7t2DV5e9Z5V3yRZLIK2tBEqYHsRNGAxA6RQKBDCYTAzQgj8p2LT07/fEicPTxIRUeNkcwA0bNgwzJ07F7m5ufKxnJwcvPjiixg6dKhdG9fYBWilP7LGIuiycgMyC6RtRaKszgJrWAYI4HYYluw7n43Dl3Kg8VJiar8EVzeHiIgczOaUzZtvvomBAwciLi4ON910EwDg8OHDiIiIwGeffWb3BjZm1fcCS88rgRCARqWUi5VlthZBA7WvBcQASLasIvtzb48WaB6greVsIiLydDYHQDExMTh69ChWr16NI0eOwMfHB1OnTsX9999vcU0gss6/SgBkMAh5F/jIIG8oq0+/ZgbIYf68motdZzKgVAAzBnDbCyKipqBeRTt+fn6YMWOGvdvS5BhngQFAQVl5ZQF09RlgADNADrR8l7Tuz51do9GymQ39S0REHqveVcsnTpxAamoqyspM/4jeddddDW5UU+GtVkGjUqJMb0BBSXmVVaAtZHkckAHKYgCEi1mF2Hz0KgDg0UFulP0puA7l3uVITL8CxUkdEJoABLUA/MMBbs1BRNRg9VoJeuzYsTh27BgUCoW867txvyS9nmvL2MLf2wvZhWXIL6ktA2SfdYCAyh3hbzAAwoc//wWDAAa3a46O0YGubo5EXw58MQmq1L3oDAAb11Y+ptJKgVBwLBBUcQuu8m9gDKDiUDQRUW1sDoCefPJJJCQkYOfOnUhISMD+/fuRlZWFZ555Bm+++aYj2tioBVQEQAWlOrkGyG5DYFYyQNwRXnI9vwTrD1wGAMx0p+zPrteA1L0QGn9c8euMaD8DlLmXgfxrgL4UyD4n3SxSAAFRpkFR9UBJ6+/Ut0NE5I5sDoD27t2LH3/8EWFhYVAqlVAqlejfvz+WLFmCJ554AocOHXJEOxst/yr7gVVmgOw0BMYd4Wu08tcLKCs34OaWweiVEOrq5kjO/wz8/AYAQH/HUhy46I2IO+6AUq0G9Dog7wqQcwnIvVT5r3z/shQg5V+VbpfMt6wBIO0LZyl7ZDzmF8ZhNiJq9GwOgPR6PQICAgAAYWFhuHr1Ktq1a4e4uDicPn3a7g1s7EwCIOM2GNXXAALsmgFiETSQV6LD//ZeBADMHNxaHsJ1qcIsYOMMAAK46W8QncYBF7dUPq5SAyHx0s0SgwEoyqwIhlKrBEiXK4+V5ALFN6Rb2lHL1/HyqXmYLSAaUHHRUyLybDb/FuvcuTOOHDmChIQE9O7dG6+//jo0Gg0+/PBDtGrVyhFtbNSMKw5nFZTKRclmq0AD9dsKQ84A5Up/HJXSupfGACinqAx6g2iSO56v/i0V+aXlaBPuj9vbh7u6OYAQwKaZ0jBXWFtg5Ou2X0OplIqk/cOBFkmWzynJqxIUpVbLJF0G8tOA8mIg66x0s0ShlIIgk+xRCyCoZeV9jZ/t7SciciKbA6B//vOfKCwsBAAsXLgQd955JwYMGIBmzZph3bp1dm9gY2dcDPHs9QIAgLdaiWDfakWs+nJAX5GtqU8GCAIozZO/Nm6FYRBAbrFODoiaihKdHp/8ch6ANPPLbM0lV/htGXD2e6nIecJKKYDQ6Wp/nq28AwHvTkBEJ8uPl5eaDrNVzR7lXJIe05cBeZelG/Zavo5vs4qgKBYIbmkeKPmGcpiNiFzK5gBo+PDh8v3WrVvj1KlTyM7ORkhIiHsMI3gYYwB0Jj0fgFT/Y9aP5cWV923JAHlppeGM8mKpDqgiAFKrlAj09kJeSTmyC0ubXAC04cBlZBaUIjrIG3d1j3Z1c4Crh4Ad86T7w/8FRHZ2XVu8tEBoK+lmicEAFF6vNsx22TSTVJoHFGVJt2tHLF9H7VstKKoWKAVEAUqV494nETV5NgVAOp0OPj4+OHz4MDp3rvwlHRrqJgWkHshYA3QmXcoA1TgFHrAtAAKkoCe/WKoDCqk83MxfWxEAOSDL4MbK9QZ8+LO08OH0ga2gVtm8HZ59leYDGx4CDDqg/Z1Az4dd257aKJVAQKR0i+1p+ZzinGpBUbVAqSBdGtLNPC3dLFGopCn9ZsNssYB/FJSGplu/RkT2YVMApFar0bJlS671Y0fG7TByi6VAxPIMsCoF0LZm2byDpbqSajPBQnzVOA8gu7DUtut5uC3H05CaXYQQXzUm9ox1dXOAzc8C2X8BgS2Au95tHMNCPsHSzVomS1dSMcyWap49ykmVHjOUS4FTbqrZ09UARgMQKXPNs0dVi7d9QhpHfxKRQ9g8BPbSSy/hxRdfxGeffcbMjx0Yi6CNoi3OAKvHFHgjqzPBpA0/m1IGSAghb3o6pW8CfDUunsl0+HPg6FqpqHj8x1JdTFOg9gaaJUo3Swx6KUtUNSiqEiiJ3FQoygqhKMwACjOkIURLNP7mQVHVQCkgksNsRE2YzX8B3nvvPaSkpCA6OhpxcXHw8zOd7XHw4EG7Na4pCNCafgtqzQDZyupaQFLg1ZQyQLvOZODktTz4alSY3DfOtY3JTAE2PyPdH/wiENfHte1xJ0oVEBgt3dDb7OHysjLs+HYDhvZqD3XhNQvrIV2SAqOyAiDjpHSz+Dpq6TUsZY+CW0pDcGoL/yEhokbB5gBozJgxDmhG0+VfPQBycgaoKe0HZsz+PNCrJYJ9XVj4XV4KbJgK6AqB+AHAgNmua4snUiig8/IDIrsA6pstn6MrtjC8ViVQyr0i1V3lXJRu1viFV6tDalltmC3YIW+RiBzP5gBo/vz5jmhHk2WcBWZkt33AjLgfGADgwMUb2Hc+G2qVAtMGJLi2MTvmS4sQ+jYDxn3EYRhHUPsAYW2kmyUGvVQbZyl7ZPxXVyTNeCu8Dlw5YPk62kAL2aMqgZJ/hLz+FhG5Fy7n6mL+ZgGQnYfAatkPrKlkgJbvkrI/Y2+KsdzHznJ6K7BvmXR/zDIgMMp1bWnKlKqKAuoWACwMPwohrZZtsljkZdMVtouypCn/1/+UbpaoNKaz2SxtXuuldehbJSLLbA6AlEpljev9cIaYbQKrFEH7aVQI9LbwLXFkBqgJ7Ad2Nj0fO06kQ6EAZgx04aanuVeATY9J9295HGg7vObzyXUUCqko3TcUiO5u+ZyyQul7WjUoqjrd37ho5I3z0s3yC0lZopo2r/UOdNS7JGrSbA6AvvrqK5OvdTodDh06hFWrVmHBggV2a1hTUbUGKCrYwiKIgEMzQNkFjT8AWr5LWvdneMdItA530U7oBr20z1dxNhDVDRjCoWSPp/EDmreVbpboy6VNaS1lj4wrbJcXAwVp0u3y75av4x1U8+a1/uGc7k9UDzYHQHfffbfZsQkTJqBTp05Yt24dpk2bZnMj3n//fbzxxhtIS0tDt27d8O6776JXr14Wz/30008xdepUk2NarRYlJSXy10IIzJ8/Hx999BFycnLQr18/LFu2DG3aWKkHcKGqQ2AW638Ah2aAGvuO8FdyivH14SsAgEcHuzD78/ObwMVfpKnZE1Zy2KMpUHlJs8mCW1p+XAhpGM04zCZvO3Kp8ljxDWkvv5JcIP24ldfRyjVIqoAYtE0vhuJoHhAaX7l5rVfTWu2dqC7sVgN0yy23YMaMGTY/b926dZg9ezaWL1+O3r174+2338bw4cNx+vRphIdb3qQyMDDQZOf56lmT119/Hf/+97+xatUqJCQk4OWXX8bw4cNx4sQJeHu717RWtUoJb7USJTpDDQFQPTZCNaolA1SiM6CorNz1a+I4yMe7/0K5QaBvYjN0jw12TSMu/Ars+j/p/qil1te/oaZFoQD8wqRbjJXZbKUFVWazWQiU8q8B+lIg+xyQfQ5KAB0A4NuNVV9I2lpEzhq1qCzUNh7TuigzSuRCdvmrV1xcjH//+9+IiYmx+blLly7F9OnT5azO8uXLsXnzZqxYsQIvvPCCxecoFApERkZafEwIgbfffhv//Oc/5WzVf//7X0RERGDTpk247777bG6jo/lr1SjRlVovzpUzQPZbB8hPo4LGS4mycgOyCsrgG9r4AqDswjKs3X8JADDTVdmfomxg43RAGIBuDwDdJrqmHeSZtP5AeHvpZoleJ9UaVQRF+uwLuPznXsQGAkrj8fISaSgu/ypwaZ/l63gHmwdFVQMlvzAOs1GjY/NfveqbngohkJ+fD19fX/zvf/+z6VplZWU4cOAA5s6dKx9TKpUYMmQI9u61sss0gIKCAsTFxcFgMODmm2/G4sWL0amTtLv1+fPnkZaWhiFDhsjnBwUFoXfv3ti7d6/FAKi0tBSlpZULAubl5QGQ6pt0dtiR23gNa9cK0KqQWQBEBKgtnqMsLYAKgF6lhcHW9nj5QQ1AlOSivKxUWnW4QqivGml5pcjIK0JkgNr6NRyotr5piJW/nEOxTo9O0QHoHRfkkNeokRBQfTUTyrwrEKGJKB+22KYd3h3ZN56M/VKNf4x0i+kNnU6Hw/kd0XzoUKjVammYrTADitzLQN4l6d/cy1DkVtzPuwxFSY70H6S0HCDtmMWXEF4+QFAMRKA0c04ExUJUBEkisIW0oKTSvf8Txc+NdY2pb2x5DzZ/Yt966y2TAEipVKJ58+bo3bs3QkJCanimuczMTOj1ekRERJgcj4iIwKlTpyw+p127dlixYgW6du2K3NxcvPnmm+jbty/+/PNPtGjRAmlpafI1ql/T+Fh1S5YssVjAvX37dvj61iPrYsWOHTssHvfWKwEokZlyFFvSj5o93i31DOIBnDl/CWeKt9j0mkpDGUYDUAgDtn+3EeWqyvejKlcBUOD75D24FCJsuq69Weub+irVA58clN5fT/8cbN261a7Xr4uEjB3oenkb9Aov7G4+Gbk//Fyv69i7bxoL9ot1lvtGDSBBuvlDusUAXvpi+JRlwbcsEz5lmfAty5K+1mXCpywL3rocKMqLgawUKLJSLL6egALF6hAUa8JQpGlm/q86DHqVe9S98XNjXWPom6Kiojqfa3MANGXKFFufYld9+vRBnz6V63b07dsXHTp0wAcffIBFixbV65pz587F7NmVq/Hm5eUhNjYWw4YNQ2Bgw6eg6nQ67NixA0ON/yurpvfAUpzLLESveMt7Qam+/hbIAtp27IbWt9xh8+uLP2dBUV6CYQN6mRRkfnH9AK6cy0LrTt1wR/dom69rD7X1TX2t3HMRReWnERfqixce7AeV0snp+7Rj8Pp0nXR/6EL062l7fZyj+sbTsV+sc0TflOvLgLyrUFTUH5lkjyqm+yv0ZfDVZcNXl41mhZavI3xCq2SPWgCBVe4HxQI+oQ4dZuPnxrrG1DfGEZy6sDkAWrlyJfz9/XHPPfeYHF+/fj2KioowefLkOl8rLCwMKpUK6enpJsfT09Ot1vhUp1arcdNNNyElRfqfifF56enpiIqqXGQuPT0d3bt3t3gNrVYLrdb8fydqtdquHwZr14sMUSMypIYixHKpBkjl7Q9VfdrjHQwUpEFdXgBUeX4zf+k955boXf6ht2dfl5UbsHKPtL3Bo4MT4a118gyY0gJg0wxpDZi2I6Hq8xhUDfjFbu/PYWPBfrHOrn2jVgPebYBwa6tqG6TVsi2tqm0s2C7NhaI4GyjOhiLNPMstvY5vxeKUsdU2r604FhAlzaxr8Nvh58aaxtA3trTf5k/TkiVL8MEHH5gdDw8Px4wZM2wKgDQaDZKSkrBz5055jzGDwYCdO3di1qxZdbqGXq/HsWPHcMcdUmYkISEBkZGR2Llzpxzw5OXlYd++fZg5c2ad2+ZWGlIEDUgzwQrSpCm1VYQap8I3stWgvz58BddySxAeoMW4m20vzG+wrc8DWWel6cdj/sPiUWrclEogIFK6xfa0fE5JbrWgKNU0UCpIl2a7Zp6RbpYoVFVW1W5hvh5SUAtAY7+SBWr8bA6AUlNTkZBgvpdSXFwcUlNTbW7A7NmzMXnyZPTo0QO9evXC22+/jcLCQnlW2KRJkxATE4MlS5YAABYuXIhbbrkFrVu3Rk5ODt544w1cvHgRDz/8MABphthTTz2FV199FW3atJGnwUdHR3vuRq4NDYCMM8HMNkRtfAGQwSDkbS+m9U+A1svJ+2wd/QI4vFoqNh//kbSSMFFT5x0ERAYBkZ0tP15ear55bdVAybh5bW6qdLPGN8z6tiN+UVJROFEFmwOg8PBwHD16FPHx8SbHjxw5gmbNmtncgIkTJyIjIwPz5s1DWloaunfvjm3btslFzKmpqVBW2Uzwxo0bmD59OtLS0hASEoKkpCTs2bMHHTt2lM95/vnnUVhYiBkzZiAnJwf9+/fHtm3b3G4NoDpryErQQOVaQNWmwoc2wv3AdpxMx7mMQgR4e+GB3lYWoHOUrHPAd09L9wc+D8T3d+7rE3kqL620Ppa1NbIMeilLZCl7ZBxmK8sHijKl29VDZpdQAxil9IbqclzFApUWAqWASG5O3ITYHADdf//9eOKJJxAQEICBAwcCAHbt2oUnn3yy3mvszJo1y+qQV3JyssnXb731Ft56660ar6dQKLBw4UIsXLiwXu1xOw1ZCRqwmgFqbDvCCyHwn2Qp+zOpTxwCvJ04ll1eBmx4CCgrAOL6AQOfc95rEzV2SpU01T4wGoi1sEuAENJ/8KwOs10GCq/Dy1ACZJ6WbhZfx0saZrO27UhQC0Dtof+RJjM2B0CLFi3ChQsXcPvtt8PLS3q6wWDApEmTsHjxYrs3kGCfGiDALAMU0siGwH77KxtHLuVA66XElL7mw7QOtXMBcO0w4BMCjPvILsWaRFRHCoX0s+cTAkR1tXiKrigPu75dg8HdE+FVcLXakFsqkHcVMJQDORel20Urr+UXXq0OqWWVQKmF9B9O1v15BJt/S2s0Gqxbtw6vvvoqDh8+DB8fH3Tp0gVxcXGOaB8BDdsKA6g1A9RY9gNbVlH7c2+PWDQPcOKaI2e2A3vfk+7f/R8gyAWF10RUM7UPCr2jIFoNNpkNKzPogfw006BI3si24piuUJrxVngduHLA8utoAqplj6oFSv4RUuE4uVy9/5vapk0bt9xctFFq6BBYLRmgnCIdyvUGeKk894fy+JVc/HwmAyqlAjMGtnLeC+ddAzY9Kt3v9QjQ3vZ1mojIDShV0n9egmKAlreYPy6ENJM2J9U8e2SsQyrKlGqRrp+QbhZfR13xOhayR8ZhNm6W7BQ2B0Djx49Hr169MGfOHJPjr7/+On7//XesX7/ebo0jSD90DS2CtpIBCvZRQ6GQXuJGkc65WRM7M878urNrFGJDnTQV1qAHvpoh7egd2QUY2khqzojInEIhzer0DQWiu1s+p6yoIjiqEhRVLdjOuyrNZrtxQbpZfiEpS1TjMFuQY95jE2NzAPTzzz/jlVdeMTs+cuRI/L//9//s0SaqqrwUQMXUTTtngLxUSgT5qJFTpMONojKPDYAuZBZiy7FrAIBHBzlx09NflgLnfwbUfsCElSyOJGrqNL5A87bSzRJ9OZB/zXL2yHisvFhat60gDbj8u+XraINqHmbza85htjqwOQAqKCiARmO+sq5arbZpCWqqI2P2B7B7DRAgTYXPKdIhq6AMiDB72CN88PNfMAjg1nbN0SGq4VuX1Enqb8BP0tpUGPUmEMbhYCKqhcpLCliCYwFLZbNCSBnlqlmj6itsF2cDpblAei6QftzK62irDLPFAkEVK2obg6bAGMDLySvkuyGbA6AuXbpg3bp1mDdvnsnxtWvXmqzFQ3ZirP9RqgFVPad1W8kAAVIh9F8ZhbjhoYXQ1/NK8OWBywCAmYNbO+dFi28AXz4MCD3Q5V6g2/3OeV0iatwUCsAvTLpF32T5nNKCimG2y1UKtatM98+/CuhLgey/pJvlF5K2FqkIipQBMYjPyIUiRQ2ExkuBkjbAUe/SbdgcAL388ssYN24czp07h9tuuw0AsHPnTqxZswYbNmywewObvIZOgQekqaGAtBy9wWCSGg3x9ezFED/59TzK9AYkxYWgZ3yI419QCOCbf0i/cEJbAXcu5ZRXInIerT8Q3l66WaLXSbVGVYOiqoFS7mWgvEQKlPKvApf3QwWgGwCsW1V5He9gy9kj4zG/MI//3WdzADR69Ghs2rQJixcvxoYNG+Dj44Nu3brhxx9/RGgol/23u4ZOgQcqh8CEQZqhUKWArpm/5y6GmFusw+rfpGXxZw5KhMIZP4x/fAKc/FbKyE1Y0ST+l0REHkSlBkLipJslQgCFmSZBkT77Iq6fPYBIbx0UuZek0YKSHCAtB0g7Zvk6Xt7V9mSrPswWXf9RCyep1zT4UaNGYdSoUQCkjUY///xzPPvsszhw4AD0er1dG9jkNXQKPCAV53p5S1F/cY5JAGTMAHniYoj/++0iCkrL0TbCH7e1D3f8C6YdB7a9KN0fusB6ipqIyF0pFIB/c+kWkwQAMOh02K/fgjvuuEPaTb0033r2KOeSVMhdXgJkpUg3i6+jlDaENsseVbmv8XPiGzdX73WAfv75Z3zyySf48ssvER0djXHjxuH999+3Z9sIaPgUeCPvYGlWQUkOqlbfeep+YCU6PVb+eh4AMHNwIpRKB2d/ygqlrS70pUCbYcAtjzn29YiIXEUbAER0lG6WlJcBeVdMg6LqgZK+DMi7LN0u/Wb5Orc8Doxw3Q4SNgVAaWlp+PTTT/HJJ58gLy8P9957L0pLS7Fp0yYWQDuKPTJAgFQIXZBmdUd4TxsCW3/gMjILyhAT7IM7u0Y7/gW3vSDtH+QfCYxZ5vFj30RE9ealAUITpJslBgNQmFFRh5RaLVCqqE0qzQX8bN9A3Z7qHACNHj0aP//8M0aNGoW3334bI0aMgEqlwvLlyx3ZPrJHDRBQWQfUCHaEL9cb8OHP0sKHMwa2gtrRK1gf/xI4+F8ACmD8R1LxHxERWaZUAgER0q1FD8vnlOQ6t00W1DkA2rp1K5544gnMnDmTW2A4k72GwIxT4c32A5MWP/SkDNDmY9dwKbsYoX4a3Nsj1rEvln0e+PYp6f7AZ4GEgY59PSKipsANVrOu83+df/nlF+Tn5yMpKQm9e/fGe++9h8zMTEe2jQD7DYFZyQCF+ElV+tmFZRBCNOw1nEAIgWXJUvZnat94+GhUjnsxvQ74chpQmgfE3gIMesFxr0VERE5V5wDolltuwUcffYRr167hkUcewdq1axEdHQ2DwYAdO3YgPz/fke1suowZoIZWy9eSASrTG1BY5v4z+JLPZOBUWj78NCpM6hPv2Bf7cZG047N3EDD+Y2kVVyIiahRsLp7w8/PDQw89hF9++QXHjh3DM888g//7v/9DeHg47rrrLke0sWlzcAbIR6OCt1r6GGQXuP8wmDH780DvlgjydeAaEyk/AL++I92/+31pyiYRETUaDaoebdeuHV5//XVcvnwZn3/+ub3aRFXZqwjaSgYIqMwCZRWWNuw1HOzAxWzsP58NtUqBaf1bOe6F8tOBrx6V7vd8GOgw2nGvRURELmGX6TMqlQpjxozBN998Y4/LUVX22AoDsJoBAqpMhXfz/cCWJUv72oy7qQUigxy087rBAHw1Q5rCGd4JGPaqY16HiIhcysHzh6nB7LkOEGAxAxRinArvxkNgZ9Lz8cPJdCgUwIxBDsz+7HkH+CsZ8PIB7lnZ8H4nIiK3xADI3dlzJWjA6o7wgHtngJbvkmp/RnSKRGJzf8e8yKXfgZ2LpPt3vA40b+eY1yEiIpdjAOTunJEBcvMd4S/fKMI3h68CAB4dlOiYFynOAb58CBB6oNM44Ka/O+Z1iIjILTAAcnd2zwDlSrsBV2HcEd5dZ4F9vPs8yg0C/Vo3Q7fYYPu/gBDAt09KS7YHxwGj3+ZWF0REjRwDIHdn7wyQ0Es7/VZhzAC54xBYdmEZ1v6eCgCYOai1Y17k4CrgxCZA6QVMWOkWK5QSEZFjMQByd/YKgNQ+gEqa7u5J+4F9uucCSnQGdIkJQr/WDtg47/pJYOsc6f7t84AWSfZ/DSIicjsMgNydvYbAAOurQfu7547whaXlWLXnAgBg5uBEKOw9LKUrBtZPBcpLgMTbgT7/sO/1iYjIbTEAcnf2ygAB1vcDc9Mi6M/3pyK3WIeEMD8M7xRp/xfYNhfIOAn4hQNjl0s7GBMRUZPA3/juzhkZoIohsPyScuj0hoa/jh2UlRvw8e7zAIBHBraCSmnn7M+fm4ADK6X74z4A/MPte30iInJrDIDcnRMyQEE+ahjjC3cZBtt0+ArS8koQHqDF2Jtj7HvxGxeBb56Q7vd/Gki8zb7XJyIit8cAyJ3pywF9RUDiwAyQUqlwq2Ewg0HICx8+PCABWi+V/S6u1wFfPgyU5gItegK3vmS/axMRkcdgAOTOyosr7zswAwRUbofhDhmg7SfS8VdGIQK9vXB/r5b2vfhPi4HL+wFtEDD+Y0DlwB3liYjIbTEAcmdlRZX3veyw+WcNq0G7y1R4IQSWJacAACb1iUeAtx0DlHM/Ab+8Jd2/6x0gJN5+1yYiIo/CAMidVS2AtscUcA/YD2zvuSwcuZwLrZcSU/rF2+/CBRnAV48AEEDSFKDTWPtdm4iIPA4DIHcmF0Dbof4H8Igd4ZdV1P5M7BmLMH+tfS5qMACbHgUK0oHmHYDhS+xzXSIi8lgMgNyZvQMgN88AHbuci91nM6FSKjB9QCv7XXjve0DKD9Iw4oQVgMZO/UlERB6LAZA7k4fA7FAADbj9jvDGmV+ju0YhNtROQcqVA8DOBdL9EUuAiI72uS4REXk0BkDuzJ5rAAE1Z4BcvCP8haxCbDl+DQDw6OBE+1y0JA/Y8BBgKAc63g0kTbXPdYmIyOMxAHJn9lwFGjDNAAlh8pCrd4T/+JcLEAK4vX042kcGNvyCQgDfPQXcuAAEtQRG/9s+heRERNQoMAByZ47KAAk9UFZg8pArp8HnlgEbD10FIG16aheH/gcc/xJQqIAJn1QGf0RERGAA5N7sXQOk9gFUUqBT047wolp2yNGSrymh0wv0jA9Bj/jQhl8w4zSw9Xnp/m0vAbG9Gn5NIiJqVBgAuTN7zwJTKGrdEb7cIJBXUm6f16uD3GIdfk2Thqbskv3RlUh1P7oioNVgoN/TDb8mERE1OgyA3Jm9h8AAqzPBvNUq+GmkPbeynTgMtmb/JZQaFGgb7o9b29lhR/bt/wTSjwO+YcDYDwAlP+JERGTOy9UNoBrYuwgaqHU/sMKyYmw7noaEMMevlSME8OneiwCAGQMToGhokfLJb4HfP5Luj/0ACIhsYAuJiKixYgDkzpyYAQKAMH8tLt8oxmvbTtnv9eogVCswqnNEwy6Scwn4epZ0v+8/gDZDGt4wIiJqtBgAuTMnZ4Aev7U1Ptr9FwwG5xVBq5TATd6Z8FI1YKhKXw58+bD0nqJvBm6bZ7f2ERFR48QAyJ05OQM0tGMEhnZsYCbGRjqdDlu2bGnYRXa9Blz6DdAESFtdeGns0zgiImq0WCHqzuw9DR6oMQPkkc7/DPz8hnR/9NtAaIJLm0NERJ6BAZA7s/c0eKBKBuiG/a7pKoWZwMYZAARw09+ALhNc3SIiIvIQDIDcmSOGwIwZIAtDYB5FCGDTY0D+NSCsLTDydVe3iIiIPAgDIHemK5T+dUQGyNOHwH5bBpz9HlBpgQkrAY2fq1tEREQehAGQOzNmgDQOmAXmyRmgq4eAHRUzvYb/C4js7Nr2EBGRx2EA5M4cOQvMUzNApfnSVhcGHdD+TqDnw65uEREReSC3CIDef/99xMfHw9vbG71798b+/fvr9Ly1a9dCoVBgzJgxJsenTJkChUJhchsxYoQDWu5gjlwHqDhHqqPxNJufAbL/AgJbAHe9K+1vRkREZCOXB0Dr1q3D7NmzMX/+fBw8eBDdunXD8OHDcf369Rqfd+HCBTz77LMYMGCAxcdHjBiBa9euybfPP//cEc13LEdmgIQeKCuw33Wd4fDnwNF1gEIJjP8Y8LXDzvFERNQkuTwAWrp0KaZPn46pU6eiY8eOWL58OXx9fbFixQqrz9Hr9XjwwQexYMECtGrVyuI5Wq0WkZGR8i0kJMRRb8ExhHBMBkjtC6gqFgr0pDqgzBQp+wMAg18E4vq4tj1EROTRXLoSdFlZGQ4cOIC5c+fKx5RKJYYMGYK9e/dafd7ChQsRHh6OadOmYffu3RbPSU5ORnh4OEJCQnDbbbfh1VdfRbNmzSyeW1paitLSUvnrvLw8ANIqxTqdrj5vzYTxGjZdS1cMtfEuvAA7tMPIyzsYisLr0BVkAn6u3TC0Tn1TXgqv9VOg0BXCENcP+lv+Ydf+cFf1+tw0AewX69g31rFvrGtMfWPLe3BpAJSZmQm9Xo+ICNPtFyIiInDqlOUNOX/55Rd88sknOHz4sNXrjhgxAuPGjUNCQgLOnTuHF198ESNHjsTevXuhUqnMzl+yZAkWLFhgdnz79u3w9bVf9mXHjh11Plddno87Ku5v/SEZQmHe7vq6rVyFAAD7kr9HVkCq3a7bEDX1TefL/0NixjGUegUgOeBelGz73oktcz1bPjdNCfvFOvaNdewb6xpD3xQVFdX5XI/aCyw/Px9///vf8dFHHyEsLMzqeffdd598v0uXLujatSsSExORnJyM22+/3ez8uXPnYvbs2fLXeXl5iI2NxbBhwxAYGNjgdut0OuzYsQNDhw6FWq2u/QkAkHcFOAYIpRojR41ucBuqUl1/F7hyDbd0aw/R/o7an+BAtfWN4sxWeB3aDgBQjfsAt7UZ5uwmuky9PjdNAPvFOvaNdewb6xpT3xhHcOrCpQFQWFgYVCoV0tPTTY6np6cjMtJ8aObcuXO4cOECRo+uDAgMBgMAwMvLC6dPn0ZiYqLZ81q1aoWwsDCkpKRYDIC0Wi20Wq3ZcbVabdcPg03X00sF0Aqtv/0/kL5SPZSXLh9wkw+7xb7JvQJ894R0/5bH4dVxlPMb5gbs/TlsLNgv1rFvrGPfWNcY+saW9ru0CFqj0SApKQk7d+6UjxkMBuzcuRN9+pgXubZv3x7Hjh3D4cOH5dtdd92FW2+9FYcPH0ZsbKzF17l8+TKysrIQFRXlsPdidyUVUax3kP2v7Qkbohr0wMbp0p5lUd2AIfNd3SIiImpEXD4ENnv2bEyePBk9evRAr1698Pbbb6OwsBBTp04FAEyaNAkxMTFYsmQJvL290bmz6aq/wcHBACAfLygowIIFCzB+/HhERkbi3LlzeP7559G6dWsMHz7cqe/NjL4MKMkGlF6An+WCbFlpRQCkbfgQnBl5Q9Qc+1/bXn5+A7j4K6Dxl7a68DLP0BEREdWXywOgiRMnIiMjA/PmzUNaWhq6d++Obdu2yYXRqampUCrrnqhSqVQ4evQoVq1ahZycHERHR2PYsGFYtGiRxWEuZ1L++haw+w2gxzTgzqU1n1ySK/3bFDNAF34Fdr0m3R+1FGhmPqxJRETUEC4PgABg1qxZmDVrlsXHkpOTa3zup59+avK1j48Pvv/eTWcJGYMZY3BTE0cGQO6cASrKBr58GBAGoNsDQLeJrm4RERE1Qi5fCLEpEVobAiBHDoG5awZICODrx4H8q0Cz1sAdb7i6RURE1EgxAHImmzJAxiLoJlQDtP9D4PQWaaXqCSsArb+rW0RERI0UAyBnMgYztgyBNZUMUNoxYPs/pftDF0kzv4iIiByEAZAT1WsIrAnUAKn0JfD66mFpllzbkUDvR1zdJCIiauQYADmTuwyBVc0ACWH/69uo6+XPoMg+BwREA2P+AygUrm4SERE1cgyAnMkYAJUXA+WlNZ/ryCEwYwbIUA6UFdr/+jZQHF+Pltm7IRRKYPxHgG+oS9tDRERNAwMgZ9IGAKjIbpTUsl+JI4fA1L6AsmK5cFfWAd24ANXWZwEAhv7PAPH9XdcWIiJqUhgAOZNCWZnRqW0YzJFDYAqFe9QB7fsQirJCZPm1kQIgIiIiJ2EA5Gx1nQkmrwPkgAwQ4PqZYPpy4NgXAICzEXdK24MQERE5CQMgZ5MLoXOsn2PQVxkCc0AGCHB9Bujcj0BhBoRvGK4HdnFNG4iIqMliAORsdZkJVppfed8RRdCA6zNAR9cCAAydxkEomP0hIiLnYgDkbHUKgCqyPyotoPZ2TDtcmQEqyQVObQYAGLrc6/zXJyKiJo8BkLPVJQByZAG03I7gitfKcdxrWHPia6C8BAhrB0RyxWciInI+BkDOZgyASmuYBu/IneCNXJkBOrJO+rfbfVz0kIiIXIIBkLPZMgTmqPofwHUZoBsXgYu/AFAAXTn8RURErsEAyNncZQjMVRmgo9LUdyQMAIJaOPe1iYiIKjAAcrY6BUAO3AZDbkdwxWvlOO41qhNCnv2Fbvc773WJiIiqYQDkbHUaAmukNUBXDgBZKYCXD9BhtPNel4iIqBoGQM5m0xCYAwMgV2SAjlRkfzqMrtgXjYiIyDUYADmbuxRBV80ACeG41zEqLwOOb5Dud7vP8a9HRERUAwZAzmZLDZAz1gEy6ABdkeNex+jsdqD4BuAfCbQa7PjXIyIiqgEDIGczBkC6IikrYokzhsA0fpUbkDqjDshY/Nz1HkCpcvzrERER1YABkLNVHdaythiiM4bAFArn1QEVZQOnt0n3OfuLiIjcAAMgZ1OqKgMba8NgzlgHCHDeTLA/N0pDbRFdgIhOjn0tIiKiOmAA5ApyHVCO5cedsRUG4LwMUNWtL4iIiNwAAyBXqK0Q2hlDYIBzMkBZ54DL+wGFEuhyj+Neh4iIyAYMgFyhpgBIX2VWVmPIABnX/km8DQiIcNzrEBER2YABkCvUFACVVCmMdvRigY7OABkM3PqCiIjcEgMgV6gpADJug6H2A1RqB7cjuKIdOY65/qXfgJxUQBMAtLvDMa9BRERUDwyAXKEuGSBHzwADHJ8BOvK59G/HuwGNr2Neg4iIqB4YALlCjRkgJxVAA47NAOmKgT+/lu5z9hcREbkZBkCuUGMGyElT4AHHZoBOb5WG84Jigbh+9r8+ERFRAzAAcgV3GQJzZAboaMXaP13vBZT8mBERkXvhXyZXcJchMEdlgAoygLM7pPtdOfxFRETuhwGQK9RpCMzJGSAh7Hfd4xsAoQeibwaat7XfdYmIiOyEAZAr1GkIzIk1QPoyqWjZXo5w7R8iInJvDIBcoS7rADljCEzjDyhU0v3iG/a55vWTwLXDgNIL6DzePtckIiKyMwZArmAMbnRFQHmZ6WPOzAApFJVZIHsVQhuzP22GAX7N7HNNIiIiO2MA5ApVszuleaaPOXMaPAD4hEj/2qMQ2qAHjq2X7nPtHyIicmMMgFxB5SVtDwGYD4M5cxYYYN+p8Bd2A3lXpOCt7YiGX4+IiMhBGAC5ilwHlGN63JnrAAH2nQpvHP7qNA7w0jb8ekRERA7CAMhV5ACo2hCYp2aAygqBE99I9zn7i4iI3BwDIFexNhPM6TVAwdK/Dc0AnfwO0BUCIQlAbK+GtoqIiMihGAC5iqUASFcirckDOG8IzF4ZIOPO793uk2aXERERuTEGQK5iKQCSZ4QpKoukHc0eGaC8q8D5XdL9rhMb2iIiIiKHYwDkKpYCION9bYDzNhC1Rwbo2HpAGIDYW4DQBHu0ioiIyKEYALmKxQDIiYsgGjU0AyREla0vuPYPERF5BgZArmJxCMyJ22DI7QiuaEdO/Z6fdgy4fgJQaYFOY+zUKCIiIsdiAOQqNWaAnBgANTQDZMz+tBtRuao0ERGRm2MA5Co11QA5cwisagZICNueqy+vsvUF1/4hIiLPwQDIVWqaBebMITBjBkhfBuiKbXvuXz8BhdcB32ZA6yF2bxoREZGjMAByFXcZAtP4AwpVxevn2PZc49o/nScAKrVdm0VERORIbhEAvf/++4iPj4e3tzd69+6N/fv31+l5a9euhUKhwJgxY0yOCyEwb948REVFwcfHB0OGDMHZs2cd0PIGcJcMkEJRvzqgkjzg1GbpPmd/ERGRh3F5ALRu3TrMnj0b8+fPx8GDB9GtWzcMHz4c169fr/F5Fy5cwLPPPosBAwaYPfb666/j3//+N5YvX459+/bBz88Pw4cPR0lJiaPehu2MAZCuENDrpPuuqAEC6jcT7MTXQHkJENYOiL7JEa0iIiJyGJcHQEuXLsX06dMxdepUdOzYEcuXL4evry9WrFhh9Tl6vR4PPvggFixYgFatWpk8JoTA22+/jX/+85+4++670bVrV/z3v//F1atXsWnTJge/GxtUzfIYh75cMQQG1C8DJK/9M5FbXxARkcfxcuWLl5WV4cCBA5g7d658TKlUYsiQIdi7d6/V5y1cuBDh4eGYNm0adu/ebfLY+fPnkZaWhiFDKotyg4KC0Lt3b+zduxf33Wc+XFNaWorS0lL567w8KRDR6XTQ6XT1fn9GxmtUv5aXxh+KsgLoCjIBTSBUJTlQAij38oOww+vWlUobJL1uYVbdXjf3EtQXf4GAAuUdxgENaKu1viH2jTXsF+vYN9axb6xrTH1jy3twaQCUmZkJvV6PiIgIk+MRERE4deqUxef88ssv+OSTT3D48GGLj6elpcnXqH5N42PVLVmyBAsWLDA7vn37dvj6+tb2Nupsx44dJl8PFRr4Atjz4xbk+LbCoOuXEAzg92NncP3iFru9bm2SsovQAsDJg3vw1+Xas09t075BBwCZ/u2x59ejAI42uA3V+4YqsW8sY79Yx76xjn1jXWPom6Kiojqf69IAyFb5+fn4+9//jo8++ghhYWF2u+7cuXMxe/Zs+eu8vDzExsZi2LBhCAxs+HCUTqfDjh07MHToUKjVlbOlvK78H3A9G/2SukAkDILX+ZeBYqBn/9shWvRs8OvWlXLrT8DB39AxIRrtB91R88lCwOuDhQCAkMGP4Y5utZxfC2t9Q+wba9gv1rFvrGPfWNeY+sY4glMXLg2AwsLCoFKpkJ6ebnI8PT0dkZGRZuefO3cOFy5cwOjRo+VjBoMBAODl5YXTp0/Lz0tPT0dUVJTJNbt3726xHVqtFlqt1uy4Wq2264fB7HoVxcdeugJArZZngXn5hUpfO4tfKABAVZYPVW2ve/kAkJUCePnAq8tYu7XT3n3dmLBvLGO/WMe+sY59Y11j6Btb2u/SImiNRoOkpCTs3LlTPmYwGLBz50706dPH7Pz27dvj2LFjOHz4sHy76667cOutt+Lw4cOIjY1FQkICIiMjTa6Zl5eHffv2WbymS1WdCi+E64qgbZkFZlz7p8Od0q71REREHsjlQ2CzZ8/G5MmT0aNHD/Tq1Qtvv/02CgsLMXXqVADApEmTEBMTgyVLlsDb2xudO3c2eX5wcDAAmBx/6qmn8Oqrr6JNmzZISEjAyy+/jOjoaLP1glyuagBUVggIvelxZ6nrLLDyMuD4l9J9rv1DREQezOUB0MSJE5GRkYF58+YhLS0N3bt3x7Zt2+Qi5tTUVCiVtiWqnn/+eRQWFmLGjBnIyclB//79sW3bNnh7ezviLdRf1QDIuAiiQgWo7Vd4Xbd2BFe0I6fm81J2AMXZgH8kkDDYsW0iIiJyIJcHQAAwa9YszJo1y+JjycnJNT73008/NTumUCiwcOFCLFy40A6tc6CqAVDV4S9nr6tT1wyQcfirywRA5RYfHSIionpx+UKITZqlDJAzt8GQ2xFc0Y4c6+cUZQNnvpfuc+d3IiLycAyAXMkkA+SibTCAumWA/vxK2jE+ogsQ2dn6eURERB6AAZAruUsAZMwA6UsBXbHlc6pufUFEROThGAC5knG6u6uHwLQBUvE1YDkLlHUOuLwfUCiBLvc4tWlERESOwADIldwlA6RQVGlLjvnjR9dJ/7a6FQgwX6CSiIjI0zAAciVrs8BcwVodkBBVhr9Y/ExERI0DAyBXMtbe6Aql9XUA1wyBVW1L9QxQ6m9AzkVA4w+0H+XsVhERETkEAyBXqhrs5F6W/nW3DJBx7Z+OdwMaJy/QSERE5CAMgFxJ5SVlVgAgJ1X61xU1QIDlDJCuBPhzk3SfW18QEVEjwgDI1YwBT84l6V9XDYFZygCd2QqU5gKBLYC4/q5oFRERkUMwAHI1YwBUXrH+jquGwCxlgIzFz13vBWzcj42IiMid8a+aq1Uf8nLVEFj1DFBBBpDyg3Sfw19ERNTIMAByteoBj9ZNaoCOfwkYyoHom4Hm7VzTJiIiIgdhAORqZhkgN6kBMs7+YvaHiIgaIQZArmaWAXKDGqDrp4BrhwGlF9B5vGvaQ0RE5EAMgFytagCk0gJqb9e0o2oG6GhF8XObYYBfmGvaQ0RE5EAMgFytagDkquEvoDIDVHwDOPqFdL8rd34nIqLGiQGQq1UNgFw1/AVUZoD0pUDeFaldbUe4rj1EREQOxADI1UwyQC6aAQYAmgBAUeXj0Gms64bjiIiIHIwBkKu5yxCYUmnaFu78TkREjRgDIFdzlyEwoLIOKCQeiO3typYQERE5FAMgV3OXDBAA+IRI/3a9D1AoXNsWIiIiB2IA5GrGrEv1+67Q53GgzXCg13TXtoOIiMjBvFzdgCav6rCXq4fAukyQbkRERI0cM0CupvICNP7SfVcPgRERETURDIDcgbEOyNUZICIioiaCAZA7MAZAzAARERE5BWuA3EHn8cDRciD2Fle3hIiIqElgAOQOBj4r3YiIiMgpOARGRERETQ4DICIiImpyGAARERFRk8MAiIiIiJocBkBERETU5DAAIiIioiaHARARERE1OQyAiIiIqMlhAERERERNDgMgIiIianIYABEREVGTwwCIiIiImhwGQERERNTkMAAiIiKiJsfL1Q1wR0IIAEBeXp5drqfT6VBUVIS8vDyo1Wq7XLOxYN9Yx76xjP1iHfvGOvaNdY2pb4x/t41/x2vCAMiC/Px8AEBsbKyLW0JERES2ys/PR1BQUI3nKERdwqQmxmAw4OrVqwgICIBCoWjw9fLy8hAbG4tLly4hMDDQDi1sPNg31rFvLGO/WMe+sY59Y11j6hshBPLz8xEdHQ2lsuYqH2aALFAqlWjRooXdrxsYGOjxHy5HYd9Yx76xjP1iHfvGOvaNdY2lb2rL/BixCJqIiIiaHAZARERE1OQwAHICrVaL+fPnQ6vVuropbod9Yx37xjL2i3XsG+vYN9Y11b5hETQRERE1OcwAERERUZPDAIiIiIiaHAZARERE1OQwACIiIqImhwGQg73//vuIj4+Ht7c3evfujf3797u6SXb1yiuvQKFQmNzat28vP15SUoLHH38czZo1g7+/P8aPH4/09HSTa6SmpmLUqFHw9fVFeHg4nnvuOZSXl5uck5ycjJtvvhlarRatW7fGp59+6oy3Z5Off/4Zo0ePRnR0NBQKBTZt2mTyuBAC8+bNQ1RUFHx8fDBkyBCcPXvW5Jzs7Gw8+OCDCAwMRHBwMKZNm4aCggKTc44ePYoBAwbA29sbsbGxeP31183asn79erRv3x7e3t7o0qULtmzZYvf3a4va+mbKlClmn6MRI0aYnNMY+2bJkiXo2bMnAgICEB4ejjFjxuD06dMm5zjzZ8idfl/VpW8GDx5s9rl59NFHTc5pjH2zbNkydO3aVV64sE+fPti6dav8eFP9zNhMkMOsXbtWaDQasWLFCvHnn3+K6dOni+DgYJGenu7qptnN/PnzRadOncS1a9fkW0ZGhvz4o48+KmJjY8XOnTvFH3/8IW655RbRt29f+fHy8nLRuXNnMWTIEHHo0CGxZcsWERYWJubOnSuf89dffwlfX18xe/ZsceLECfHuu+8KlUoltm3b5tT3WpstW7aIl156SWzcuFEAEF999ZXJ4//3f/8ngoKCxKZNm8SRI0fEXXfdJRISEkRxcbF8zogRI0S3bt3Eb7/9Jnbv3i1at24t7r//fvnx3NxcERERIR588EFx/Phx8fnnnwsfHx/xwQcfyOf8+uuvQqVSiddff12cOHFC/POf/xRqtVocO3bM4X1gTW19M3nyZDFixAiTz1F2drbJOY2xb4YPHy5Wrlwpjh8/Lg4fPizuuOMO0bJlS1FQUCCf46yfIXf7fVWXvhk0aJCYPn26yecmNzdXfryx9s0333wjNm/eLM6cOSNOnz4tXnzxRaFWq8Xx48eFEE33M2MrBkAO1KtXL/H444/LX+v1ehEdHS2WLFniwlbZ1/z580W3bt0sPpaTkyPUarVYv369fOzkyZMCgNi7d68QQvrDqFQqRVpamnzOsmXLRGBgoCgtLRVCCPH888+LTp06mVx74sSJYvjw4XZ+N/ZT/Y+8wWAQkZGR4o033pCP5eTkCK1WKz7//HMhhBAnTpwQAMTvv/8un7N161ahUCjElStXhBBC/Oc//xEhISFy3wghxJw5c0S7du3kr++9914xatQok/b07t1bPPLII3Z9j/VlLQC6++67rT6nqfTN9evXBQCxa9cuIYRzf4bc/fdV9b4RQgqAnnzySavPaSp9I4QQISEh4uOPP+ZnxgYcAnOQsrIyHDhwAEOGDJGPKZVKDBkyBHv37nVhy+zv7NmziI6ORqtWrfDggw8iNTUVAHDgwAHodDqTPmjfvj1atmwp98HevXvRpUsXREREyOcMHz4ceXl5+PPPP+Vzql7DeI4n9eP58+eRlpZm8j6CgoLQu3dvk74IDg5Gjx495HOGDBkCpVKJffv2yecMHDgQGo1GPmf48OE4ffo0bty4IZ/jif2VnJyM8PBwtGvXDjNnzkRWVpb8WFPpm9zcXABAaGgoAOf9DHnC76vqfWO0evVqhIWFoXPnzpg7dy6Kiorkx5pC3+j1eqxduxaFhYXo06cPPzM24GaoDpKZmQm9Xm/yAQOAiIgInDp1ykWtsr/evXvj008/Rbt27XDt2jUsWLAAAwYMwPHjx5GWlgaNRoPg4GCT50RERCAtLQ0AkJaWZrGPjI/VdE5eXh6Ki4vh4+PjoHdnP8b3Yul9VH2f4eHhJo97eXkhNDTU5JyEhASzaxgfCwkJsdpfxmu4oxEjRmDcuHFISEjAuXPn8OKLL2LkyJHYu3cvVCpVk+gbg8GAp556Cv369UPnzp0BwGk/Qzdu3HDr31eW+gYAHnjgAcTFxSE6OhpHjx7FnDlzcPr0aWzcuBFA4+6bY8eOoU+fPigpKYG/vz+++uordOzYEYcPH+Znpo4YAFGDjBw5Ur7ftWtX9O7dG3Fxcfjiiy88IjAh93DffffJ97t06YKuXbsiMTERycnJuP32213YMud5/PHHcfz4cfzyyy+uborbsdY3M2bMkO936dIFUVFRuP3223Hu3DkkJiY6u5lO1a5dOxw+fBi5ubnYsGEDJk+ejF27drm6WR6FQ2AOEhYWBpVKZVZ5n56ejsjISBe1yvGCg4PRtm1bpKSkIDIyEmVlZcjJyTE5p2ofREZGWuwj42M1nRMYGOgxQZbxvdT0eYiMjMT169dNHi8vL0d2drZd+suTPnetWrVCWFgYUlJSADT+vpk1axa+++47/PTTT2jRooV83Fk/Q+78+8pa31jSu3dvADD53DTWvtFoNGjdujWSkpKwZMkSdOvWDe+88w4/MzZgAOQgGo0GSUlJ2Llzp3zMYDBg586d6NOnjwtb5lgFBQU4d+4coqKikJSUBLVabdIHp0+fRmpqqtwHffr0wbFjx0z+uO3YsQOBgYHo2LGjfE7VaxjP8aR+TEhIQGRkpMn7yMvLw759+0z6IicnBwcOHJDP+fHHH2EwGORf7H369MHPP/8MnU4nn7Njxw60a9cOISEh8jme3l+XL19GVlYWoqKiADTevhFCYNasWfjqq6/w448/mg3hOetnyB1/X9XWN5YcPnwYAEw+N42xbywxGAwoLS1t0p8Zm7m6CrsxW7t2rdBqteLTTz8VJ06cEDNmzBDBwcEmlfee7plnnhHJycni/Pnz4tdffxVDhgwRYWFh4vr160IIaTpmy5YtxY8//ij++OMP0adPH9GnTx/5+cbpmMOGDROHDx8W27ZtE82bN7c4HfO5554TJ0+eFO+//75bToPPz88Xhw4dEocOHRIAxNKlS8WhQ4fExYsXhRDSNPjg4GDx9ddfi6NHj4q7777b4jT4m266Sezbt0/88ssvok2bNiZTvXNyckRERIT4+9//Lo4fPy7Wrl0rfH19zaZ6e3l5iTfffFOcPHlSzJ8/3+XT4Gvqm/z8fPHss8+KvXv3ivPnz4sffvhB3HzzzaJNmzaipKREvkZj7JuZM2eKoKAgkZycbDKVu6ioSD7HWT9D7vb7qra+SUlJEQsXLhR//PGHOH/+vPj6669Fq1atxMCBA+VrNNa+eeGFF8SuXbvE+fPnxdGjR8ULL7wgFAqF2L59uxCi6X5mbMUAyMHeffdd0bJlS6HRaESvXr3Eb7/95uom2dXEiRNFVFSU0Gg0IiYmRkycOFGkpKTIjxcXF4vHHntMhISECF9fXzF27Fhx7do1k2tcuHBBjBw5Uvj4+IiwsDDxzDPPCJ1OZ3LOTz/9JLp37y40Go1o1aqVWLlypTPenk1++uknAcDsNnnyZCGENBX+5ZdfFhEREUKr1Yrbb79dnD592uQaWVlZ4v777xf+/v4iMDBQTJ06VeTn55ucc+TIEdG/f3+h1WpFTEyM+L//+z+ztnzxxReibdu2QqPRiE6dOonNmzc77H3XRU19U1RUJIYNGyaaN28u1Gq1iIuLE9OnTzf7JdoY+8ZSnwAw+Xw782fInX5f1dY3qampYuDAgSI0NFRotVrRunVr8dxzz5msAyRE4+ybhx56SMTFxQmNRiOaN28ubr/9djn4EaLpfmZspRBCCOflm4iIiIhcjzVARERE1OQwACIiIqImhwEQERERNTkMgIiIiKjJYQBERERETQ4DICIiImpyGAARERFRk8MAiIjcjkKhwKZNm1zdDLcwePBgPPXUU65uBlGjwwCIiOpsypQpUCgUUCgUUKvVSEhIwPPPP4+SkhK7vs61a9cwcuRIu16zJu4QZCQnJ0OhUJhtYklEjuHl6gYQkWcZMWIEVq5cCZ1OhwMHDmDy5MlQKBR47bXX7PYanrKbNBF5LmaAiMgmWq0WkZGRiI2NxZgxYzBkyBDs2LFDftxgMGDJkiVISEiAj48PunXrhg0bNsiPtWjRAsuWLTO55qFDh6BUKnHx4kUA5kNgly5dwr333ovg4GCEhobi7rvvxoULFwAAx48fh1KpREZGBgAgOzsbSqUS9913n/z8V199Ff3796/3e/7ll18wYMAA+Pj4IDY2Fk888QQKCwvlx+Pj47F48WI89NBDCAgIQMuWLfHhhx+aXGPPnj3o3r07vL290aNHD2zatAkKhQKHDx/GhQsXcOuttwIAQkJCoFAoMGXKFJM+ff755xEaGorIyEi88sor9X4vRCRhAERE9Xb8+HHs2bMHGo1GPrZkyRL897//xfLly/Hnn3/i6aefxt/+9jfs2rULSqUS999/P9asWWNyndWrV6Nfv36Ii4szew2dTofhw4cjICAAu3fvxq+//gp/f3+MGDECZWVl6NSpE5o1a4Zdu3YBAHbv3m3yNQDs2rULgwcPrtd7PHfuHEaMGIHx48fj6NGjWLduHX755RfMmjXL5Lz/9//+H3r06IFDhw7hsccew8yZM3H69GkAQF5eHkaPHo0uXbrg4MGDWLRoEebMmSM/NzY2Fl9++SUA4PTp07h27Rreeecd+fFVq1bBz88P+/btw+uvv46FCxeaBJ1EVA+u3o2ViDzH5MmThUqlEn5+fkKr1QoAQqlUig0bNgghhCgpKRG+vr5iz549Js+bNm2auP/++4UQQhw6dEgoFApx8eJFIYQQer1exMTEiGXLlsnnAxBfffWVEEKIzz77TLRr104YDAb58dLSUuHj4yO+//57IYQQ48aNE48//rgQQoinnnpKPPfccyIkJEScPHlSlJWVCV9fX5PdsqsbNGiQePLJJy0+Nm3aNDFjxgyTY7t37xZKpVIUFxcLIYSIi4sTf/vb3+THDQaDCA8Pl9/TsmXLRLNmzeTzhRDio48+EgDEoUOHhBDSztsAxI0bN8za1r9/f5NjPXv2FHPmzLH6foiodqwBIiKb3HrrrVi2bBkKCwvx1ltvwcvLC+PHjwcApKSkoKioCEOHDjV5TllZGW666SYAQPfu3dGhQwesWbMGL7zwAnbt2oXr16/jnnvusfh6R44cQUpKCgICAkyOl5SU4Ny5cwCAQYMGyUNOu3btwuLFi3HmzBkkJycjOzsbOp0O/fr1q9f7PXLkCI4ePYrVq1fLx4QQMBgMOH/+PDp06AAA6Nq1q/y4QqFAZGQkrl+/DkDK6nTt2hXe3t7yOb169apzG6peGwCioqLkaxNR/TAAIiKb+Pn5oXXr1gCAFStWoFu3bvjkk08wbdo0FBQUAAA2b96MmJgYk+dptVr5/oMPPigHQGvWrMGIESPQrFkzi69XUFCApKQkkwDEqHnz5gAqZ3GdPXsWJ06cQP/+/XHq1CkkJyfjxo0b6NGjB3x9fev1fgsKCvDII4/giSeeMHusZcuW8n21Wm3ymEKhgMFgqNdrVufIaxM1VQyAiKjelEolXnzxRcyePRsPPPAAOnbsCK1Wi9TUVAwaNMjq8x544AH885//xIEDB7BhwwYsX77c6rk333wz1q1bh/DwcAQGBlo8p0uXLggJCcGrr76K7t27w9/fH4MHD8Zrr72GGzdu1Lv+x/j6J06ckIO++mjXrh3+97//obS0VA4Ef//9d5NzjHVUer2+3q9DRHXHImgiapB77rkHKpUK77//PgICAvDss8/i6aefxqpVq3Du3DkcPHgQ7777LlatWiU/Jz4+Hn379sW0adOg1+tx1113Wb3+gw8+iLCwMNx9993YvXs3zp8/j+TkZDzxxBO4fPkyACkjMnDgQKxevVoOdrp27YrS0lLs3LmzxmDMKCMjA4cPHza5paenY86cOdizZw9mzZqFw4cP4+zZs/j666/NiqBr8sADD8BgMGDGjBk4efIkvv/+e7z55pty2wEgLi4OCoUC3333HTIyMuRsGhE5BgMgImoQLy8vzJo1C6+//joKCwuxaNEivPzyy1iyZAk6dOiAESNGYPPmzUhISDB53oMPPogjR45g7Nix8PHxsXp9X19f/Pzzz2jZsiXGjRuHDh06YNq0aSgpKTHJCA0aNAh6vV4OgJRKJQYOHAiFQlGn+p81a9bgpptuMrl99NFH6Nq1K3bt2oUzZ85gwIABuOmmmzBv3jxER0fXuY8CAwPx7bff4vDhw+jevTteeuklzJs3DwDkuqCYmBgsWLAAL7zwAiIiImwKsIjIdgohhHB1I4iImprVq1dj6tSpyM3NrTEAJCLHYA0QEZET/Pe//0WrVq0QExODI0eOYM6cObj33nsZ/BC5CAMgIiInSEtLw7x585CWloaoqCjcc889+Ne//uXqZhE1WRwCIyIioiaHRdBERETU5DAAIiIioiaHARARERE1OQyAiIiIqMlhAERERERNDgMgIiIianIYABEREVGTwwCIiIiImhwGQERERNTk/H8XvCWDvch6tgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_review_length['review_length'], df_review_length['accuracy'])\n",
    "plt.plot(df_review_length['review_length'], df_review_length['f1_score'])\n",
    "plt.title('Scatter Plot of Accuracy / F1 score vs. Review Length')\n",
    "plt.xlabel('Review Length')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>small_extended</th>\n",
       "      <th>big_extended</th>\n",
       "      <th>small_float</th>\n",
       "      <th>big_float</th>\n",
       "      <th>small_float_binary</th>\n",
       "      <th>big_float_binary</th>\n",
       "      <th>small_few_shot</th>\n",
       "      <th>big_few_shot</th>\n",
       "      <th>random_binary</th>\n",
       "      <th>review_length_200_end</th>\n",
       "      <th>review_length_600_end</th>\n",
       "      <th>review_length_1000_end</th>\n",
       "      <th>review_length_1500_end</th>\n",
       "      <th>review_length_2000_end</th>\n",
       "      <th>review_length_3000_end</th>\n",
       "      <th>review_length_5000_end</th>\n",
       "      <th>review_length_10000_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>I first saw the film when it landed on US cabl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19005</th>\n",
       "      <td>Tom the cat, Jerry the mouse, and Spike the Do...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21690</th>\n",
       "      <td>Average viewers looking for any sense of inter...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10326</th>\n",
       "      <td>This movie made me so angry!! Here I am thinki...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12590</th>\n",
       "      <td>After having seen Deliverance, movies like Pul...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5489</th>\n",
       "      <td>I managed to grab a viewing of this with the a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34228</th>\n",
       "      <td>Engaging characters, nice animation, dynamite ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22232</th>\n",
       "      <td>I saw this in the early 70s (when I was 16), a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32062</th>\n",
       "      <td>I'm not sure why there are no articles or post...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14017</th>\n",
       "      <td>Countless TV displays and the memorable appear...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39371</th>\n",
       "      <td>First of all, I'd like to say that I really en...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35966</th>\n",
       "      <td>When a Stranger Calls belongs to the group of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24811</th>\n",
       "      <td>Up to this point, Gentle Rain was the movie I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22153</th>\n",
       "      <td>This movie is funny if you're the gentleman wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14862</th>\n",
       "      <td>For those of you who've wondered what an art-h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35650</th>\n",
       "      <td>* Some spoilers *&lt;br /&gt;&lt;br /&gt;This movie is som...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34704</th>\n",
       "      <td>When a movie's claim to fame is that Martin Sh...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7644</th>\n",
       "      <td>The Knowledge is a typical British comedy for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26813</th>\n",
       "      <td>Yesterday my Spanish / Catalan wife and myself...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7057</th>\n",
       "      <td>One of the most boring,pointless movies I have...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39775</th>\n",
       "      <td>*I mark where there are spoilers! Overall comm...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14897</th>\n",
       "      <td>Worthless movie. A complete waste of time and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13906</th>\n",
       "      <td>This is without a doubt the WORST sequel I hav...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28866</th>\n",
       "      <td>If you want a fun romp with loads of subtle hu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10550</th>\n",
       "      <td>It's 1913. A studio prop boy spies the actress...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25325</th>\n",
       "      <td>H.G. Wells is spinning. No doubt about it.&lt;br ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29377</th>\n",
       "      <td>I just purchased this movie because I love to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730</th>\n",
       "      <td>I just viewed Eddie Monroe and I was very impr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2680</th>\n",
       "      <td>This film is easily one of the worst ones I ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31621</th>\n",
       "      <td>If you're a fan of the original series, do NOT...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38833</th>\n",
       "      <td>I think the show had a pretty good concept to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39071</th>\n",
       "      <td>Ooof! This one was a stinker. It does not fall...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10938</th>\n",
       "      <td>This is some of the worst acting I have ever s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28642</th>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16906</th>\n",
       "      <td>As many others have stated, this is a terrible...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11681</th>\n",
       "      <td>hey i think this movie was great and it had gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37382</th>\n",
       "      <td>The title of this film nearly put me off watch...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>I went to this movie expecting a concise movie...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35551</th>\n",
       "      <td>Everybody interested in Texas needs to have th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6993</th>\n",
       "      <td>I've seen some bad things in my time. A half d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14696</th>\n",
       "      <td>The old man mouse in this cartoon would have y...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5114</th>\n",
       "      <td>The hurried approach that Lewis Seiler takes w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>This is a really silly job of miscasting--abou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>More eeriness and dark secrets released in the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26100</th>\n",
       "      <td>From the portrayals of Andy Warhol in the film...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20732</th>\n",
       "      <td>Following a roughly 7 year rocky road on NBC, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23039</th>\n",
       "      <td>I just can't believe some of the comments on t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33804</th>\n",
       "      <td>Dr. Krellman wants to save his son Julio who's...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13977</th>\n",
       "      <td>I too like Dafoe as an actor but i wasted a fe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>This was the one movie to see about the Civi W...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label  \\\n",
       "709    I first saw the film when it landed on US cabl...      0   \n",
       "19005  Tom the cat, Jerry the mouse, and Spike the Do...      0   \n",
       "21690  Average viewers looking for any sense of inter...      1   \n",
       "10326  This movie made me so angry!! Here I am thinki...      1   \n",
       "12590  After having seen Deliverance, movies like Pul...      0   \n",
       "5489   I managed to grab a viewing of this with the a...      1   \n",
       "34228  Engaging characters, nice animation, dynamite ...      0   \n",
       "22232  I saw this in the early 70s (when I was 16), a...      0   \n",
       "32062  I'm not sure why there are no articles or post...      0   \n",
       "14017  Countless TV displays and the memorable appear...      0   \n",
       "39371  First of all, I'd like to say that I really en...      1   \n",
       "35966  When a Stranger Calls belongs to the group of ...      1   \n",
       "24811  Up to this point, Gentle Rain was the movie I ...      1   \n",
       "22153  This movie is funny if you're the gentleman wh...      1   \n",
       "14862  For those of you who've wondered what an art-h...      0   \n",
       "35650  * Some spoilers *<br /><br />This movie is som...      1   \n",
       "34704  When a movie's claim to fame is that Martin Sh...      1   \n",
       "7644   The Knowledge is a typical British comedy for ...      0   \n",
       "26813  Yesterday my Spanish / Catalan wife and myself...      0   \n",
       "7057   One of the most boring,pointless movies I have...      1   \n",
       "39775  *I mark where there are spoilers! Overall comm...      0   \n",
       "14897  Worthless movie. A complete waste of time and ...      1   \n",
       "13906  This is without a doubt the WORST sequel I hav...      1   \n",
       "28866  If you want a fun romp with loads of subtle hu...      0   \n",
       "10550  It's 1913. A studio prop boy spies the actress...      0   \n",
       "25325  H.G. Wells is spinning. No doubt about it.<br ...      1   \n",
       "29377  I just purchased this movie because I love to ...      1   \n",
       "6730   I just viewed Eddie Monroe and I was very impr...      0   \n",
       "2680   This film is easily one of the worst ones I ha...      1   \n",
       "31621  If you're a fan of the original series, do NOT...      1   \n",
       "38833  I think the show had a pretty good concept to ...      1   \n",
       "39071  Ooof! This one was a stinker. It does not fall...      1   \n",
       "10938  This is some of the worst acting I have ever s...      1   \n",
       "28642  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      1   \n",
       "16906  As many others have stated, this is a terrible...      1   \n",
       "11681  hey i think this movie was great and it had gr...      0   \n",
       "37382  The title of this film nearly put me off watch...      0   \n",
       "4837   I went to this movie expecting a concise movie...      1   \n",
       "35551  Everybody interested in Texas needs to have th...      0   \n",
       "6993   I've seen some bad things in my time. A half d...      1   \n",
       "14696  The old man mouse in this cartoon would have y...      1   \n",
       "5114   The hurried approach that Lewis Seiler takes w...      0   \n",
       "367    This is a really silly job of miscasting--abou...      1   \n",
       "1927   More eeriness and dark secrets released in the...      0   \n",
       "26100  From the portrayals of Andy Warhol in the film...      1   \n",
       "20732  Following a roughly 7 year rocky road on NBC, ...      0   \n",
       "23039  I just can't believe some of the comments on t...      0   \n",
       "33804  Dr. Krellman wants to save his son Julio who's...      1   \n",
       "13977  I too like Dafoe as an actor but i wasted a fe...      1   \n",
       "427    This was the one movie to see about the Civi W...      0   \n",
       "\n",
       "       small_extended  big_extended  small_float  big_float  \\\n",
       "709                 1             1           -2         -2   \n",
       "19005               0             0           -2         -2   \n",
       "21690               0             1           -2         -2   \n",
       "10326               0             1           -1         -2   \n",
       "12590               0             1           -2         -2   \n",
       "5489                0             1           -1         -2   \n",
       "34228               0             1           -2         -2   \n",
       "22232               1             1           -2         -2   \n",
       "32062               0             1           -2         -2   \n",
       "14017               0             1           -2         -2   \n",
       "39371               0             1           -2         -2   \n",
       "35966               0             1           -2         -2   \n",
       "24811               0             1           -1         -2   \n",
       "22153               0             1           -2         -2   \n",
       "14862               0             1           -2         -2   \n",
       "35650               0             1           -2         -2   \n",
       "34704               0             1           -2         -2   \n",
       "7644                0             0           -2         -2   \n",
       "26813               1             1           -2         -2   \n",
       "7057                0             1           -2         -2   \n",
       "39775               0             1           -2         -2   \n",
       "14897               0             1           -2         -2   \n",
       "13906               0             1           -1         -2   \n",
       "28866               0             1           -2         -2   \n",
       "10550               0             1           -2         -2   \n",
       "25325               0             1           -1         -2   \n",
       "29377               0             1           -2         -2   \n",
       "6730                0             1           -2         -2   \n",
       "2680                0             1           -2         -2   \n",
       "31621               0             1           -2         -2   \n",
       "38833               0             1           -2         -2   \n",
       "39071               0             1           -1         -2   \n",
       "10938               0             1           -2         -2   \n",
       "28642               0             1           -2         -2   \n",
       "16906               0             1           -1         -2   \n",
       "11681               1             1           -2         -2   \n",
       "37382               0             1           -2         -2   \n",
       "4837                0             1           -2         -2   \n",
       "35551               0             1           -2         -2   \n",
       "6993                0             1           -2         -2   \n",
       "14696               0             1           -2         -2   \n",
       "5114                0             1           -2         -2   \n",
       "367                 0             1           -1         -2   \n",
       "1927                0             1           -2         -2   \n",
       "26100               0             1           -2         -2   \n",
       "20732               0             1           -2         -2   \n",
       "23039               1             1           -2         -2   \n",
       "33804               0             1           -1         -2   \n",
       "13977               0             1           -2         -2   \n",
       "427                 1             1           -2         -2   \n",
       "\n",
       "       small_float_binary  big_float_binary  small_few_shot  big_few_shot  \\\n",
       "709                    -2                -2               0             1   \n",
       "19005                  -2                -2               0            -2   \n",
       "21690                  -2                -2               0            -2   \n",
       "10326                   1                -2               0            -2   \n",
       "12590                  -2                -2               0             1   \n",
       "5489                    1                -2               0             1   \n",
       "34228                  -2                -2               0             1   \n",
       "22232                  -2                -2               0             1   \n",
       "32062                  -2                -2               0             1   \n",
       "14017                  -2                -2               0             1   \n",
       "39371                  -2                -2               0             1   \n",
       "35966                  -2                -2               0            -2   \n",
       "24811                   1                -2               0            -2   \n",
       "22153                  -2                -2               0            -2   \n",
       "14862                  -2                -2               1             1   \n",
       "35650                  -2                -2               0             1   \n",
       "34704                  -2                -2               0            -2   \n",
       "7644                   -2                -2               0             0   \n",
       "26813                  -2                -2               0             1   \n",
       "7057                   -2                -2               0             1   \n",
       "39775                  -2                -2               0             1   \n",
       "14897                  -2                -2               0            -2   \n",
       "13906                   1                -2               0             1   \n",
       "28866                  -2                -2               0             1   \n",
       "10550                  -2                -2               0             1   \n",
       "25325                   1                -2               0             1   \n",
       "29377                  -2                -2               0            -2   \n",
       "6730                   -2                -2               0             1   \n",
       "2680                   -2                -2               0            -2   \n",
       "31621                  -2                -2               0            -2   \n",
       "38833                  -2                -2               0             1   \n",
       "39071                   1                -2               0            -2   \n",
       "10938                  -2                -2               0            -2   \n",
       "28642                  -2                -2               0            -2   \n",
       "16906                   1                -2               0             1   \n",
       "11681                  -2                -2               0             1   \n",
       "37382                  -2                -2               0             1   \n",
       "4837                   -2                -2               0             1   \n",
       "35551                  -2                -2               0             1   \n",
       "6993                   -2                -2               0             1   \n",
       "14696                  -2                -2               0             1   \n",
       "5114                   -2                -2               0             1   \n",
       "367                     1                -2               0            -2   \n",
       "1927                   -2                -2               1             1   \n",
       "26100                  -2                -2               0            -2   \n",
       "20732                  -2                -2               0             1   \n",
       "23039                  -2                -2               0             1   \n",
       "33804                   1                -2               0             1   \n",
       "13977                  -2                -2               0            -2   \n",
       "427                    -2                -2               0             1   \n",
       "\n",
       "       random_binary  review_length_200_end  review_length_600_end  \\\n",
       "709                0                      1                      1   \n",
       "19005              0                      0                      1   \n",
       "21690              1                      1                      1   \n",
       "10326              1                      1                      1   \n",
       "12590              0                      1                      1   \n",
       "5489               1                      1                      1   \n",
       "34228              1                      1                      1   \n",
       "22232              1                      1                      1   \n",
       "32062              0                      1                      1   \n",
       "14017              1                      1                      1   \n",
       "39371              1                      1                      1   \n",
       "35966              0                      1                      1   \n",
       "24811              1                      1                      1   \n",
       "22153              0                      1                      1   \n",
       "14862              0                      1                      1   \n",
       "35650              0                      1                      1   \n",
       "34704              1                      1                      1   \n",
       "7644               1                      1                      1   \n",
       "26813              0                      1                      1   \n",
       "7057               1                      1                      1   \n",
       "39775              1                      1                      1   \n",
       "14897              1                      1                      1   \n",
       "13906              0                      1                      0   \n",
       "28866              0                      1                      1   \n",
       "10550              1                      1                      1   \n",
       "25325              0                      1                      1   \n",
       "29377              0                      1                      1   \n",
       "6730               0                      1                      1   \n",
       "2680               1                      1                      1   \n",
       "31621              1                      1                      1   \n",
       "38833              0                      1                      1   \n",
       "39071              0                      1                      0   \n",
       "10938              0                      1                      1   \n",
       "28642              0                      1                      1   \n",
       "16906              1                      1                      1   \n",
       "11681              1                      1                      1   \n",
       "37382              0                      1                      1   \n",
       "4837               0                      1                      1   \n",
       "35551              0                      1                      1   \n",
       "6993               1                      1                      0   \n",
       "14696              0                      1                      1   \n",
       "5114               0                      1                      1   \n",
       "367                1                      1                      1   \n",
       "1927               1                      1                      1   \n",
       "26100              0                      1                      1   \n",
       "20732              1                      1                      1   \n",
       "23039              0                      1                      1   \n",
       "33804              1                      1                      1   \n",
       "13977              0                      1                      1   \n",
       "427                1                      1                      1   \n",
       "\n",
       "       review_length_1000_end  review_length_1500_end  review_length_2000_end  \\\n",
       "709                         1                       0                       1   \n",
       "19005                       1                       0                       1   \n",
       "21690                       1                       1                       1   \n",
       "10326                       1                       1                       1   \n",
       "12590                       1                       1                       1   \n",
       "5489                        1                       1                       1   \n",
       "34228                       1                       0                       1   \n",
       "22232                       1                       0                       1   \n",
       "32062                       1                       1                       0   \n",
       "14017                       1                       1                       1   \n",
       "39371                       1                       1                       1   \n",
       "35966                       1                       1                       1   \n",
       "24811                       1                       1                       1   \n",
       "22153                       1                       1                       1   \n",
       "14862                       1                       1                       1   \n",
       "35650                       1                       1                       1   \n",
       "34704                       1                       1                       1   \n",
       "7644                        1                       1                       1   \n",
       "26813                       1                       1                       0   \n",
       "7057                        1                       1                       1   \n",
       "39775                       1                       1                       1   \n",
       "14897                       1                       1                       0   \n",
       "13906                       1                       1                       1   \n",
       "28866                       1                       0                       0   \n",
       "10550                       1                       1                       1   \n",
       "25325                       1                       1                       1   \n",
       "29377                       0                       1                       1   \n",
       "6730                        1                       1                       0   \n",
       "2680                        1                       1                       1   \n",
       "31621                       1                       1                       1   \n",
       "38833                       1                       1                       1   \n",
       "39071                       1                       1                       1   \n",
       "10938                       1                       1                       1   \n",
       "28642                       0                       0                       1   \n",
       "16906                       1                       1                       1   \n",
       "11681                       1                       1                       1   \n",
       "37382                       1                       1                       1   \n",
       "4837                        1                       1                       1   \n",
       "35551                       1                       1                       0   \n",
       "6993                        1                       1                       0   \n",
       "14696                       0                       1                       1   \n",
       "5114                        0                       1                       1   \n",
       "367                         1                       1                       1   \n",
       "1927                        1                       1                       1   \n",
       "26100                       1                       0                       1   \n",
       "20732                       1                       1                       1   \n",
       "23039                       1                       1                       1   \n",
       "33804                       1                       1                       0   \n",
       "13977                       1                       1                       1   \n",
       "427                         0                       0                       1   \n",
       "\n",
       "       review_length_3000_end  review_length_5000_end  review_length_10000_end  \n",
       "709                         1                       1                        1  \n",
       "19005                       1                       1                        1  \n",
       "21690                       1                       0                        1  \n",
       "10326                       1                       1                        1  \n",
       "12590                       1                       1                        0  \n",
       "5489                        1                       1                        1  \n",
       "34228                       1                       0                        1  \n",
       "22232                       1                       1                        0  \n",
       "32062                       1                       0                        1  \n",
       "14017                       1                       1                        1  \n",
       "39371                       1                       1                        1  \n",
       "35966                       1                       1                        1  \n",
       "24811                       1                       0                        1  \n",
       "22153                       1                       1                        1  \n",
       "14862                       1                       1                        1  \n",
       "35650                       1                       1                        0  \n",
       "34704                       1                       1                        0  \n",
       "7644                        1                       1                        0  \n",
       "26813                       1                       1                        1  \n",
       "7057                        1                       0                        1  \n",
       "39775                       1                       0                        1  \n",
       "14897                       1                       1                        1  \n",
       "13906                       1                       1                        1  \n",
       "28866                       1                       1                        1  \n",
       "10550                       1                       1                        1  \n",
       "25325                       1                       0                        1  \n",
       "29377                       0                       1                        1  \n",
       "6730                        1                       0                        1  \n",
       "2680                        0                       1                        1  \n",
       "31621                       1                       1                        1  \n",
       "38833                       1                       0                        1  \n",
       "39071                       1                       0                        1  \n",
       "10938                       1                       1                        1  \n",
       "28642                       1                       1                        1  \n",
       "16906                       0                       0                        0  \n",
       "11681                       1                       1                        1  \n",
       "37382                       1                       0                        1  \n",
       "4837                        1                       1                        1  \n",
       "35551                       1                       1                        0  \n",
       "6993                        1                       1                        1  \n",
       "14696                       1                       0                        1  \n",
       "5114                        0                       1                        1  \n",
       "367                         0                       1                        1  \n",
       "1927                        1                       1                        1  \n",
       "26100                       0                       0                        1  \n",
       "20732                       1                       1                        1  \n",
       "23039                       1                       1                        1  \n",
       "33804                       0                       0                        1  \n",
       "13977                       1                       1                        1  \n",
       "427                         1                       1                        1  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jetbrains",
   "language": "python",
   "name": "jetbrains"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
